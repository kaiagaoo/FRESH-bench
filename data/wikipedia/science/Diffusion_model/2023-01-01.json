{"title": "Diffusion model", "page_id": 71912239, "revision_id": 1129335322, "revision_timestamp": "2022-12-24T20:03:14Z", "content": "{{Short description|Deep learning algorithm}}\nIn [[machine learning]], '''diffusion models''', also known as '''diffusion probabilistic models''', are a class of [[latent variable model]]s. They are [[Markov chain]]s trained using [[Variational Bayesian methods|variational inference]].<ref>{{cite journal |last1=Ho |first1=Jonathan |last2=Jain |first2=Ajay |last3=Abbeel |first3=Pieter |title=Denoising Diffusion Probabilistic Models |date=19 June 2020 |arxiv=2006.11239}}</ref> The goal of diffusion models is to learn the latent structure of a dataset by modeling the way in which data points diffuse through the [[latent space]]. In [[computer vision]], this means that a neural network is trained to [[denoise]] images blurred with [[Gaussian noise]] by learning to reverse the diffusion process.<ref>{{cite journal |last1=Song |first1=Yang |last2=Ermon |first2=Stefano |title=Improved Techniques for Training Score-Based Generative Models |date=2020 |arxiv=2006.09011}}</ref><ref>{{cite journal |last1=Gu |first1=Shuyang |last2=Chen |first2=Dong |last3=Bao |first3=Jianmin |last4=Wen |first4=Fang |last5=Zhang |first5=Bo |last6=Chen |first6=Dongdong |last7=Yuan |first7=Lu |last8=Guo |first8=Baining |title=Vector Quantized Diffusion Model for Text-to-Image Synthesis |date=2021 |arxiv=2111.14822}}</ref>\n\nDiffusion models were introduced in 2015 with a motivation from [[non-equilibrium thermodynamics]].<ref>{{Cite journal |last1=Sohl-Dickstein |first1=Jascha |last2=Weiss |first2=Eric |last3=Maheswaranathan |first3=Niru |last4=Ganguli |first4=Surya |date=2015-06-01 |title=Deep Unsupervised Learning using Nonequilibrium Thermodynamics |url=http://proceedings.mlr.press/v37/sohl-dickstein15.pdf |journal=Proceedings of the 32nd International Conference on Machine Learning |language=en |publisher=PMLR |volume=37 |pages=2256\u20132265}}</ref>\n\nDiffusion models can be applied to a variety of tasks, including [[image denoising]], [[inpainting]], [[super-resolution]], and [[text-to-image model|image generation]]. For example, an image generation model would start with a random noise image and then, after having been trained reversing the diffusion process on natural images, the model would be able to generate new natural images. Announced on 13 April 2022, [[OpenAI]]'s text-to-image model [[DALL-E 2]] is a recent example. It uses diffusion models for both the model's prior (which produces an image embedding given a text caption) and the decoder that generates the final image.<ref>{{cite journal |last1=Ramesh |first1=Aditya |last2=Dhariwal |first2=Prafulla |last3=Nichol |first3=Alex |last4=Chu |first4=Casey |last5=Chen |first5=Mark |title=Hierarchical Text-Conditional Image Generation with CLIP Latents |date=2022 |arxiv=2204.06125}}</ref>\n\n==See also==\n* [[Diffusion process]]\n* [[Markov chain]]\n* [[Variational inference]]\n* [[Variational autoencoder]]\n\n==References==\n{{reflist}}\n\n[[Category:Markov models]]\n[[Category:Machine learning algorithms]]\n\n\n{{Artificial-intelligence-stub}}"}