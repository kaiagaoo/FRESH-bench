{"title": "GPT-3", "page_id": 64695824, "revision_id": 1130774289, "revision_timestamp": "2022-12-31T22:29:15Z", "content": "{{Short description|2020 text-generating language model}}\n{{use mdy dates|date=August 2020}}\n{{Infobox software \n| name                   = Generative Pre-trained Transformer 3 (GPT-3)\n| logo                   = \n| screenshot             = \n| screenshot size        = \n| caption                = \n| author                 =  [[OpenAI]]<ref name=\"arXiv_Brown_20200722\" />\n| developer              = \n| released               = June 11, 2020 (beta)\n| latest release version = \n| latest release date    = \n| repo                   =\n| programming language   =\n| operating system       = \n| genre                  = [[Autoregressive]] [[Transformer (machine learning model)|transformer]] [[language model]]\n| license                = \n| website                = {{URL|https://openai.com/blog/openai-api}}\n}}\n{{Artificial intelligence}}\n'''Generative Pre-trained Transformer 3''' ('''GPT-3''') is an [[autoregressive model|autoregressive]] [[language model]] that uses [[deep learning]] to produce human-like text. Given an initial text as prompt, it will produce text that continues the prompt.\n\nThe architecture is a standard [[transformer (machine learning model)|transformer network]] (with a few engineering tweaks) with the unprecedented size of 2048-[[Lexical analysis|token]]-long context and 175 billion [[Parameter (machine learning)|parameters]] (requiring 800 GB of storage). The training method is \"generative pretraining\", meaning that it is trained to predict what the next token is. The model demonstrated strong [[few-shot learning]] on many text-based tasks.\n\nIt is the third-generation language prediction model in the GPT-n series (and the successor to [[GPT-2]]) created by [[OpenAI]], a San Francisco-based [[artificial intelligence]] research laboratory.<ref name=\"CNBC_Shead_20200723\" /> GPT-3, which was introduced in May 2020, and was in beta testing as of July 2020,<ref name=\"Medium_Bussler_20200721\">{{Cite web| last = Bussler| first = Frederik| title = Will GPT-3 Kill Coding?| work = Towards Data Science| access-date = August 1, 2020| date = July 21, 2020| url = https://towardsdatascience.com/will-gpt-3-kill-coding-630e4518c04d}}</ref> is part of a trend in [[natural language processing]] (NLP) systems of pre-trained language representations.<ref name=\"arXiv_Brown_20200722\" />\n\nThe quality of the text generated by GPT-3 is so high that it can be difficult to determine whether or not it was written by a human, which has both benefits and risks.<ref name=\"analyticsindiamag_Sagar_20200603\" /> Thirty-one OpenAI researchers and engineers presented the original May 28, 2020 paper introducing GPT-3. In their paper, they warned of GPT-3's potential dangers and called for research to mitigate risk.<ref name=\"arXiv_Brown_20200722\" />{{rp|34}} [[David Chalmers]], an Australian philosopher, described GPT-3 as \"one of the most interesting and important AI systems ever produced.\"<ref name=\"DailyNous_Weinberg_Chalmer_20200730\" /> An April 2022 review in ''The New York Times'' described GPT-3's capabilities as being able to write original prose with fluency equivalent to that of a human.<ref name=\"Johnson April 2022\">{{cite web |last1=Johnson |first1=Steven |last2=Iziev |first2=Nikita |date=15 April 2022 |title=A.I. Is Mastering Language. Should We Trust What It Says? |url=https://www.nytimes.com/2022/04/15/magazine/ai-language.html |website=The New York Times}}</ref>\n\n[[Microsoft]] announced on September 22, 2020 that it had licensed \"exclusive\" use of GPT-3; others can still use the public API to receive output, but only Microsoft has access to GPT-3's underlying model.<ref name=\"MSgotcode\">{{Cite magazine |title=OpenAI is giving Microsoft exclusive access to its GPT-3 language model |url=https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-model/ |date=September 23, 2020 |last=Hao |first=Karen |access-date=2020-09-25 |magazine=[[MIT Technology Review]] |language=en |quote=\"The companies say OpenAI will continue to offer its public-facing [[API]], which allows chosen users to send text to GPT-3 or OpenAI's other models and receive its output. Only Microsoft, however, will have access to GPT-3's underlying code, allowing it to embed, repurpose, and modify the model as it pleases.\"}}</ref>\n\n== Background ==\n{{further|GPT-2#Background}}\nAccording to ''[[The Economist]]'', improved algorithms, powerful computers, and an increase in digitized data have fueled a revolution in [[machine learning]], with new techniques in the 2010s resulting in \"rapid improvements in tasks\" including manipulating language.<ref name=\"theeconomist_20200611\">{{Cite news| issn = 0013-0613| title = An understanding of AI's limitations is starting to sink in| newspaper = The Economist|date=June 11, 2020| access-date = July 31, 2020| url = https://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in}}</ref> Software models are trained to learn by using thousands or millions of examples in a \"structure{{nbsp}}... loosely based on the neural architecture of the brain\".<ref name=\"theeconomist_20200611\" /> One architecture used in [[natural language processing]] (NLP) is a [[artificial neural network|neural network]] based on a [[deep learning]] model that was first introduced in 2017\u2014the [[Transformer (machine learning model)|Transformer]].<ref name=\"Polosukhin_2017\">{{cite arXiv|last1=Polosukhin|first1=Illia|last2=Kaiser|first2=Lukasz|last3=Gomez|first3=Aidan N.|last4=Jones|first4=Llion|last5=Uszkoreit|first5=Jakob|last6=Parmar|first6=Niki|last7=Shazeer|first7=Noam|last8=Vaswani|first8=Ashish|date=2017-06-12|title=Attention Is All You Need|eprint=1706.03762|class=cs.CL}}</ref> GPT-n models are based on this Transformer-based deep learning neural network architecture. There are a number of NLP systems capable of processing, mining, organizing, connecting and contrasting textual input, as well as correctly answering questions.<ref name=\"thomsonreuters_nd\">{{Cite web| title = Natural Language Processing| access-date = 2020-07-31| url = https://www.thomsonreuters.com/en/artificial-intelligence/natural-language-processing.html}}</ref>\n\nOn June 11, 2018, OpenAI researchers and engineers posted their original paper on [[generative model]]s\u2014language models\u2014artificial intelligence systems\u2014that could be pre-trained with an enormous and diverse [[Text corpus|corpus of text]] via [[Dataset (machine learning)|datasets]], in a process they called [[generative pre-training]] (GP).<ref name=\"OpenAI_Radford_20200611\">{{Cite web| pages = 12| access-date = July 31, 2020| date = June 11, 2018| last1 = Radford| first1 = Alec| last2 = Narasimhan| first2 = Karthik| last3 = Salimans| first3 = Tim| last4 = Sutskever| first4 = Ilya| title = Improving Language Understanding by Generative Pre-Training |url=https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf }}</ref> The authors described how language understanding performances in natural language processing (NLP) were improved in GPT-n through a process of \"generative pre-training of a language model on a diverse corpus of unlabeled text, followed by [[Discriminative model|discriminative]] fine-tuning on each specific task.\" This [[Unsupervised learning|eliminated the need for human supervision]] and for time-intensive hand-labeling.<ref name=\"OpenAI_Radford_20200611\" />\n\nIn February 2020, Microsoft introduced its Turing Natural Language Generation (T-NLG), which was claimed to be the \"largest language model ever published at 17 billion parameters.\"<ref name=\"Wired_Sterling_20200213\">{{Cite magazine| issn = 1059-1028| last = Sterling| first = Bruce| title = Web Semantics: Microsoft Project Turing introduces Turing Natural Language Generation (T-NLG)| magazine = Wired| access-date = July 31, 2020| date = February 13, 2020| url = https://www.wired.com/beyond-the-beyond/2020/02/web-semantics-microsoft-project-turing-introduces-turing-natural-language-generation-t-nlg/}}</ref> It performed better than any other language model at a variety of tasks which included [[Automatic summarization|summarizing texts]] and [[question answering|answering questions]].\n\n== Training and capabilities ==\n\nOn May 28, 2020, an [[arXiv]] preprint by a group of 31 engineers and researchers at OpenAI described the development of GPT-3, a third-generation \"state-of-the-art language model\".<ref name=\"arXiv_Brown_20200722\" /><ref name=\"analyticsindiamag_Sagar_20200603\">{{Cite magazine| last = Sagar| first = Ram| title = OpenAI Releases GPT-3, The Largest Model So Far| magazine = Analytics India Magazine| access-date = July 31, 2020| date = June 3, 2020| url = https://analyticsindiamag.com/open-ai-gpt-3-language-model/}}</ref> The team increased the capacity of GPT-3 by over two orders of magnitude from that of its predecessor, GPT-2,<ref name=\"gpt2-with-quote\">{{cite web |title=Language Models are Unsupervised Multitask Learners |url=https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf |access-date=December 4, 2019|quote=\"GPT-2, is a 1.5B parameter Transformer\" |website=openai.com}}</ref> making GPT-3 the largest non-sparse language model to date. (In a sparse model, many of its [[Parameter#Artificial_Intelligence|parameters]] are set to a constant value, so even if there are more total parameters, there is less meaningful information.)<ref name=\"arXiv_Brown_20200722\">{{cite arXiv|eprint=2005.14165|class=cs.CL|first1=Tom B.|last1=Brown|first2=Benjamin|last2=Mann|title=Language Models are Few-Shot Learners|date=July 22, 2020|last3=Ryder|last25=Chess|last20=Hesse|first20=Christopher|last21=Chen|first21=Mark|last22=Sigler|first22=Eric|last23=Litwin|first23=Mateusz|last24=Gray|first24=Scott|first26=Jack|first25=Benjamin|last26=Clark|last19=Winter|last27=Berner|first27=Christopher|last28=McCandlish|first28=Sam|last29=Radford|first29=Alec|last30=Sutskever|first30=Ilya|last31=Amodei|first31=Dario|first19=Clemens|first18=Jeffrey|first3=Nick|last10=Askell|last4=Subbiah|first4=Melanie|last5=Kaplan|first5=Jared|last6=Dhariwal|first6=Prafulla|last7=Neelakantan|first7=Arvind|last8=Shyam|first8=Pranav|last9=Sastry|first9=Girish|first10=Amanda|last18=Wu|last11=Agarwal|first11=Sandhini|last12=Herbert-Voss|first12=Ariel|last13=Krueger|first13=Gretchen|last14=Henighan|first14=Tom|last15=Child|first15=Rewon|last16=Ramesh|first16=Aditya|last17=Ziegler|first17=Daniel M.}}</ref>{{rp|14|quote=\"Since we increase the capacity by over two orders of magnitude from GPT-2 to GPT-3\"}}<ref name=\"CNBC_Shead_20200723\">{{Cite news| last = Shead| first = Sam| title = Why everyone is talking about the A.I. text generator released by an Elon Musk-backed lab| work = CNBC| access-date = July 31, 2020| date = July 23, 2020| url = https://www.cnbc.com/2020/07/23/openai-gpt3-explainer.html}} Four preprints were released between May 28 and July 22, 2020.</ref> Because GPT-3 is structurally similar to its predecessors,<ref name=\"arXiv_Brown_20200722\" /> its greater accuracy is attributed to its increased capacity and greater number of parameters.<ref name=\"ZDNet_Tiernan_20200601\">{{Cite web| last = Ray| first = Tiernan |date= June 1, 2020 | title = OpenAI's gigantic GPT-3 hints at the limits of language models for AI| work = ZDNet| access-date = July 31, 2020| url = https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/}}</ref> GPT-3's capacity is ten times larger than that of Microsoft's Turing NLG, the next largest NLP model known at the time.<ref name=\"analyticsindiamag_Sagar_20200603\" />\n\nSixty percent of the weighted pre-training dataset for GPT-3 comes from a filtered version of [[Common Crawl]] consisting of 410 billion [[Byte pair encoding|byte-pair-encoded]] tokens.<ref name=\"arXiv_Brown_20200722\" />{{rp|9}} Other sources are 19 billion tokens from WebText2 representing 22% of the weighted total, 12 billion tokens from Books1 representing 8%, 55 billion tokens from Books2 representing 8%, and 3 billion tokens from Wikipedia representing 3%.<ref name=\"arXiv_Brown_20200722\" />{{rp|9}} GPT-3 was trained on hundreds of billions of words and is also capable of coding in CSS, JSX, and Python, among others.<ref name=\"Medium_Bussler_20200721\" />\n\n{| class=\"wikitable\"\n|+ GPT-3 training data\n|-\n! Dataset !! # Tokens !! Weight in training mix\n|-\n| [[Common Crawl]]\n| style=\"text-align:right; padding-left: 2em; padding-right: 2em;\" | 410 billion\n| style=\"text-align:right; padding-right: 4em;\" | 60%\n|-\n| WebText2\n| style=\"text-align:right; padding-right: 2em;\" | 19 billion\n| style=\"text-align:right; padding-right: 4em;\" | 22%\n|-\n| Books1\n| style=\"text-align:right; padding-right: 2em;\" | 12 billion\n| style=\"text-align:right; padding-right: 4em;\" | 8%\n|-\n| Books2\n| style=\"text-align:right; padding-right: 2em;\" | 55 billion\n| style=\"text-align:right; padding-right: 4em;\" | 8%\n|-\n| Wikipedia\n| style=\"text-align:right; padding-right: 2em;\" | 3 billion\n| style=\"text-align:right; padding-right: 4em;\" | 3%\n|}\n\nSince GPT-3's training data was all-encompassing, it does not require further training for distinct language tasks.<ref name=\"Medium_Bussler_20200721\" /> The training data contains occasional toxic language and GPT-3 occasionally generates toxic language as a result of mimicking its training data. A study from the University of Washington found that GPT-3 produced toxic language at a toxicity level comparable to the similar natural language processing models of [[GPT-2]] and CTRL. GPT-3 produced less toxic language compared to its predecessor model, GPT-1, although it produced both more generations and a higher toxicity of toxic language compared to CTRL Wiki, a language model trained entirely on Wikipedia data.<ref>{{Citation | first1 = Samuel | last1 = Gehman | first2 = Suchin | last2 = Gururangan | first3 = Maarten | last3 = Sap | first4 = Yejin | last4 = Choi | first5 = Noah A. | last5 = Smith  | title = REALTOXICITYPROMPTS: Evaluating Neural Toxic Degeneration in Language Models | pages = 3356\u20133369 | publisher = Association for Computational Linguistics | date = 16\u201320 November 2020 | arxiv = 2009.11462 | url = https://arxiv.org/abs/2009.11462 | access-date = June 2, 2021}}</ref>\n\nOn June 11, 2020, [[OpenAI]] announced that users could request access to its user-friendly GPT-3 API\u2014a \"machine learning toolset\"\u2014to help OpenAI \"explore the strengths and limits\" of this new technology.<ref name=\"OpenAI_20200611\">{{cite web |url=https://openai.com/blog/openai-api/ |date=June 11, 2020 |work=OpenAI |title=OpenAI API}}</ref><ref name=\"techcrunch_20200601\">{{Cite web |title=OpenAI makes an all-purpose API for its text-based AI capabilities |work=TechCrunch |date=June 11, 2020 |access-date=July 31, 2020 |url= https://techcrunch.com/2020/06/11/openai-makes-an-all-purpose-api-for-its-text-based-ai-capabilities/ |quote=If you've ever wanted to try out OpenAI's vaunted machine learning toolset, it just got a lot easier. The company has released an API that lets developers call its AI tools in on \"virtually any English language task.\" |last=Coldewey|first=Devin|archive-url=https://web.archive.org/web/20211027000059/https://techcrunch.com/2020/06/11/openai-makes-an-all-purpose-api-for-its-text-based-ai-capabilities/|archive-date=October 27, 2021|url-status=live}}</ref> The invitation described how this API had a general-purpose \"text in, text out\" interface that can complete almost \"any English language task\", instead of the usual single use-case.<ref name=\"OpenAI_20200611\" /> According to one user, who had access to a private early release of the OpenAI GPT-3 API, GPT-3 was \"eerily good\" at writing \"amazingly coherent text\" with only a few simple prompts.<ref name=\"Arram_20200709\">{{Cite web| last = Arram| title = GPT-3: An AI that's eerily good at writing almost anything| work = Arram Sabeti| access-date = July 31, 2020| date = July 9, 2020| url = https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/}}</ref> In an initial experiment 80 US subjects were asked to judge if short ~200 word articles were written by humans or GPT-3. The participants judged correctly 52% of the time, doing only slightly better than random guessing.<ref name=\"arXiv_Brown_20200722\" />\n\nOn November 18, 2021, OpenAI announced that enough safeguards had been implemented that access to its API would be unrestricted.<ref>{{Cite web |date=2021-11-18 |title=OpenAI's API Now Available with No Waitlist |url=https://openai.com/blog/api-no-waitlist/ |access-date=2022-11-05 |website=OpenAI |language=en}}</ref> OpenAI provided developers with a content moderation tool that helps them abide by OpenAI's content policy.<ref>{{Cite web |title=OpenAI API |url=https://beta.openai.com/ |access-date=2022-11-05 |website=beta.openai.com |language=en}}</ref> On January 27, 2022, OpenAI announced that its newest GPT-3 language models, collectively referred to as InstructGPT, was now the default language model used on their [[API]]. According to OpenAI, InstructGPT produced content that was better aligned to user intentions by following instructions better, generating fewer made-up facts, and producing somewhat less toxic content.<ref>{{Cite web |date=2022-01-27 |title=Aligning Language Models to Follow Instructions |url=https://openai.com/blog/instruction-following/ |access-date=2022-11-05 |website=OpenAI |language=en}}</ref>\n\nBecause GPT-3 can \"generate news articles which human evaluators have difficulty distinguishing from articles written by humans,\"<ref name=\"analyticsindiamag_Sagar_20200603\" /> GPT-3 has the \"potential to advance both the beneficial and harmful applications of language models.\"<ref name=\"arXiv_Brown_20200722\" />{{rp|34}} In their May 28, 2020 paper, the researchers described in detail the potential \"harmful effects of GPT-3\"<ref name=\"analyticsindiamag_Sagar_20200603\" /> which include \"misinformation, [[Spamming|spam]], [[phishing]], [[Abuse of process|abuse of legal and governmental processes]], [[Academic dishonesty|fraudulent academic essay]] writing and social engineering [[pretexting]]\".<ref name=\"arXiv_Brown_20200722\" /> The authors draw attention to these dangers to call for research on [[Risk management|risk mitigation]].<ref name=\"arXiv_Brown_20200722\" /><ref>{{Cite arXiv|eprint = 2005.14165|last1 = Brown|first1 = Tom B.|last2 = Mann|first2 = Benjamin|last3 = Ryder|first3 = Nick|last4 = Subbiah|first4 = Melanie|last5 = Kaplan|first5 = Jared|last6 = Dhariwal|first6 = Prafulla|last7 = Neelakantan|first7 = Arvind|last8 = Shyam|first8 = Pranav|last9 = Sastry|first9 = Girish|last10 = Askell|first10 = Amanda|last11 = Agarwal|first11 = Sandhini|last12 = Herbert-Voss|first12 = Ariel|last13 = Krueger|first13 = Gretchen|last14 = Henighan|first14 = Tom|last15 = Child|first15 = Rewon|last16 = Ramesh|first16 = Aditya|last17 = Ziegler|first17 = Daniel M.|last18 = Wu|first18 = Jeffrey|last19 = Winter|first19 = Clemens|last20 = Hesse|first20 = Christopher|last21 = Chen|first21 = Mark|last22 = Sigler|first22 = Eric|last23 = Litwin|first23 = Mateusz|last24 = Gray|first24 = Scott|last25 = Chess|first25 = Benjamin|last26 = Clark|first26 = Jack|last27 = Berner|first27 = Christopher|last28 = McCandlish|first28 = Sam|last29 = Radford|first29 = Alec|last30 = Sutskever|first30 = Ilya|title = Language Models are Few-Shot Learners|year = 2020| class=cs.CL |display-authors = 1}}</ref>{{rp|34}}\n\nGPT-3 is capable of performing [[Zero-shot learning|zero-shot]], few-shot and [[One-shot learning (software)|one-shot learning]].<ref name=\"arXiv_Brown_20200722\" />\n\nIn June 2022, Almira Osmanovic Thunstr\u00f6m wrote that GPT-3 was the primary author on an article on itself, that they had submitted it for publication,<ref name=\"Thunstr\u00f6m 2022\">{{cite web |last=Thunstr\u00f6m |first=Almira Osmanovic |title=We Asked GPT-3 to Write an Academic Paper about Itself\u2014Then We Tried to Get It Published |website=Scientific American |date=2022-06-30 |url=https://www.scientificamerican.com/article/we-asked-gpt-3-to-write-an-academic-paper-about-itself-then-we-tried-to-get-it-published/ |access-date=2022-06-30}}</ref> and that it had been pre-published while waiting for completion of its review.<ref name=\"Transformer Thunstr\u00f6m Steingrimsson 2022\">{{cite web |last1=Transformer |first1=Gpt Generative Pretrained |last2=Thunstr\u00f6m |first2=Almira Osmanovic |last3=Steingrimsson |first3=Steinn |title=Can GPT-3 write an academic paper on itself, with minimal human input? |website=Archive ouverte HAL |date=2022-06-21 |url=https://hal.archives-ouvertes.fr/hal-03701250 |language=fr |access-date=2022-06-30}}</ref>\n\n== Reception ==\n=== Applications ===\n* GPT-3, specifically the [[OpenAI Codex|Codex model]], is the basis for [[GitHub Copilot]], a code completion and generation software that can be used in various code editors and IDEs.<ref>{{cite web |title=OpenAI Codex |url=https://openai.com/blog/openai-codex/ |website=OpenAI |access-date=23 December 2022 |language=en |date=10 August 2021}}</ref><ref>{{cite news |last1=Thompson |first1=Clive |title=How an AI Became My Code-Writing Genie |url=https://www.wired.com/story/openai-copilot-autocomplete-for-code/ |access-date=23 December 2022 |work=Wired |date=15 March 2022}}</ref>\n* GPT-3 is used in certain Microsoft products to translate conventional language into formal computer code.<ref>{{Cite web|url=https://blogs.microsoft.com/ai/from-conversation-to-code-microsoft-introduces-its-first-product-features-powered-by-gpt-3/|title=Microsoft announced its first customer product features powered by GPT-3 and @Azure.|date=May 25, 2021|website=The AI Blog}}</ref><ref>{{cite news |last1=Vincent |first1=James |title=Microsoft has built an AI-powered autocomplete for code using GPT-3 |url=https://www.theverge.com/2021/5/25/22451144/microsoft-gpt-3-openai-coding-autocomplete-powerapps-power-fx |access-date=23 December 2022 |work=The Verge |date=25 May 2021}}</ref>\n* GPT-3 has been used in CodexDB<ref>{{Cite web|url=https://itrummer.github.io/CodexDB/|title=CodexDB - SQL Processing Powered by GPT-3|website=CodexDB - SQL Processing Powered by GPT-3}}</ref> to generate query-specific code for SQL processing.\n* GPT-3 has been used by [[Jason Rohrer]] in a retro-themed chatbot project named \"Project December\", which is accessible online and allows users to converse with several AIs using GPT-3 technology.<ref>{{cite news|first=Jason|last=Fagone|author-link=Jason Fagone|title=The Jessica Simulation: Love and loss in the age of A.I.|url=https://www.sfchronicle.com/projects/2021/jessica-simulation-artificial-intelligence/|work=[[San Francisco Chronicle]]|date=July 23, 2021|access-date=July 29, 2021}}</ref>\n* GPT-3 was used by ''[[The Guardian]]'' to write an article about AI being harmless to human beings. It was fed some ideas and produced eight different essays, which were ultimately merged into one article.<ref>{{Cite news|last=GPT-3|date=2020-09-08|title=A robot wrote this entire article. Are you scared yet, human? {{!}} GPT-3|work=The Guardian|url=https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3|access-date=2020-09-15|issn=0261-3077}}</ref>\n* GPT-3 was used in ''[[AI Dungeon]]'', which generates text-based adventure games. Later it was replaced by a competing model after OpenAI changed their policy regarding generated content.<ref>{{Cite web |date=2021-12-08 |title=Update: Language Models and Dragon |url=https://latitude.io/blog/update-language-models |website=Latitude blog}}</ref><ref>{{cite news |title=This Mystical Book Was Co-Authored by a Disturbingly Realistic AI |url=https://www.vice.com/en/article/7kbjvb/this-magickal-grimoire-was-co-authored-by-a-disturbingly-realistic-ai |access-date=23 December 2022 |work=www.vice.com |date=2022 |language=en}}</ref>\n* GPT-3 is used in Copy.ai, an AI copywriting app for marketers and business owners.<ref>{{Cite web |title=Writing helper Copy.ai raises $2.9M in a round led by Craft Ventures| url=https://techcrunch.com/2021/03/17/gpt-3-powered-copy-ai-raises-2-9m-in-a-round-led-by-craft-ventures/ |access-date=2022-11-05 |website=copy.ai| date=March 17, 2021 }}</ref>\n* GPT-3 is used in Jasper.ai, a content generator designed to assist marketers and copyeditors.<ref>{{Cite web |title=Jasper Announces $125M Series A Funding Round, Bringing Total Valuation to $1.5B and Launches New Browser Extension |url=https://www.jasper.ai/blog/jasper-announces-125m-series-a-funding |access-date=2022-11-05 |website=www.jasper.ai}}</ref><ref>{{cite news |last1=Dzieza |first1=Josh |title=Can AI write good novels? |url=https://www.theverge.com/c/23194235/ai-fiction-writing-amazon-kindle-sudowrite-jasper |access-date=23 December 2022 |work=The Verge |date=20 July 2022}}</ref>\n* A 2022 [[Drexel University]] study suggested that systems based on GPT-3 could be used to screen for early signs of [[Alzheimer's disease]].<ref>{{cite news |title=Can ChatGPT AI chatbot spot early stages of Alzheimer's? - study |url=https://www.jpost.com/health-and-wellness/mind-and-spirit/article-725929 |access-date=30 December 2022 |work=The Jerusalem Post |date=2022}}</ref><ref>{{cite journal |last1=Agbavor |first1=Felix |last2=Liang |first2=Hualou |title=Predicting dementia from spontaneous speech using large language models |journal=PLOS Digital Health |date=22 December 2022 |volume=1 |issue=12 |pages=e0000168 |doi=10.1371/journal.pdig.0000168}}</ref>\n\n=== Reviews ===\n* In a July 2020 review in ''[[The New York Times]]'', [[Farhad Manjoo]] said that GPT-3's ability to generate computer code, poetry, and prose is not just \"amazing\", \"spooky\", and \"humbling\", but also \"more than a little terrifying\".<ref name=\"NYT_Farhad_20190515\">{{Cite news| issn = 0362-4331|first=Farhad |last=Manjoo| title = How Do You Know a Human Wrote This?| work = [[The New York Times]]| access-date = August 4, 2020| date = July 29, 2020| url = https://www.nytimes.com/2020/07/29/opinion/gpt-3-ai-automation.html?}}</ref>\n* ''Daily Nous'' presented a series of articles by nine philosophers on GPT-3.<ref name=\"DailyNous_Weinberg_20200730\">{{Cite web| editor-last = Weinberg| editor-first = Justin| title = Philosophers On GPT-3 (updated with replies by GPT-3)| work = Daily Nous| access-date = July 31, 2020| date = July 30, 2020|url=http://dailynous.com/2020/07/30/philosophers-gpt-3/}}</ref> Australian philosopher [[David Chalmers]] described GPT-3 as \"one of the most interesting and important AI systems ever produced\".<ref name=\"DailyNous_Weinberg_Chalmer_20200730\">{{Cite news |first=David |last=Chalmers |author-link=David Chalmers |editor-last = Weinberg |editor-first = Justin |title =GPT-3 and General Intelligence |series= Philosophers On GPT-3 (updated with replies by GPT-3)| work = Daily Nous| access-date = August 4, 2020| date = July 30, 2020| url = https://dailynous.com/2020/07/30/philosophers-gpt-3/#chalmers}}</ref>\n* A review in ''[[Wired (magazine)|Wired]]'' said that GPT-3 was \"provoking chills across [[Silicon Valley]]\".<ref name=\"Wired_Simonite_20200722\">{{Cite magazine| issn = 1059-1028| title = Did a Person Write This Headline, or a Machine?|first=Tom |last=Simonite| magazine = [[Wired (magazine)|Wired]]| access-date = July 31, 2020 |date=July 22, 2020| url = https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/}}</ref>\n* The ''[[National Law Review]]'' said that GPT-3 is an \"impressive step in the larger process\", with OpenAI and others finding \"useful applications for all of this power\" while continuing to \"work toward a more [[Artificial general intelligence|general]] intelligence\".<ref name=\"NTR_20200730\">{{Cite web |first=Theodore |last=Claypoole |title = New AI Tool GPT-3 Ascends to New Peaks, But Proves How Far We Still Need to Travel |work = [[The National Law Review]] |date= July 30, 2020| access-date = August 4, 2020|volume=10 |number=214| url = https://www.natlawreview.com/article/new-ai-tool-gpt-3-ascends-to-new-peaks-proves-how-far-we-still-need-to-travel}}</ref>\n* An article in the ''[[MIT Technology Review]],'' cowritten by Deep Learning critic [[Gary Marcus]],<ref>{{Cite web|last=Marcus|first=Gary|date=2018-12-01|title=The deepest problem with deep learning|url=https://medium.com/@GaryMarcus/the-deepest-problem-with-deep-learning-91c5991f5695|access-date=2020-09-29|website=Medium|language=en}}</ref> stated that GPT-3's \"comprehension of the world is often seriously off, which means you can never really trust what it says.\"<ref name=\"Marcus_Davis_2020\">{{cite magazine |last1=Marcus |first1=Gary |last2=Davis |first2=Ernest |url=https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion |title=GPT-3, Bloviator: OpenAI's language generator has no idea what it's talking about |date=August 22, 2020 |magazine=[[MIT Technology Review]] |access-date=August 23, 2020}}</ref> According to the authors, GPT-3 models relationships between words without having an understanding of the meaning behind each word.\n* Jerome Pesenti, head of the Facebook AI lab, said GPT-3 is \"unsafe,\" pointing to the [[sexist]], [[racist]] and other biased and negative language generated by the system when it was asked to discuss Jews, women, black people, and the [[Holocaust]].<ref>{{Cite news|last=Metz|first=Cade|date=2020-11-24|title=Meet GPT-3. It Has Learned to Code (and Blog and Argue).|language=en-US|work=The New York Times|url=https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html|access-date=2020-11-24|issn=0362-4331}}</ref>\n* Nabla, a French start-up specializing in healthcare technology, tested GPT-3 as a medical [[chatbot]], though OpenAI itself warned against such use. As expected, GPT-3 showed several limitations. For example, while testing GPT-3 responses about mental health issues, the AI advised a simulated patient to commit suicide.<ref>{{Cite web|date=2020-10-28|title=Medical chatbot using OpenAI's GPT-3 told a fake patient to kill themselves|url=https://artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/|access-date=2021-01-08|website=AI News|language=en-GB}}</ref>\n* [[Noam Chomsky]] expressed his skepticism about GPT-3's scientific value: \"It's not a language model. It works just as well for impossible languages as for actual languages. It is therefore refuted, if intended as a language model, by normal scientific criteria. [...] Perhaps it's useful for some purpose, but it seems to tell us nothing about language or cognition generally.\"<ref>{{cite AV media|url=https://www.youtube.com/watch?v=c6MU5zQwtT4|title=Chomsky on Terence McKenna, Sam Harris, GPT3, Cryptocurrencies, Kierkegaard, Neuralink, & Hofstadter|date=2021-03-24|time=1:11:44}}</ref>\n* [[Luciano Floridi]] and [[Massimo Chiriatti]] highlighted the risk of \"cheap production of good, semantic artefacts\".<ref>{{Cite journal| last1=Floridi |first1=Luciano |last2=Chiriatti |first2=Massimo |date=1 November 2020 |title=GPT\u20113: Its Nature, Scope, Limits, and Consequences |url=https://link.springer.com/article/10.1007/s11023-020-09548-1 |journal=Minds and Machines |volume= 30 |issue=4 |pages= 681\u2013694  |doi= 10.1007/s11023-020-09548-1|s2cid=228954221 }}</ref>\n\nOpenAI's Sam Altman himself criticized what he called \"GPT-3 hype\", acknowledging GPT-3 \"has serious weakness and sometimes makes very silly mistakes... AI is going to change the world, but GPT-3 is just a very early glimpse.\"<ref>{{cite news |last1=Vincent |first1=James |title=OpenAI's latest breakthrough is astonishingly powerful, but still fighting its flaws |url=https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential |access-date=9 November 2022 |work=The Verge |date=30 July 2020}}</ref>\n\n=== Criticism ===\nGPT-3's builder, [[OpenAI]], was initially founded as a non-profit in 2015.<ref>{{cite news |first= Drew |last= Olanoff |title= Artificial Intelligence Nonprofit OpenAI Launches With Backing From Elon Musk And Sam Altman |url= https://techcrunch.com/2015/12/11/non-profit-openai-launches-with-backing-from-elon-musk-and-sam-altman/ |publisher= Tech Crunch |date= 11 December 2015 |accessdate=31 May 2021 }}</ref> In 2019, OpenAI did not publicly release GPT-3's precursor model, breaking from OpenAI's previous open-source practices, citing concerns that the model would perpetuate fake news. OpenAI eventually released a version of [[GPT-2]] that was 8% of the original model's size.<ref>{{cite news |first= Karen |last= Hao |title= OpenAI has released the largest version yet of its fake-news-spewing AI |url= https://www.technologyreview.com/2019/08/29/133218/openai-released-its-fake-news-ai-gpt-2/ |publisher= MIT Technology Review |date= 29 August 2019 |accessdate=31 May 2021 }}</ref> In the same year, OpenAI restructured to be a for-profit company.<ref>{{cite news |first= Devin |last= Coldewey |title= OpenAI shifts from nonprofit to 'capped-profit' to attract capital |url= https://techcrunch.com/2019/03/11/openai-shifts-from-nonprofit-to-capped-profit-to-attract-capital/ |publisher= Tech Crunch |date= 11 Mar 2019 |accessdate=31 May 2021 }}</ref> In 2020, Microsoft announced the company had exclusive licensing of GPT-3 for Microsoft's products and services following a multi-billion dollar investment in OpenAI. The agreement permits OpenAI to offer a public-facing API such that users can send text to GPT-3 to receive the model's output, but only Microsoft will have access to GPT-3's source code.<ref name=\"MSgotcode\" />\n\nLarge language models, such as GPT-3, have come under criticism from Google's AI ethics researchers for the environmental impact of training and storing the models, detailed in a paper co-authored by [[Timnit Gebru]] and [[Emily M. Bender]] in 2021.<ref>{{cite conference|last1=Bender|first1=Emily M.|last2=Gebru|first2=Timnit|last3=McMillan-Major|first3=Angelina|last4=Shmitchell|first4=Shmargaret|date=2021-03-03|title=On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?|conference=|publisher=FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency|pages=610\u2013623|doi=10.1145/3442188.3445922|doi-access=free}}</ref>\n\nThe growing{{When|date=December 2022}} use of automated writing technologies based on GPT-3 and other language generators, has raised concerns regarding academic integrity<ref>{{Cite news|last1=Mindzak|first1=Michael|last2=Eaton|first2=Sarah Elaine|title=Artificial intelligence is getting better at writing, and universities should worry about plagiarism|url=http://theconversation.com/artificial-intelligence-is-getting-better-at-writing-and-universities-should-worry-about-plagiarism-160481|access-date=2021-11-06|website=The Conversation|language=en}}</ref> and raised the stakes of how universities and schools will gauge what constitutes academic misconduct such as plagiarism.<ref>{{Cite journal|last1=Rogerson|first1=Ann M.|last2=McCarthy|first2=Grace|date=December 2017|title=Using Internet based paraphrasing tools: Original work, patchwriting or facilitated plagiarism?|url=https://edintegrity.biomedcentral.com/articles/10.1007/s40979-016-0013-y|journal=International Journal for Educational Integrity|language=en|volume=13|issue=1|pages=1\u201315|doi=10.1007/s40979-016-0013-y|s2cid=9473217|issn=1833-2595}}</ref>\n\nGPT was built with data from the [[Common Crawl]] dataset, a conglomerate of copyrighted articles, internet posts, web pages, and books scraped from 60 million domains over a period of 12 years. ''TechCrunch'' reports this training data includes copyrighted material from the BBC, ''The New York Times'', [[Reddit]], the full text of online books, and more.<ref>{{cite conference|title=Here are a few ways GPT-3 can go wrong|work=TechCrunch|url=https://techcrunch.com/2020/08/07/here-are-a-few-ways-gpt-3-can-go-wrong/}}</ref> In its response to a 2019 Request for Comments on Intellectual Property Protection for Artificial Intelligence Innovation from the United States Patent and Trademark Office (\"USPTO\"), OpenAI argued that \"Under current law, training AI systems [such as its GPT models] constitutes [[fair use]],\" but that \"given the lack of [[case law]] on point, OpenAI and other AI developers like us face substantial legal uncertainty and compliance costs.\"<ref>{{cite conference |title=Comment Regarding Request for Comments on Intellectual Property Protection for Artificial Intelligence Innovation |url=https://www.uspto.gov/sites/default/files/documents/OpenAI_RFC-84-FR-58141.pdf |publisher=USPTO}}</ref>\n\n== See also ==\n* [[BERT (language model)]]\n* [[LaMDA]]\n* [[Natural language processing]]\n* [[Wu Dao]]\n* [[ChatGPT]]\n\n== References ==\n{{reflist|30em}}\n\n{{Differentiable computing}}\n{{Existential risk from artificial intelligence}}\n\n[[Category:Language modeling]]\n[[Category:Deep learning software applications]]\n[[Category:Unsupervised learning]]\n[[Category:OpenAI]]"}