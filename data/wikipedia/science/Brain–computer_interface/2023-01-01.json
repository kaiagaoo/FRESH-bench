{"title": "Brain\u2013computer interface", "page_id": 623686, "revision_id": 1130298284, "revision_timestamp": "2022-12-29T14:10:52Z", "content": "{{merge from| Brain technology|discuss=Talk:Brain\u2013computer interface#Merger proposal|date=September 2022}}\n{{for|direct brain control of prosthetic devices|Neuroprosthetics}}\n{{Use dmy dates|date=December 2022}}\n{{Short description|Direct communication pathway between an enhanced or wired brain and an external device}}\n{{Neuropsychology}}\nA '''brain\u2013computer interface''' ('''BCI'''), sometimes called a '''brain\u2013machine interface''' ('''BMI''') or '''smartbrain''', is a direct communication pathway between the [[brain|brain's]] electrical activity and an external device, most commonly a computer or robotic limb. BCIs are often directed at researching, [[Brain mapping|mapping]], assisting, [[Augmented cognition|augmenting]], or repairing human [[Cognitive skill|cognitive]] or [[Sensory-motor coupling|sensory-motor functions]].<ref name=\"Krucoff 584\">{{cite journal | vauthors = Krucoff MO, Rahimpour S, Slutzky MW, Edgerton VR, Turner DA | title = Enhancing Nervous System Recovery through Neurobiologics, Neural Interface Training, and Neurorehabilitation | journal = Frontiers in Neuroscience | volume = 10 | page = 584 |year=2016 | pmid = 28082858 | pmc = 5186786 | doi = 10.3389/fnins.2016.00584 | doi-access = free }}</ref> Implementations of BCIs range from non-invasive ([[Electroencephalography|EEG]], [[Magnetoencephalography|MEG]], [[Electrooculography|EOG]], [[Magnetic resonance imaging|MRI]]) and partially invasive ([[Electrocorticography|ECoG]] and endovascular) to invasive ([[microelectrode array]]), based on how close electrodes get to brain tissue.<ref name=\":7\">Michael L Martini, BA, Eric Karl Oermann, MD, Nicholas L Opie, PhD, Fedor Panov, MD, Thomas Oxley, MD, PhD, Kurt Yaeger, MD, Sensor Modalities for Brain-Computer Interface Technology: A Comprehensive Literature Review, Neurosurgery, Volume 86, Issue 2, February 2020, Pages E108\u2013E117, [https://doi.org/10.1093/neuros/nyz286]</ref>\n\nResearch on BCIs began in the 1970s by Jacques Vidal at the [[University of California, Los Angeles]] (UCLA) under a grant from the [[National Science Foundation]], followed by a contract from [[DARPA]].<ref name=\"Vidal1\">{{cite journal | vauthors = Vidal JJ | title = Toward direct brain-computer communication | journal = Annual Review of Biophysics and Bioengineering | volume = 2 | issue = 1 | pages = 157\u2013180 | year = 1973 | pmid = 4583653 | doi = 10.1146/annurev.bb.02.060173.001105 }}</ref><ref name=\"Vidal2\">{{cite journal| vauthors = Vidal J |title=Real-Time Detection of Brain Events in EEG|journal= Proceedings of the IEEE|year=1977|volume=65|pages=633\u2013641|doi=10.1109/PROC.1977.10542|issue=5|s2cid=7928242}}</ref> The Vidal's 1973 paper marks the first appearance of the expression ''brain\u2013computer interface'' in scientific literature.\n\nDue to the [[neuroplasticity|cortical plasticity]] of the brain, signals from implanted [[Prosthesis|prostheses]] can, after adaptation, be handled by the brain like natural sensor or effector channels.<ref>{{cite journal | vauthors = Levine SP, Huggins JE, BeMent SL, Kushwaha RK, Schuh LA, Rohde MM, Passaro EA, Ross DA, Elisevich KV, Smith BJ | display-authors = 6 | title = A direct brain interface based on event-related potentials | journal = IEEE Transactions on Rehabilitation Engineering | volume = 8 | issue = 2 | pages = 180\u2013185 | date = June 2000 | pmid = 10896180 | doi = 10.1109/86.847809 }}</ref> Following years of animal experimentation, the first [[neuroprosthetic]] devices implanted in humans appeared in the mid-1990s.\n\nRecently, studies in [[human-computer interaction]] via the application of [[machine learning]] to statistical temporal features extracted from the [[frontal lobe]] ([[Electroencephalography|EEG brainwave]]) data has had high levels of success in autonomous recognition of fall detection as a [[medical alarm]],<ref>{{cite journal |last1=Bird |first1=Jordan J. |title=EEG Wavelet Classification for Fall Detection with Genetic Programming |journal=The15th International Conference on PErvasive Technologies Related to Assistive Environments |date=29 June 2022 |pages=376\u2013382 |doi=10.1145/3529190.3535339|isbn=9781450396318 |s2cid=250429410 }}</ref> [[mental state]] (Relaxed, Neutral, Concentrating),<ref>{{cite book | vauthors = Bird JJ, Manso LJ, Ribeiro EP, Ek\u00e1rt A, Faria DR |title=A Study on Mental State Classification using EEG-based Brain-Machine Interface |date=September 2018 |publisher=9th international Conference on Intelligent Systems 2018 |location=Madeira Island, Portugal |url=https://www.researchgate.net/publication/328615252 |access-date=3 December 2018 |ref=birdeegmentalstates}}</ref>  mental emotional state (Negative, Neutral, Positive),<ref>{{cite book | vauthors = Bird JJ, Ekart A, Buckingham CD, Faria DR |title=Mental Emotional Sentiment Classification with an EEG-based Brain-Machine Interface |date=2019 |publisher=The International Conference on Digital Image and Signal Processing (DISP'19) |location=St Hugh's College, University of Oxford, United Kingdom |url=https://www.disp-conference.org |access-date=3 December 2018 |ref=birdeegemotions |archive-url=https://web.archive.org/web/20181203202733/https://www.disp-conference.org/ |archive-date=3 December 2018 |url-status=dead }}</ref> and [[thalamocortical dysrhythmia]].<ref>{{cite journal | vauthors = Vanneste S, Song JJ, De Ridder D | title = Thalamocortical dysrhythmia detected by machine learning | language = En | journal = Nature Communications | volume = 9 | issue = 1 | pages = 1103 | date = March 2018 | pmid = 29549239 | pmc = 5856824 | doi = 10.1038/s41467-018-02820-0 | bibcode = 2018NatCo...9.1103V }}</ref>\n\n{{TOC limit|4}}\n\n==History==\nThe history of brain\u2013computer interfaces (BCIs) starts with [[Hans Berger]]'s discovery of the electrical activity of the human brain and the development of [[electroencephalography]] (EEG). In 1924 Berger was the first to record human brain activity by means of EEG. Berger was able to identify [[neural oscillation|oscillatory activity]], such as Berger's wave or the [[alpha wave]] (8\u201313&nbsp;Hz), by analyzing EEG traces.\n\nBerger's first recording device was very rudimentary. He inserted [[silver]] wires under the scalps of his patients. These were later replaced by silver foils attached to the patient's head by rubber bandages. Berger connected these sensors to a [[Lippmann electrometer|Lippmann capillary electrometer]], with disappointing results. However, more sophisticated measuring devices, such as the [[Siemens]] double-coil recording [[galvanometer]], which displayed electric voltages as small as one ten thousandth of a volt, led to success.\n\nBerger analyzed the interrelation of alternations in his EEG wave diagrams with [[Central nervous system disease|brain diseases]]. EEGs permitted completely new possibilities for the research of human brain activities.\n\nAlthough the term had not yet been coined, one of the earliest examples of a working brain-machine interface was the piece ''Music for Solo Performer'' (1965) by the American composer [[Alvin Lucier]]. The piece makes use of EEG and analog signal processing hardware (filters, amplifiers, and a mixing board) to stimulate acoustic percussion instruments. To perform the piece one must produce [[alpha waves]] and thereby \"play\" the various percussion instruments via loudspeakers which are placed near or directly on the instruments themselves.<ref>{{cite journal | vauthors = Straebel V, Thoben W | author-link1 = Volker Straebel |title = Alvin Lucier's music for solo performer: experimental music beyond sonification |url= https://depositonce.tu-berlin.de//handle/11303/7085|journal = Organised Sound |volume = 19 |issue =1 |year = 2014 |pages = 17\u201329|doi = 10.1017/S135577181300037X |s2cid = 62506825 }}</ref>\n\n[[UCLA]] Professor Jacques Vidal coined the term \"BCI\" and produced the first peer-reviewed publications on this topic.<ref name=\"Vidal1\"/><ref name=\"Vidal2\"/> Vidal is widely recognized as the inventor of BCIs in the BCI community, as reflected in numerous peer-reviewed articles reviewing and discussing the field (e.g.,<ref name=\"Wolpaw, J.R 2012\">Wolpaw, J.R. and Wolpaw, E.W. (2012). \"Brain-Computer Interfaces: Something New Under the Sun\". In: ''Brain-Computer Interfaces: Principles and Practice'', Wolpaw, J.R. and Wolpaw (eds.), E.W. Oxford University Press.</ref><ref>{{cite journal | vauthors = Wolpaw JR, Birbaumer N, McFarland DJ, Pfurtscheller G, Vaughan TM | title = Brain-computer interfaces for communication and control | journal = Clinical Neurophysiology | volume = 113 | issue = 6 | pages = 767\u2013791 | date = June 2002 | pmid = 12048038 | doi = 10.1016/s1388-2457(02)00057-3 | s2cid = 17571592 }}</ref><ref>{{cite journal | vauthors = Allison BZ, Wolpaw EW, Wolpaw JR | title = Brain-computer interface systems: progress and prospects | journal = Expert Review of Medical Devices | volume = 4 | issue = 4 | pages = 463\u2013474 | date = July 2007 | pmid = 17605682 | doi = 10.1586/17434440.4.4.463 | s2cid = 4690450 }}</ref>). A review pointed out that Vidal's 1973 paper stated the \"BCI challenge\"<ref name=\"Bozinovski1\">{{cite journal | vauthors = Bozinovski S, Bozinovska L | year = 2019 | title = Brain-computer interface in Europe: The thirtieth anniversary | journal = Automatika | volume = 60 | issue = 1| pages = 36\u201347 | doi = 10.1080/00051144.2019.1570644 | doi-access = free }}</ref> of controlling external objects using EEG signals, and especially use of [[Contingent negative variation|Contingent Negative Variation (CNV)]] potential as a challenge for BCI control. The 1977 experiment Vidal described was the first application of BCI after his 1973 BCI challenge. It was a noninvasive EEG (actually Visual Evoked Potentials (VEP)) control of a cursor-like graphical object on a computer screen. The demonstration was movement in a maze.<ref>{{cite journal |last1=Vidal |first1=Jacques J. |title=Real-time detection of brain events in EEG |journal=Proceedings of the IEEE |date=1977 |volume=65 |issue=5 |pages=633\u2013641 |doi=10.1109/PROC.1977.10542 |s2cid=7928242 |url=http://web.cs.ucla.edu/~vidal/Real_Time_Detection.pdf| url-status=dead |access-date=4 November 2022 |language=en |archive-url=https://web.archive.org/web/20150719005915/http://web.cs.ucla.edu/~vidal/Real_Time_Detection.pdf |archive-date=19 July 2015}}</ref>\n\nAfter his early contributions, Vidal was not active in BCI research, nor BCI events such as conferences, for many years. In 2011, however, he gave a lecture in [[Graz]], [[Austria]], supported by the Future BNCI project, presenting the first BCI, which earned a standing ovation. Vidal was joined by his wife, Laryce Vidal, who previously worked with him at UCLA on his first BCI project.\n\nIn 1988, a report was given on noninvasive EEG control of a physical object, a robot. The experiment described was EEG control of multiple start-stop-restart of the robot movement, along an arbitrary trajectory defined by a line drawn on a floor. The line-following behavior was the default robot behavior, utilizing autonomous intelligence and autonomous source of energy.<ref>S. Bozinovski, M. Sestakov, L. Bozinovska: Using EEG alpha rhythm to control a mobile robot, In G. Harris, C. Walker (eds.) ''Proc. IEEE Annual Conference of Medical and Biological Society'', p. 1515-1516, New Orleans, 1988</ref><ref>S. Bozinovski: Mobile robot trajectory control: From fixed rails to direct bioelectric control, In O. Kaynak (ed.) ''Proc. IEEE Workshop on Intelligent Motion Control'', p. 63-67, Istanbul, 1990</ref> This 1988 report written by Stevo Bozinovski, Mihail Sestakov, and Liljana Bozinovska was the first one about a robot control using EEG.<ref>M. Lebedev: Augmentation of sensorimotor functions with neural prostheses. Opera Medica and Physiologica. Vol. 2 (3): 211-227, 2016</ref><ref>M. Lebedev, M. Nicolelis: Brain-machine interfaces: from basic science to neuroprostheses and neurorehabilitation, Physiological Review 97:737-867, 2017</ref>\n\nIn 1990, a report was given on a closed loop, bidirectional adaptive BCI controlling computer buzzer by an anticipatory brain potential, the Contingent Negative Variation (CNV) potential.<ref>L. Bozinovska, G. Stojanov, M. Sestakov, S. Bozinovski: CNV pattern recognition: step toward a cognitive wave observation, In L. Torres, E. Masgrau, E. Lagunas (eds.) Signal Processing V: Theories and Applications, Proc. EUSIPCO-90: Fifth European Signal Processing Conference, Elsevier, p. 1659-1662, Barcelona, 1990</ref><ref>L. Bozinovska, S. Bozinovski, G. Stojanov, Electroexpectogram: experimental design and algorithms, In Proc IEEE International Biomedical Engineering Days, p. 55-60, Istanbul, 1992</ref> The experiment described how an expectation state of the brain, manifested by CNV, controls in a feedback loop the S2 buzzer in the S1-S2-CNV paradigm. The obtained cognitive wave representing the expectation learning in the brain is named Electroexpectogram (EXG). The CNV brain potential was part of the BCI challenge presented by Vidal in his 1973 paper.\n\nStudies in 2010s suggested the potential ability of neural stimulation to restore functional connectively and associated behaviors through modulation of molecular mechanisms of synaptic efficacy.<ref>{{cite journal | vauthors = Miranda RA, Casebeer WD, Hein AM, Judy JW, Krotkov EP, Laabs TL, Manzo JE, Pankratz KG, Pratt GA, Sanchez JC, Weber DJ, Wheeler TL, Ling GS | display-authors = 6 | title = DARPA-funded efforts in the development of novel brain-computer interface technologies | journal = Journal of Neuroscience Methods | volume = 244 | pages = 52\u201367 | date = April 2015 | pmid = 25107852 | doi = 10.1016/j.jneumeth.2014.07.019 | s2cid = 14678623 | doi-access = free }}</ref><ref>{{cite journal | vauthors = Jacobs M, Premji A, Nelson AJ | title = Plasticity-inducing TMS protocols to investigate somatosensory control of hand function | journal = Neural Plasticity | volume = 2012 | pages = 350574 | date = 16 May 2012 | pmid = 22666612 | pmc = 3362131 | doi = 10.1155/2012/350574 | doi-access = free }}</ref> This opened the door for the concept that BCI technologies may be able to restore function in addition to enabling functionality.\n\nSince 2013, [[DARPA]] has funded BCI technology through the BRAIN initiative, which has supported work out of the University of Pittsburgh Medical Center,<ref>{{cite web |last=Fox |first=Maggie |title=Brain Chip Helps Paralyzed Man Feel His Fingers |url=https://www.nbcnews.com/health/health-news/brain-chip-helps-paralyzed-man-feel-his-fingers-n665881 |website=NBC News |date=October 13, 2016 |access-date=23 March 2021}}</ref> Paradromics,<ref>{{cite web |last=Hatmaker |first=Taylor |title=DARPA awards $65 million to develop the perfect, tiny two-way brain-computer inerface |url= https://techcrunch.com/2017/07/10/darpa-nesd-grants-paradromics/ |website=Tech Crunch |date=July 10, 2017 |access-date=23 March 2021}}</ref> Brown,<ref>{{cite news |first=Kevin |last=Stacey |title=Brown to receive up to $19M to engineer next-generation brain-computer interface |url=https://www.brown.edu/news/2017-07-10/neurograins |website=Brown University |date=July 10, 2017 |access-date=23 March 2021}}</ref> and Synchron,<ref>{{cite web |title=Minimally Invasive \"Stentrode\" Shows Potential as Neural Interface for Brain |url= https://www.darpa.mil/news-events/2016-02-08 |website=Defense Advanced Research Projects Agency (DARPA) |date=2016-02-08 |access-date=23 March 2021}}</ref> among others.\n\n==BCIs versus neuroprosthetics==\n{{Main|Neuroprosthetics}}\n\nNeuroprosthetics is an area of [[neuroscience]] concerned with neural prostheses, that is, using artificial devices to replace the function of impaired nervous systems and brain-related problems, or of sensory organs or organs itself (bladder, diaphragm, etc.). As of December 2010, [[cochlear implants]] had been implanted as neuroprosthetic device in approximately 220,000 people worldwide.<ref>{{cite web|url= http://www.nidcd.nih.gov/health/hearing/pages/coch.aspx|title= Cochlear Implants|author= NIH Publication No. 11-4798|date= 1 March 2011|publisher= [[National Institute on Deafness and Other Communication Disorders]]}}</ref> There are also several neuroprosthetic devices that aim to restore vision, including [[retinal implant]]s. The first neuroprosthetic device, however, was the pacemaker.\n\nThe terms are sometimes used interchangeably. Neuroprosthetics and BCIs seek to achieve the same aims, such as restoring sight, hearing, movement, ability to communicate, and even [[cognitive function]].<ref name=\"Krucoff 584\"/> Both use similar experimental methods and surgical techniques.\n\n==Animal BCI research==\n\nSeveral laboratories have managed to record signals from monkey and rat [[cerebral cortex|cerebral cortices]] to operate BCIs to produce movement. Monkeys have navigated [[Cursor (computers)|computer cursors]] on screen and commanded robotic arms to perform simple tasks simply by thinking about the task and seeing the visual feedback, but without any motor output.<ref>Miguel Nicolelis et al. (2001) [http://www.dukemedicine.org/AboutUs/Facts_and_Statistics/historical_highlights/index/view Duke neurobiologist has developed system that allows monkeys to control robot arms via brain signals] {{webarchive |url=https://web.archive.org/web/20081219060005/http://www.dukemedicine.org/AboutUs/Facts_and_Statistics/historical_highlights/index/view |date=19 December 2008 }}</ref> In May 2008 photographs that showed a monkey at the [[University of Pittsburgh Medical Center]] operating a robotic arm by thinking were published in a number of well-known science journals and magazines.<ref>{{cite web| vauthors = Baum M | title = Monkey Uses Brain Power to Feed Itself With Robotic Arm| publisher = Pitt Chronicle| date = 6 September 2008| url = http://www.chronicle.pitt.edu/?p=1478| access-date = 6 July 2009| url-status = dead| archive-url = https://web.archive.org/web/20090910034547/http://www.chronicle.pitt.edu/?p=1478| archive-date = 10 September 2009| df = dmy-all}}</ref> Sheep too have been used to evaluate BCI technology including Synchron's Stentrode.\n\nIn 2020, Elon Musk's [[Neuralink]] was successfully implanted in a pig,<ref>{{cite web | vauthors = Lewis T |title= Elon Musk's Pig-Brain Implant Is Still a Long Way from 'Solving Paralysis' |url= https://www.scientificamerican.com/article/elon-musks-pig-brain-implant-is-still-a-long-way-from-solving-paralysis/ |website=[[Scientific American]] |access-date=23 March 2021}}</ref> announced in a widely viewed webcast. In 2021 Elon Musk announced that he had successfully enabled a monkey to play video games<ref>{{cite web | vauthors = Shead S |title=Elon Musk says his start-up Neuralink has wired up a monkey to play video games using its mind |url=https://www.cnbc.com/2021/02/01/elon-musk-neuralink-wires-up-monkey-to-play-video-games-using-mind.html |website=CNBC |date=February 2021 |publisher=CNBC |access-date=23 March 2021}}</ref> using Neuralink's device.\n\n===Early work===\n<noinclude>[[File:Monkey using a robotic arm.jpg|thumb|Monkey operating a robotic arm with brain\u2013computer interfacing (Schwartz lab, University of Pittsburgh)]]</noinclude>\nIn 1969 the [[operant conditioning]] studies of Fetz and colleagues,\nat the Regional Primate Research Center and Department of Physiology and Biophysics, [[University of Washington School of Medicine]] in [[Seattle]], showed for the first time that monkeys could learn to control the deflection of a [[biofeedback]] meter arm with neural activity.<ref>{{cite journal | vauthors = Fetz EE | title = Operant conditioning of cortical unit activity | journal = Science | volume = 163 | issue = 3870 | pages = 955\u2013958 | date = February 1969 | pmid = 4974291 | doi = 10.1126/science.163.3870.955 | s2cid = 45427819 | bibcode = 1969Sci...163..955F }}</ref> Similar work in the 1970s established that monkeys could quickly learn to voluntarily control the firing rates of individual and multiple neurons in the primary [[motor cortex]] if they were rewarded for generating appropriate patterns of neural activity.<ref>{{cite journal | vauthors = Schmidt EM, McIntosh JS, Durelli L, Bak MJ | title = Fine control of operantly conditioned firing patterns of cortical neurons | journal = Experimental Neurology | volume = 61 | issue = 2 | pages = 349\u2013369 | date = September 1978 | pmid = 101388 | doi = 10.1016/0014-4886(78)90252-2 | s2cid = 37539476 }}</ref>\n\nStudies that developed [[algorithms]] to reconstruct movements from [[motor cortex]] [[neurons]], which control movement, date back to the 1970s. In the 1980s, Apostolos Georgopoulos at [[Johns Hopkins University]] found a mathematical relationship between the electrical responses of single motor cortex neurons in [[rhesus macaque|rhesus macaque monkeys]] and the direction in which they moved their arms (based on a [[cosine]] function). He also found that dispersed groups of neurons, in different areas of the monkey's brains, collectively controlled motor commands, but was able to record the firings of neurons in only one area at a time, because of the technical limitations imposed by his equipment.<ref>{{cite journal | vauthors = Georgopoulos AP, Lurito JT, Petrides M, Schwartz AB, Massey JT | title = Mental rotation of the neuronal population vector | journal = Science | volume = 243 | issue = 4888 | pages = 234\u2013236 | date = January 1989 | pmid = 2911737 | doi = 10.1126/science.2911737 | s2cid = 37161168 | bibcode = 1989Sci...243..234G }}</ref>\n\nThere has been rapid development in BCIs since the mid-1990s.<ref>{{cite journal | vauthors = Lebedev MA, Nicolelis MA | title = Brain-machine interfaces: past, present and future | journal = Trends in Neurosciences | volume = 29 | issue = 9 | pages = 536\u2013546 | date = September 2006 | pmid = 16859758 | doi = 10.1016/j.tins.2006.07.004 | s2cid = 701524 }}</ref> Several groups have been able to capture complex brain motor cortex signals by recording from [[neural ensemble]]s (groups of neurons) and using these to control external devices.\n\n===Prominent research successes===\n\n====Kennedy and Yang Dan====\nPhillip Kennedy (who later founded Neural Signals in 1987) and colleagues built the first intracortical brain\u2013computer interface by implanting neurotrophic-cone [[electrodes]] into monkeys.{{Citation needed|date=February 2012}}\n\n<noinclude>[[File:LGN Cat Vison Recording.jpg|thumb|Yang Dan and colleagues' recordings of cat vision using a BCI implanted in the [[lateral geniculate nucleus]] (top row: original image; bottom row: recording)]]</noinclude><!-- FAIR USE of LGN Cat Vison Recording.jpg: see image description page at http://en.wikipedia.org/wiki/Image:LGN Cat Vison Recording.jpg for rationale --> In 1999, researchers led by [[Yang Dan (neuroscientist)|Yang Dan]] at the [[University of California, Berkeley]] decoded neuronal firings to reproduce images seen by cats. The team used an array of electrodes embedded in the [[thalamus]] (which integrates all of the brain's sensory input) of sharp-eyed cats. Researchers targeted 177 brain cells in the thalamus [[lateral geniculate nucleus]] area, which decodes signals from the [[retina]]. The cats were shown eight short movies, and their neuron firings were recorded. Using mathematical filters, the researchers decoded the signals to generate movies of what the cats saw and were able to reconstruct recognizable scenes and moving objects.<ref>{{cite journal | vauthors = Stanley GB, Li FF, Dan Y | title = Reconstruction of natural scenes from ensemble responses in the lateral geniculate nucleus | journal = The Journal of Neuroscience | volume = 19 | issue = 18 | pages = 8036\u20138042 | date = September 1999 | pmid = 10479703 | pmc = 6782475 | doi = 10.1523/JNEUROSCI.19-18-08036.1999 }}</ref> Similar results in humans have since been achieved by researchers in Japan ([[#MEG and MRI|see below]]).\n\n====Nicolelis====\n[[Miguel Nicolelis]], a professor at [[Duke University]], in [[Durham, North Carolina]], has been a prominent proponent of using multiple electrodes spread over a greater area of the brain to obtain neuronal signals to drive a BCI.\n\nAfter conducting initial studies in rats during the 1990s, Nicolelis and his colleagues developed BCIs that decoded brain activity in [[night monkey|owl monkeys]] and used the devices to reproduce monkey movements in robotic arms. Monkeys have advanced reaching and grasping abilities and good hand manipulation skills, making them ideal test subjects for this kind of work.\n\nBy 2000, the group succeeded in building a BCI that reproduced owl monkey movements while the monkey operated a [[joystick]] or reached for food.<ref>{{cite journal | vauthors = Wessberg J, Stambaugh CR, Kralik JD, Beck PD, Laubach M, Chapin JK, Kim J, Biggs SJ, Srinivasan MA, Nicolelis MA | display-authors = 6 | title = Real-time prediction of hand trajectory by ensembles of cortical neurons in primates | journal = Nature | volume = 408 | issue = 6810 | pages = 361\u2013365 | date = November 2000 | pmid = 11099043 | doi = 10.1038/35042582 | s2cid = 795720 | bibcode = 2000Natur.408..361W }}</ref> The BCI operated in real time and could also control a separate robot remotely over [[internet protocol]]. But the monkeys could not see the arm moving and did not receive any feedback, a so-called [[open-loop controller|open-loop]] BCI.\n\n[[File:Brain-computer interface (schematic).jpg|thumb|Diagram of the BCI developed by Miguel Nicolelis and colleagues for use on [[rhesus monkeys]]]]\n\nLater experiments by Nicolelis using [[rhesus monkeys]] succeeded in [[feedback loop|closing the feedback loop]] and reproduced monkey reaching and grasping movements in a robot arm. With their deeply cleft and furrowed brains, rhesus monkeys are considered to be better models for human [[neurophysiology]] than owl monkeys. The monkeys were trained to reach and grasp objects on a computer screen by manipulating a joystick while corresponding movements by a robot arm were hidden.<ref name=carmena2003>{{cite journal | vauthors = Carmena JM, Lebedev MA, Crist RE, O'Doherty JE, Santucci DM, Dimitrov DF, Patil PG, Henriquez CS, Nicolelis MA | display-authors = 6 | title = Learning to control a brain-machine interface for reaching and grasping by primates | journal = PLOS Biology | volume = 1 | issue = 2 | pages = E42 | date = November 2003 | pmid = 14624244 | pmc = 261882 | doi = 10.1371/journal.pbio.0000042 }}</ref><ref name=lebedev2005>{{cite journal | vauthors = Lebedev MA, Carmena JM, O'Doherty JE, Zacksenhouse M, Henriquez CS, Principe JC, Nicolelis MA | title = Cortical ensemble adaptation to represent velocity of an artificial actuator controlled by a brain-machine interface | journal = The Journal of Neuroscience | volume = 25 | issue = 19 | pages = 4681\u20134693 | date = May 2005 | pmid = 15888644 | pmc = 6724781 | doi = 10.1523/JNEUROSCI.4088-04.2005 }}</ref> The monkeys were later shown the robot directly and learned to control it by viewing its movements. The BCI used velocity predictions to control reaching movements and simultaneously predicted [[Grip strength|handgripping force]]. In 2011 O'Doherty and colleagues showed a BCI with sensory feedback with rhesus monkeys. The monkey was brain controlling the position of an avatar arm while receiving sensory feedback through direct [[Cortical stimulation mapping|intracortical stimulation (ICMS)]] in the arm representation area of the [[sensory cortex]].<ref name=Odoherty2003>{{cite journal | vauthors = O'Doherty JE, Lebedev MA, Ifft PJ, Zhuang KZ, Shokur S, Bleuler H, Nicolelis MA | title = Active tactile exploration using a brain-machine-brain interface | journal = Nature | volume = 479 | issue = 7372 | pages = 228\u2013231 | date = October 2011 | pmid = 21976021 | pmc = 3236080 | doi = 10.1038/nature10489 | bibcode = 2011Natur.479..228O }}</ref>\n\n====Donoghue, Schwartz and Andersen====\n[[File:164_Angell_Street.jpg|thumb|BCIs are a core focus of the [[Carney Institute for Brain Science]] at [[Brown University]] ]]\nOther laboratories which have developed BCIs and algorithms that decode neuron signals include the [[Carney Institute for Brain Science]] at [[Brown University]] and the labs of Andrew Schwartz at the [[University of Pittsburgh]] and [[Richard A. Andersen (neuroscientist)|Richard Andersen]] at [[Caltech]]. These researchers have been able to produce working BCIs, even using recorded signals from far fewer neurons than did Nicolelis (15\u201330 neurons versus 50\u2013200 neurons).\n\n[[John Donoghue (neuroscientist)|John Donoghue]]'s lab at the Carney Institute reported training rhesus monkeys to use a BCI to track visual targets on a computer screen (closed-loop BCI) with or without assistance of a joystick.<ref>{{cite journal | vauthors = Serruya MD, Hatsopoulos NG, Paninski L, Fellows MR, Donoghue JP | title = Instant neural control of a movement signal | journal = Nature | volume = 416 | issue = 6877 | pages = 141\u2013142 | date = March 2002 | pmid = 11894084 | doi = 10.1038/416141a | s2cid = 4383116 | bibcode = 2002Natur.416..141S }}</ref> Schwartz's group created a BCI for three-dimensional tracking in virtual reality and also reproduced BCI control in a robotic arm.<ref>{{cite journal | vauthors = Taylor DM, Tillery SI, Schwartz AB | title = Direct cortical control of 3D neuroprosthetic devices | journal = Science | volume = 296 | issue = 5574 | pages = 1829\u20131832 | date = June 2002 | pmid = 12052948 | doi = 10.1126/science.1070291 | s2cid = 9402759 | citeseerx = 10.1.1.1027.4335 | bibcode = 2002Sci...296.1829T }}</ref> The same group also created headlines when they demonstrated that a monkey could feed itself pieces of fruit and marshmallows using a robotic arm controlled by the animal's own brain signals.<ref>[http://www.pittsburghlive.com:8000/x/tribunereview/s_469059.html Pitt team to build on brain-controlled arm] {{webarchive |url=https://web.archive.org/web/20070704125118/http://www.pittsburghlive.com:8000/x/tribunereview/s_469059.html |date=4 July 2007 }}, ''Pittsburgh Tribune Review'', 5 September 2006.</ref><ref>{{YouTube|wxIgdOlT2cY}}</ref><ref>{{cite journal | vauthors = Velliste M, Perel S, Spalding MC, Whitford AS, Schwartz AB | title = Cortical control of a prosthetic arm for self-feeding | journal = Nature | volume = 453 | issue = 7198 | pages = 1098\u20131101 | date = June 2008 | pmid = 18509337 | doi = 10.1038/nature06996 | s2cid = 4404323 | bibcode = 2008Natur.453.1098V | url = https://zenodo.org/record/891045 }}</ref>\n\nAndersen's group used recordings of [[premovement neuronal activity|premovement activity]] from the [[posterior parietal cortex]] in their BCI, including signals created when experimental animals anticipated receiving a reward.<ref>{{cite journal | vauthors = Musallam S, Corneil BD, Greger B, Scherberger H, Andersen RA | title = Cognitive control signals for neural prosthetics | journal = Science | volume = 305 | issue = 5681 | pages = 258\u2013262 | date = July 2004 | pmid = 15247483 | doi = 10.1126/science.1097938 | s2cid = 3112034 | bibcode = 2004Sci...305..258M }}</ref>\n\n====Other research====\nIn addition to predicting [[kinematic]] and [[kinetic energy|kinetic]] parameters of limb movements, BCIs that predict [[Electromyography|electromyographic]] or electrical activity of the muscles of primates are being developed.<ref>{{cite journal | vauthors = Santucci DM, Kralik JD, Lebedev MA, Nicolelis MA | title = Frontal and parietal cortical ensembles predict single-trial muscle activity during reaching movements in primates | journal = The European Journal of Neuroscience | volume = 22 | issue = 6 | pages = 1529\u20131540 | date = September 2005 | pmid = 16190906 | doi = 10.1111/j.1460-9568.2005.04320.x | s2cid = 31277881 }}</ref> Such BCIs could be used to restore mobility in paralyzed limbs by electrically stimulating muscles.\n\nMiguel Nicolelis and colleagues demonstrated that the activity of large neural ensembles can predict arm position. This work made possible creation of BCIs that read arm movement intentions and translate them into movements of artificial actuators. Carmena and colleagues<ref name=carmena2003/> programmed the [[neural coding]] in a BCI that allowed a monkey to control reaching and grasping movements by a robotic arm. Lebedev and colleagues<ref name=lebedev2005/> argued that brain networks reorganize to create a new representation of the robotic appendage in addition to the representation of the animal's own limbs.\n\nIn 2019, researchers from [[University of California, San Francisco|UCSF]] published a study where they demonstrated a BCI that had the potential to help patients with speech impairment caused by neurological disorders. Their BCI used high-density electrocorticography to tap neural activity from a patient's brain and used [[deep learning]] methods to synthesize speech.<ref>{{cite journal | vauthors = Anumanchipalli GK, Chartier J, Chang EF | title = Speech synthesis from neural decoding of spoken sentences | journal = Nature | volume = 568 | issue = 7753 | pages = 493\u2013498 | date = April 2019 | pmid = 31019317 | doi = 10.1038/s41586-019-1119-1 | pmc = 9714519 | s2cid = 129946122 | bibcode = 2019Natur.568..493A }}</ref><ref>{{cite journal | vauthors = Pandarinath C, Ali YH | title = Brain implants that let you speak your mind | language = EN | journal = Nature | volume = 568 | issue = 7753 | pages = 466\u2013467 | date = April 2019 | pmid = 31019323 | doi = 10.1038/d41586-019-01181-y | doi-access = free | bibcode = 2019Natur.568..466P }}</ref> In 2021, researchers from the same group published a study showing the potential of a BCI to decode words and sentences in an anarthric patient who had been unable to speak for over 15 years.<ref name=\"Neuroprosthesis for Decoding Speech\">{{cite journal | vauthors = Moses DA, Metzger SL, Liu JR, Anumanchipalli GK, Makin JG, Sun PF, Chartier J, Dougherty ME, Liu PM, Abrams GM, Tu-Chan A, Ganguly K, Chang EF | display-authors = 6 | title = Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria | journal = The New England Journal of Medicine | volume = 385 | issue = 3 | pages = 217\u2013227 | date = July 2021 | pmid = 34260835 | doi = 10.1056/NEJMoa2027540 | pmc = 8972947 | s2cid = 235907121 }}</ref><ref>Belluck, Pam (14 July 2021). [https://www.nytimes.com/2021/07/14/health/speech-brain-implant-computer.html \"Tapping Into the Brain to Help a Paralyzed Man Speak\"]. ''The New York Times''.</ref>\n\nThe biggest impediment to BCI technology at present is the lack of a sensor modality that provides safe, accurate and robust access to brain signals. It is conceivable or even likely, however, that such a sensor will be developed within the next twenty years. The use of such a sensor should greatly expand the range of communication functions that can be provided using a BCI.\n\nDevelopment and implementation of a BCI system is complex and time-consuming. In response to this problem, Gerwin Schalk has been developing a general-purpose system for BCI research, called [[BCI2000]]. BCI2000 has been in development since 2000 in a project led by the Brain\u2013Computer Interface R&D Program at the [[Wadsworth Center]] of the [[New York State Department of Health]] in [[Albany, New York]], United States.\n\nA new 'wireless' approach uses [[light-gated ion channel]]s such as [[Channelrhodopsin]] to control the activity of genetically defined subsets of neurons [[in vivo]]. In the context of a simple learning task, illumination of [[Transfection|transfected]] cells in the [[Somatosensory system|somatosensory cortex]] influenced the decision-making process of freely moving [[mice]].<ref>{{cite journal | vauthors = Huber D, Petreanu L, Ghitani N, Ranade S, Hrom\u00e1dka T, Mainen Z, Svoboda K|author7-link=Karel Svoboda (scientist) | title = Sparse optical microstimulation in barrel cortex drives learned behaviour in freely moving mice | journal = Nature | volume = 451 | issue = 7174 | pages = 61\u201364 | date = January 2008 | pmid = 18094685 | pmc = 3425380 | doi = 10.1038/nature06445 | bibcode = 2008Natur.451...61H }}</ref>\n\nThe use of BMIs has also led to a deeper understanding of neural networks and the central nervous system. Research has shown that despite the inclination of neuroscientists to believe that neurons have the most effect when working together, single neurons can be conditioned through the use of BMIs to fire at a pattern that allows primates to control motor outputs. The use of BMIs has led to development of the single neuron insufficiency principle which states that even with a well tuned firing rate single neurons can only carry a narrow amount of information and therefore the highest level of accuracy is achieved by recording firings of the collective ensemble. Other principles discovered with the use of BMIs include the neuronal multitasking principle, the neuronal mass principle, the neural degeneracy principle, and the plasticity principle.<ref>{{cite journal | vauthors = Nicolelis MA, Lebedev MA | title = Principles of neural ensemble physiology underlying the operation of brain-machine interfaces | journal = Nature Reviews. Neuroscience | volume = 10 | issue = 7 | pages = 530\u2013540 | date = July 2009 | pmid = 19543222 | doi = 10.1038/nrn2653 | s2cid = 9290258 }}</ref>\n\nBCIs are also proposed to be applied by users without disabilities. A [[User-centered design|user-centered]] categorization of BCI approaches by [[Thorsten O. Zander]] and Christian Kothe introduces the term passive BCI.<ref name=\":0\">{{cite journal | vauthors = Zander TO, Kothe C | title = Towards passive brain-computer interfaces: applying brain-computer interface technology to human-machine systems in general | journal = Journal of Neural Engineering | volume = 8 | issue = 2 | pages = 025005 | date = April 2011 | pmid = 21436512 | doi = 10.1088/1741-2560/8/2/025005 | bibcode = 2011JNEng...8b5005Z | s2cid = 37168897 }}</ref> Next to active and reactive BCI that are used for directed control, passive BCIs allow for assessing and interpreting changes in the user state during Human-Computer Interaction ([[Human-Computer Interaction|HCI]]). In a secondary, implicit control loop the computer system adapts to its user improving its [[usability]] in general.\n\nBeyond BCI systems that decode neural activity to drive external effectors, BCI systems may be used to encode signals from the periphery. These sensory BCI devices enable real-time, behaviorally-relevant decisions based upon closed-loop neural stimulation.<ref>{{cite journal | vauthors = Richardson AG, Ghenbot Y, Liu X, Hao H, Rinehart C, DeLuccia S, Torres Maldonado S, Boyek G, Zhang M, Aflatouni F, Van der Spiegel J, Lucas TH | display-authors = 6 | title = Learning active sensing strategies using a sensory brain-machine interface | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 116 | issue = 35 | pages = 17509\u201317514 | date = August 2019 | pmid = 31409713 | pmc = 6717311 | doi = 10.1073/pnas.1909953116 | bibcode = 2019PNAS..11617509R | doi-access = free }}</ref>\n\n====The BCI Award====\nThe [[Annual BCI Research Award]] is awarded in recognition of outstanding and innovative research in the field of Brain-Computer Interfaces. Each year, a renowned research laboratory is asked to judge the submitted projects. The jury consists of world-leading BCI experts recruited by the awarding laboratory. The jury selects twelve nominees, then chooses a first, second, and third-place winner, who receive awards of $3,000, $2,000, and $1,000, respectively.\n\n==Human BCI research==\n\n===Invasive BCIs===\nInvasive BCI requires surgery to implant electrodes under scalp for communicating brain signals. The main advantage is to provide more accurate reading; however, its downside includes side effects from the surgery. After the surgery, scar tissues may form which can make brain signals weaker. In addition, according to the research of Abdulkader et al., (2015),<ref>{{cite journal| vauthors = Abdulkader SN, Atia A, Mostafa MS |date=July 2015|title=Brain computer interfacing: Applications and challenges|journal=Egyptian Informatics Journal |volume=16 |issue=2 |pages=213\u2013230 |doi=10.1016/j.eij.2015.06.002 |issn=1110-8665 |doi-access=free}}</ref> the body may not accept the implanted electrodes and this can cause a medical condition.\n\n==== Vision ====\nInvasive BCI research has targeted repairing damaged sight and providing new functionality for people with paralysis. Invasive BCIs are implanted directly into the [[grey matter]] of the brain during neurosurgery. Because they lie in the grey matter, invasive devices produce the highest quality signals of BCI devices but are prone to [[scar|scar-tissue]] build-up, causing the signal to become weaker, or even non-existent, as the body reacts to a foreign object in the brain.<ref>{{cite journal | vauthors = Polikov VS, Tresco PA, Reichert WM | title = Response of brain tissue to chronically implanted neural electrodes | journal = Journal of Neuroscience Methods | volume = 148 | issue = 1 | pages = 1\u201318 | date = October 2005 | pmid = 16198003 | doi = 10.1016/j.jneumeth.2005.08.015 | s2cid = 11248506 }}</ref>\n\nIn ''[[vision science]]'', direct [[brain implant]]s have been used to treat non-[[congenital]] (acquired) blindness. One of the first scientists to produce a working brain interface to restore sight was private researcher [[William H. Dobelle|William Dobelle]].\n\nDobelle's first prototype was implanted into \"Jerry\", a man blinded in adulthood, in 1978. A single-array BCI containing 68 electrodes was implanted onto Jerry's [[visual cortex]] and succeeded in producing [[phosphenes]], the sensation of seeing light. The system included cameras mounted on glasses to send signals to the implant. Initially, the implant allowed Jerry to see shades of grey in a limited field of vision at a low frame-rate. This also required him to be hooked up to a [[mainframe computer]], but shrinking electronics and faster computers made his artificial eye more portable and now enable him to perform simple tasks unassisted.<ref>[https://www.wired.com/wired/archive/10.09/vision.html \"Vision quest\"]. ''[[Wired (magazine)|Wired]]''. (September 2002).</ref>\n\n[[File:BrainGate.jpg|thumb|Dummy unit illustrating the design of a [[BrainGate]] interface]]\n\nIn 2002, Jens Naumann, also blinded in adulthood, became the first in a series of 16 paying patients to receive Dobelle's second generation implant, marking one of the earliest commercial uses of BCIs. The second generation device used a more sophisticated implant enabling better mapping of phosphenes into coherent vision. Phosphenes are spread out across the visual field in what researchers call \"the starry-night effect\". Immediately after his implant, Jens was able to use his imperfectly restored vision to [[driving|drive]] an automobile slowly around the parking area of the research institute.<ref>{{Cite news| vauthors = Kotler S |title=Vision Quest|language=en-US|magazine=Wired|url=https://www.wired.com/2002/09/vision/|access-date=2021-11-10|issn=1059-1028}}</ref> Unfortunately, Dobelle died in 2004<ref>{{cite web | vauthors = Tuller D | date = 1 November 2004 | url = https://www.nytimes.com/2004/11/01/obituaries/01dobelle.html | title = Dr. William Dobelle, Artificial Vision Pioneer, Dies at 62 | work = The New York Times }}</ref> before his processes and developments were documented. Subsequently, when Mr. Naumann and the other patients in the program began having problems with their vision, there was no relief and they eventually lost their \"sight\" again. Naumann wrote about his experience with Dobelle's work in ''Search for Paradise: A Patient's Account of the Artificial Vision Experiment''<ref name=\"Naumann,_2012\">{{cite book | vauthors = Naumann J |title=Search for Paradise: A Patient's Account of the Artificial Vision Experiment. |date=2012 |publisher=Xlibris |isbn=978-1-4797-0920-5}}</ref> and has returned to his farm in Southeast Ontario, Canada, to resume his normal activities.<ref>{{cite web|author=nurun.com |url=http://www.thewhig.com/2012/11/28/mans-high-tech-paradise-lost |title=Mr. Jen Naumann's high-tech paradise lost |publisher=Thewhig.com |date= 28 November 2012|access-date=19 December 2016}}</ref>\n\n====Movement====\nBCIs focusing on ''motor neuroprosthetics'' aim to either restore movement in individuals with paralysis or provide devices to assist them, such as interfaces with computers or robot arms.\n\nResearchers at [[Emory University]] in [[Atlanta]], led by Philip Kennedy and Roy Bakay, were first to install a brain implant in a human that produced signals of high enough quality to simulate movement. Their patient, Johnny Ray (1944\u20132002), developed '[[locked-in syndrome]]' after having a brain-stem [[stroke]] in 1997. Ray's implant was installed in 1998 and he lived long enough to start working with the implant, eventually learning to control a computer cursor; he died in 2002 of a [[brain aneurysm]].<ref>{{cite journal | vauthors = Kennedy PR, Bakay RA | title = Restoration of neural output from a paralyzed patient by a direct brain connection | journal = NeuroReport | volume = 9 | issue = 8 | pages = 1707\u20131711 | date = June 1998 | pmid = 9665587 | doi = 10.1097/00001756-199806010-00007 | s2cid = 5681602 }}</ref>\n\n[[Tetraplegic]] [[Matt Nagle]] became the first person to control an artificial hand using a BCI in 2005 as part of the first nine-month human trial of [[Cyberkinetics]]'s [[BrainGate]] chip-implant. Implanted in Nagle's right [[precentral gyrus]] (area of the motor cortex for arm movement), the 96-electrode BrainGate implant allowed Nagle to control a robotic arm by thinking about moving his hand as well as a computer cursor, lights and TV.<ref>{{cite journal | vauthors = Hochberg LR, Serruya MD, Friehs GM, Mukand JA, Saleh M, Caplan AH, Branner A, Chen D, Penn RD, Donoghue JP | display-authors = 6 | title = Neuronal ensemble control of prosthetic devices by a human with tetraplegia | journal = Nature | volume = 442 | issue = 7099 | pages = 164\u2013171 | date = July 2006 | pmid = 16838014 | doi = 10.1038/nature04970 | s2cid = 4347367 | bibcode = 2006Natur.442..164H | others = Gerhard M. Friehs, Jon A. Mukand, Maryam Saleh, Abraham H. Caplan, Almut Branner, David Chen, Richard D. Penn and John P. Donoghue }}</ref> One year later, professor [[Jonathan Wolpaw]] received the prize of the [[Altran Foundation for Innovation]] to develop a Brain Computer Interface with electrodes located on the surface of the skull, instead of directly in the brain.\n\nMore recently, research teams led by the BrainGate group at [[Brown University]]<ref>{{cite journal | vauthors = Hochberg LR, Bacher D, Jarosiewicz B, Masse NY, Simeral JD, Vogel J, Haddadin S, Liu J, Cash SS, van der Smagt P, Donoghue JP | display-authors = 6 | title = Reach and grasp by people with tetraplegia using a neurally controlled robotic arm | journal = Nature | volume = 485 | issue = 7398 | pages = 372\u2013375 | date = May 2012 | pmid = 22596161 | pmc = 3640850 | doi = 10.1038/nature11076 | bibcode = 2012Natur.485..372H }}</ref> and a group led by [[University of Pittsburgh Medical Center]],<ref>{{cite journal | vauthors = Collinger JL, Wodlinger B, Downey JE, Wang W, Tyler-Kabara EC, Weber DJ, McMorland AJ, Velliste M, Boninger ML, Schwartz AB | display-authors = 6 | title = High-performance neuroprosthetic control by an individual with tetraplegia | journal = Lancet | volume = 381 | issue = 9866 | pages = 557\u2013564 | date = February 2013 | pmid = 23253623 | pmc = 3641862 | doi = 10.1016/S0140-6736(12)61816-9 }}</ref> both in collaborations with the [[United States Department of Veterans Affairs]], have demonstrated further success in direct control of robotic prosthetic limbs with many degrees of freedom using direct connections to arrays of neurons in the motor cortex of patients with tetraplegia.\n\n====Communication====\nIn May 2021, a Stanford University team reported a successful proof-of-concept test that enabled a quadraplegic participant to input English sentences at about 86 characters per minute and 18 words per minute. The participant imagined moving his hand to write letters, and the system performed handwriting recognition on electrical signals detected in the motor cortex, utilizing hidden Markov models and recurrent neural networks for decoding.<ref>{{cite journal | vauthors = Willett FR, Avansino DT, Hochberg LR, Henderson JM, Shenoy KV | title = High-performance brain-to-text communication via handwriting | journal = Nature | volume = 593 | issue = 7858 | pages = 249\u2013254 | date = May 2021 | pmid = 33981047 | pmc = 8163299 | doi = 10.1038/s41586-021-03506-2 | bibcode = 2021Natur.593..249W }}</ref><ref>{{cite book | vauthors = Willett FR |title=Brain-Computer Interface Research|chapter=A High-Performance Handwriting BCI|date=2021 |work=Brain-Computer Interface Research: A State-of-the-Art Summary 10|pages=105\u2013109| veditors = Guger C, Allison BZ, Gunduz A |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing|language=en|doi=10.1007/978-3-030-79287-9_11|isbn=978-3-030-79287-9 |s2cid=239736609}}</ref>\n\nA report published in July 2021 reported a paralyzed patient was able to communicate 15 words per minute using a brain implant that analyzed motor neurons that previously controlled the vocal tract.<ref>{{cite web | vauthors = Hamliton J | date = 14 July 2021 | url = https://www.npr.org/sections/health-shots/2021/07/14/1016028911/experimental-brain-implant-lets-man-with-paralysis-turn-his-thoughts-into-words | title = Experimental Brain Implant Lets Man With Paralysis Turn His Thoughts Into Words | work =  All Things Considered | publisher = NPR }}</ref><ref name=\"Neuroprosthesis for Decoding Speech\"/>\n\nIn a recent review article, researchers raised an open question of whether human information transfer rates can surpass that of language with BCIs. Given that recent language research has demonstrated that human information transfer rates are relatively constant across many languages, there may exist a limit at the level of information processing in the brain. On the contrary, this \"upper limit\" of information transfer rate may be intrinsic to language itself, as a modality for information transfer.<ref name=\":5\">{{cite journal | vauthors = Pandarinath C, Bensmaia SJ | title = The science and engineering behind sensitized brain-controlled bionic hands | journal = Physiological Reviews | date = September 2021 | volume = 102 | issue = 2 | pages = 551\u2013604 | pmid = 34541898 | doi = 10.1152/physrev.00034.2020 | pmc = 8742729 | s2cid = 237574228 | pmc-embargo-date = April 1, 2023 }}</ref>\n\n==== Technical challenges ====\nThere exist a number of technical challenges to recording brain activity with invasive BCIs. Advances in [[CMOS]] technology are pushing and enabling integrated, invasive BCI designs with smaller size, lower power requirements, and higher signal acquisition capabilities.<ref>{{Cite journal| vauthors = Zhang M, Tang Z, Liu X, Van der Spiegel J |date= April 2020 |title=Electronic neural interfaces |journal=Nature Electronics |language=en |volume=3 |issue=4 |pages=191\u2013200 |doi=10.1038/s41928-020-0390-3 |s2cid= 216508360 |issn=2520-1131 }}</ref> Invasive BCIs involve electrodes that penetrate brain tissue in an attempt to record [[action potential]] signals (also known as spikes) from individual, or small groups of, neurons near the electrode. The interface between a recording electrode and the electrolytic solution surrounding neurons has been modelled using the [[Hodgkin\u2013Huxley model|Hodgkin-Huxley model]].<ref>{{cite journal | vauthors = Hodgkin AL, Huxley AF | title = A quantitative description of membrane current and its application to conduction and excitation in nerve | journal = The Journal of Physiology | volume = 117 | issue = 4 | pages = 500\u2013544 | date = August 1952 | pmid = 12991237 | pmc = 1392413 | doi = 10.1113/jphysiol.1952.sp004764 }}</ref><ref name=\"Revealing neuronal function through\">{{cite journal | vauthors = Obien ME, Deligkaris K, Bullmann T, Bakkum DJ, Frey U | title = Revealing neuronal function through microelectrode array recordings | journal = Frontiers in Neuroscience | volume = 8 | pages = 423 | date = 2015 | pmid = 25610364 | doi = 10.3389/fnins.2014.00423 | pmc = 4285113 | doi-access = free }}</ref>\n\nElectronic limitations to invasive BCIs have been an active area of research in recent decades. While [[Patch clamp|intracellular recordings]] of neurons reveal action potential voltages on the scale of hundreds of millivolts, chronic invasive BCIs rely on recording extracellular voltages which typically are three orders of magnitude smaller, existing at hundreds of microvolts.<ref name=\":8\">{{Cite journal| vauthors = Harrison RR |date= July 2008 |title=The Design of Integrated Circuits to Observe Brain Activity |journal=Proceedings of the IEEE|volume=96|issue=7|pages=1203\u20131216|doi=10.1109/JPROC.2008.922581|s2cid= 7020369 |issn=1558-2256}}</ref> Further adding to the challenge of detecting signals on the scale of microvolts is the fact that the electrode-tissue interface has a high [[capacitance]] at small voltages. Due to the nature of these small signals, for BCI systems that incorporate functionality onto an integrated circuit, each electrode requires its own [[amplifier]] and [[Analog-to-digital converter|ADC]], which convert analog extracellular voltages into digital signals.<ref name=\":8\" /> Because a typical neuron action potential lasts for one millisecond, BCIs measuring spikes must have sampling rates ranging from 300&nbsp;Hz to 5&nbsp;kHz. Yet another concern is that invasive BCIs must be low-power, so as to dissipate less heat to surrounding tissue; at the most basic level more power is traditionally needed to optimize [[signal-to-noise ratio]].<ref name=\"Revealing neuronal function through\"/> Optimal battery design is an active area of research in BCIs.<ref>{{Cite journal| vauthors = Haci D, Liu Y, Ghoreishizadeh SS, Constandinou TG |date= February 2020 |title=Key Considerations for Power Management in Active Implantable Medical Devices |journal=2020 IEEE 11th Latin American Symposium on Circuits Systems (LASCAS)|pages=1\u20134|doi=10.1109/LASCAS45839.2020.9069004|isbn= 978-1-7281-3427-7 |s2cid= 215817530 |url= https://discovery.ucl.ac.uk/id/eprint/10090175/ }}</ref>[[File:Invasive and partially invasive BCIs.png|thumb|Illustration of invasive and partially invasive BCIs: electrocorticography (ECoG), endovascular, and intracortical microelectrode.|248x248px]]Challenges existing in the area of [[Materials science|material science]] are central to the design of invasive BCIs. Variations in signal quality over time have been commonly observed with implantable microelectrodes.<ref>{{cite journal | vauthors = Downey JE, Schwed N, Chase SM, Schwartz AB, Collinger JL | title = Intracortical recording stability in human brain-computer interface users | journal = Journal of Neural Engineering | volume = 15 | issue = 4 | pages = 046016 | date = August 2018 | pmid = 29553484 | doi = 10.1088/1741-2552/aab7a0 | bibcode = 2018JNEng..15d6016D | s2cid = 3961913 }}</ref><ref>{{cite journal | vauthors = Freire MA, Morya E, Faber J, Santos JR, Guimaraes JS, Lemos NA, Sameshima K, Pereira A, Ribeiro S, Nicolelis M | title = Comprehensive analysis of tissue preservation and recording quality from chronic multielectrode implants. | journal = PLOS ONE | volume = 6 | issue = 11 | pages = e27554 | date = November 2011 | pmid = 26098896 | doi = 10.1371/journal.pone.0027554 | pmc = 4476592 | bibcode = 2011PLoSO...627554F | doi-access = free }}</ref> Optimal material and mechanical characteristics for long term signal stability in invasive BCIs has been an active area of research.<ref>{{cite journal | vauthors = Szostak KM, Grand L, Constandinou TG | title = Neural Interfaces for Intracortical Recording: Requirements, Fabrication Methods, and Characteristics | journal = Frontiers in Neuroscience | volume = 11 | pages = 665 | date = 2017 | pmid = 29270103 | doi = 10.3389/fnins.2017.00665 | pmc = 5725438 | doi-access = free }}</ref> It has been proposed that the formation of [[glial scar]]ring, secondary to damage at the electrode-tissue interface, is likely responsible for electrode failure and reduced recording performance.<ref name=\":10\" /> Research has suggested that [[Blood\u2013brain barrier|blood-brain barrier]] leakage, either at the time of insertion or over time, may be responsible for the inflammatory and glial reaction to chronic microelectrodes implanted in the brain.<ref name=\":10\">{{cite journal | vauthors = Saxena T, Karumbaiah L, Gaupp EA, Patkar R, Patil K, Betancur M, Stanley GB, Bellamkonda RV | display-authors = 6 | title = The impact of chronic blood-brain barrier breach on intracortical electrode function | journal = Biomaterials | volume = 34 | issue = 20 | pages = 4703\u20134713 | date = July 2013 | pmid = 23562053 | doi = 10.1016/j.biomaterials.2013.03.007 }}</ref><ref>{{cite journal | vauthors = Nolta NF, Christensen MB, Crane PD, Skousen JL, Tresco PA | title = BBB leakage, astrogliosis, and tissue loss correlate with silicon microelectrode array recording performance | journal = Biomaterials | volume = 53 | pages = 753\u2013762 | date = 2015-06-01 | pmid = 25890770 | doi = 10.1016/j.biomaterials.2015.02.081 }}</ref> As a result, flexible<ref>{{cite journal | vauthors = Robinson JT, Pohlmeyer E, Gather MC, Kemere C, Kitching JE, Malliaras GG, Marblestone A, Shepard KL, Stieglitz T, Xie C | display-authors = 6 | title = Developing Next-generation Brain Sensing Technologies - A Review | journal = IEEE Sensors Journal | volume = 19 | issue = 22 | pages = 10163\u201310175 | date = November 2019 | pmid = 32116472 | doi = 10.1109/JSEN.2019.2931159 | pmc = 7047830 }}</ref><ref>{{cite journal | vauthors = Luan L, Wei X, Zhao Z, Siegel JJ, Potnis O, Tuppen CA, Lin S, Kazmi S, Fowler RA, Holloway S, Dunn AK, Chitwood RA, Xie C | display-authors = 6 | title = Ultraflexible nanoelectronic probes form reliable, glial scar-free neural integration | journal = Science Advances | volume = 3 | issue = 2 | pages = e1601966 | date = February 2017 | pmid = 28246640 | pmc = 5310823 | doi = 10.1126/sciadv.1601966 | bibcode = 2017SciA....3E1966L }}</ref><ref>{{cite journal | vauthors = Frank JA, Antonini MJ, Anikeeva P | title = Next-generation interfaces for studying neural function | journal = Nature Biotechnology | volume = 37 | issue = 9 | pages = 1013\u20131023 | date = September 2019 | pmid = 31406326 | pmc = 7243676 | doi = 10.1038/s41587-019-0198-8 }}</ref> and tissue-like designs<ref name=\":9\">{{cite journal | vauthors = Hong G, Viveros RD, Zwang TJ, Yang X, Lieber CM | title = Tissue-like Neural Probes for Understanding and Modulating the Brain | journal = Biochemistry | volume = 57 | issue = 27 | pages = 3995\u20134004 | date = July 2018 | pmid = 29529359 | pmc = 6039269 | doi = 10.1021/acs.biochem.8b00122 }}</ref><ref>{{cite journal | vauthors = Viveros RD, Zhou T, Hong G, Fu TM, Lin HG, Lieber CM | title = Advanced One- and Two-Dimensional Mesh Designs for Injectable Electronics | journal = Nano Letters | volume = 19 | issue = 6 | pages = 4180\u20134187 | date = June 2019 | pmid = 31075202 | pmc = 6565464 | doi = 10.1021/acs.nanolett.9b01727 | bibcode = 2019NanoL..19.4180V }}</ref> have been researched and developed to minimize [[Foreign body reaction|foreign-body reaction]] by means of matching the [[Young's modulus]] of the electrode closer to that of brain tissue.<ref name=\":9\" />\n\n===Partially invasive BCIs===\nPartially invasive BCI devices are implanted inside the skull but rest outside the brain rather than within the grey matter. They produce better resolution signals than non-invasive BCIs where the bone tissue of the cranium deflects and deforms signals and have a lower risk of forming scar-tissue in the brain than fully invasive BCIs. There has been preclinical demonstration of intracortical BCIs from the stroke perilesional cortex.<ref name=\"robust neuroprosthetic\">{{cite journal | vauthors = Gulati T, Won SJ, Ramanathan DS, Wong CC, Bodepudi A, Swanson RA, Ganguly K | title = Robust neuroprosthetic control from the stroke perilesional cortex | journal = The Journal of Neuroscience | volume = 35 | issue = 22 | pages = 8653\u20138661 | date = June 2015 | pmid = 26041930 | pmc = 6605327 | doi = 10.1523/JNEUROSCI.5007-14.2015 }}</ref>\n\n====Endovascular====\nA systematic review published in 2020 detailed multiple studies, both clinical and non-clinical, dating back decades investigating the feasibility of endovascular BCIs.<ref>{{cite journal | vauthors = Soldozy S, Young S, Kumar JS, Capek S, Felbaum DR, Jean WC, Park MS, Syed HR | display-authors = 6 | title = A systematic review of endovascular stent-electrode arrays, a minimally invasive approach to brain-machine interfaces | language = en-US | journal = Neurosurgical Focus | volume = 49 | issue = 1 | pages = E3 | date = July 2020 | pmid = 32610291 | doi = 10.3171/2020.4.FOCUS20186 | s2cid = 220308983 }}</ref>\n\nIn recent years, the biggest advance in partially invasive BCIs has emerged in the area of interventional neurology.<ref name=\":7\" /> In 2010, researchers affiliated with University of Melbourne had begun developing a BCI that could be inserted via the vascular system. The Australian neurologist [[Thomas Oxley (Mount Sinai Hospital)]] conceived the idea for this BCI, called Stentrode, which has received funding from DARPA. Preclinical studies evaluated the technology in sheep.\n\nThe Stentrode, a monolithic stent electrode array, is designed to be delivered via an intravenous catheter under image-guidance to the [[superior sagittal sinus]], in the region which lies adjacent to [[motor cortex]].<ref name=\":4\">{{cite book | vauthors = Opie N | chapter = The StentrodeTM Neural Interface System|date=2021 | title = Brain-Computer Interface Research: A State-of-the-Art Summary 9|pages=127\u2013132| veditors = Guger C, Allison BZ, Tangermann M |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing |doi=10.1007/978-3-030-60460-8_13 |isbn = 978-3-030-60460-8 | s2cid = 234102889}}</ref> This proximity to [[motor cortex]] underlies the Stentrode's ability to measure neural activity. The procedure is most similar to how venous sinus stents are placed for the treatment of [[idiopathic intracranial hypertension]].<ref>{{cite journal | vauthors = Teleb MS, Cziep ME, Lazzaro MA, Gheith A, Asif K, Remler B, Zaidat OO | title = Idiopathic Intracranial Hypertension. A Systematic Analysis of Transverse Sinus Stenting | journal = Interventional Neurology | volume = 2 | issue = 3 | pages = 132\u2013143 | date = May 2014 | pmid = 24999351 | pmc = 4080637 | doi = 10.1159/000357503 }}</ref> The Stentrode communicates neural activity to a battery-less telemetry unit implanted in the chest, which communicates wirelessly with an external telemetry unit capable of power and data transfer. While an endovascular BCI benefits from avoiding craniotomy for insertion, risks such as [[Thrombus|clotting]] and [[venous thrombosis]] are possible. In pre-clinical animal studies implanted with Stentrode, twenty animals showed no evidence of thrombus formation after 190 days, possibly due to endothelial incorporation of the Stentrode into the vessel wall.<ref name=\":4\" />\n\nFirst-in-human trials with the Stentrode are underway.<ref name=\":4\" /> In November 2020, two participants with [[amyotrophic lateral sclerosis]] were able to wirelessly control an operating system to text, email, shop, and bank using direct thought through the Stentrode brain-computer interface,<ref>{{cite web | vauthors = Bryson S |title=Stentrode Device Allows Computer Control by ALS Patients with Partial Upper Limb Paralysis |url=https://alsnewstoday.com/news-posts/2020/11/05/stentrode-device-allows-computer-control-by-als-patients-with-partial-upper-limb-paralysis |website=ALS News Today}}</ref> marking the first time a brain-computer interface was implanted via the patient's blood vessels, eliminating the need for open brain surgery.\n\n====ECoG====\n''[[Electrocorticography]]'' (ECoG) measures the electrical activity of the brain taken from beneath the skull in a similar way to non-invasive electroencephalography, but the electrodes are embedded in a thin plastic pad that is placed above the cortex, beneath the [[dura mater]].<ref>{{cite book | last1=Serruya | first1=Mijail | last2=Donoghue | first2=John | chapter = Chapter III: Design Principles of a Neuromotor Prosthetic Device | title = Neuroprosthetics: Theory and Practice | veditors = Horch KW, Dhillon GS | publisher = Imperial College Press | year=2004 |pages=1158\u20131196 | doi=10.1142/9789812561763_0040 | archive-url=https://web.archive.org/web/20050404155139/http://donoghue.neuro.brown.edu/pubs/2003-SerruyaDonoghue-Chap3-preprint.pdf | archive-date=4 April 2005 |chapter-url=http://donoghue.neuro.brown.edu/pubs/2003-SerruyaDonoghue-Chap3-preprint.pdf}}</ref> ECoG technologies were first trialled in humans in 2004 by Eric Leuthardt and Daniel Moran from [[Washington University]] in [[St Louis]]. In a later trial, the researchers enabled a teenage boy to play [[Space Invaders]] using his ECoG implant.<ref>{{cite web | url = http://news-info.wustl.edu/news/page/normal/7800.html | title = Teenager moves video icons just by imagination | work = Press release | publisher = Washington University in St Louis | date = 9 October 2006 }}</ref> This research indicates that control is rapid, requires minimal training, and may be an ideal tradeoff with regards to signal fidelity and level of invasiveness.{{refn|group=note|These electrodes had not been implanted in the patient with the intention of developing a BCI. The patient had had severe [[epilepsy]] and the electrodes were temporarily implanted to help his physicians localize seizure foci; the BCI researchers simply took advantage of this.<ref>{{cite journal | vauthors = Schalk G, Miller KJ, Anderson NR, Wilson JA, Smyth MD, Ojemann JG, Moran DW, Wolpaw JR, Leuthardt EC | display-authors = 6 | title = Two-dimensional movement control using electrocorticographic signals in humans | journal = Journal of Neural Engineering | volume = 5 | issue = 1 | pages = 75\u201384 | date = March 2008 | pmid = 18310813 | pmc = 2744037 | doi = 10.1088/1741-2560/5/1/008 | bibcode = 2008JNEng...5...75S }}</ref>}}\n\nSignals can be either subdural or epidural, but are not taken from within the brain [[parenchyma]] itself. It has not been studied extensively until recently due to the limited access of subjects. Currently, the only manner to acquire the signal for study is through the use of patients requiring invasive monitoring for localization and resection of an epileptogenic focus.\n\nECoG is a very promising intermediate BCI modality because it has higher spatial resolution, better signal-to-noise ratio, wider frequency range, and less training requirements than scalp-recorded EEG, and at the same time has lower technical difficulty, lower clinical risk, and may have superior long-term stability than intracortical single-neuron recording.<ref>{{cite journal | vauthors = Nicolas-Alonso LF, Gomez-Gil J | title = Brain computer interfaces, a review | journal = Sensors | volume = 12 | issue = 2 | pages = 1211\u20131279 | date = 2012-01-31 | pmid = 22438708 | pmc = 3304110 | doi = 10.3390/s120201211 | bibcode = 2012Senso..12.1211N | doi-access = free }}</ref> This feature profile and recent evidence of the high level of control with minimal training requirements shows potential for real world application for people with motor disabilities.<ref name=Mondeofuse>{{cite news | vauthors = Yanagisawa T |title=Electrocorticographic Control of Prosthetic Arm in Paralyzed Patients |doi=10.1002/ana.22613 |quote= ECoG- Based BCI has advantage in signal and durability that are absolutely necessary for clinical application|work=[[American Neurological Association]] |year= 2011 |volume=71 |issue=3 |pages=353\u2013361 }}</ref><ref name=TelepathicCommVowel>{{cite news | vauthors = Pei X |title=Decoding Vowels and Consonants in Spoken and Imagined Words Using Electrocorticographic Signals in Humans |pmid=21750369 |quote= Justin Williams, a biomedical engineer at the university, has already transformed the ECoG implant into a micro device that can be installed with a minimum of fuss. It has been tested in animals for a long period of time \u2013 the micro ECoG stays in place and doesn't seem to negatively affect the immune system.|work=J Neural Eng 046028th ser. 8.4 |year=2011 }}</ref> Light reactive imaging BCI devices are still in the realm of theory.\n\nRecent work published by [[Edward Chang (neurosurgeon)|Edward Chang]] and Joseph Makin from [[UCSF Medical Center|UCSF]] revealed that ECoG signals could be used to decode speech from epilepsy patients implanted with high-density ECoG arrays over the peri-Sylvian cortices.<ref>{{cite book | vauthors = Makin JG, Moses DA, Chang EF | veditors = Guger C, Allison BZ, Gunduz A | chapter = Speech Decoding as Machine Translation|date=2021 | title = Brain-Computer Interface Research: A State-of-the-Art Summary 10|pages=23\u201333 |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing |language=en |doi=10.1007/978-3-030-79287-9_3 |isbn=978-3-030-79287-9 | s2cid = 239756345 }}</ref><ref>{{cite journal | vauthors = Makin JG, Moses DA, Chang EF | title = Machine translation of cortical activity to text with an encoder-decoder framework | journal = Nature Neuroscience | volume = 23 | issue = 4 | pages = 575\u2013582 | date = April 2020 | pmid = 32231340 | doi = 10.1038/s41593-020-0608-8 | s2cid = 214704481 }}</ref> Their study achieved word error rates of 3% (a marked improvement from prior publications) utilizing an encoder-decoder [[neural network]], which translated ECoG data into one of fifty sentences composed of 250 unique words.\n\n===Non-invasive BCIs===\nThere have also been experiments in humans using [[non-invasive (medical)|non-invasive]] [[neuroimaging]] technologies as interfaces. The substantial majority of published BCI work involves noninvasive EEG-based BCIs. Noninvasive EEG-based technologies and interfaces have been used for a much broader variety of applications. Although EEG-based interfaces are easy to wear and do not require surgery, they have relatively poor spatial resolution and cannot effectively use higher-frequency signals because the skull dampens signals, dispersing and blurring the electromagnetic waves created by the neurons. EEG-based interfaces also require some time and effort prior to each usage session, whereas non-EEG-based ones, as well as invasive ones require no prior-usage training. Overall, the best BCI for each user depends on numerous factors.\n\n==== Non-EEG-based human\u2013computer interface ====\n\n=====Electrooculography (EOG)=====\nIn 1989, a report was given on control of a mobile robot by eye movement using [[electrooculography]] (EOG) signals. A mobile robot was driven from a start to a goal point using five EOG commands, interpreted as forward, backward, left, right, and stop.<ref>{{cite book | vauthors = Bozinovski S | year = 2017 | chapter = Signal Processing Robotics Using Signals Generated by a Human Head: From Pioneering Works to EEG-Based Emulation of Digital Circuits | title = Advances in Robot Design and Intelligent Control | series = Advances in Intelligent Systems and Computing | volume = 540 | pages = 449\u2013462 |doi=10.1007/978-3-319-49058-8_49| isbn = 978-3-319-49057-1}}</ref> The EOG as a challenge of controlling external objects was presented by Vidal in his 1973 paper.<ref name=\"Vidal1\"/>\n\n=====Pupil-size oscillation=====\nA 2016 article<ref>{{cite journal | vauthors = Math\u00f4t S, Melmi JB, van der Linden L, Van der Stigchel S | title = The Mind-Writing Pupil: A Human-Computer Interface Based on Decoding of Covert Attention through Pupillometry | journal = PLOS ONE | volume = 11 | issue = 2 | pages = e0148805 | year = 2016 | pmid = 26848745 | pmc = 4743834 | doi = 10.1371/journal.pone.0148805 | doi-access = free | bibcode = 2016PLoSO..1148805M }}</ref> described an entirely new communication device and non-EEG-based human-computer interface, which requires no [[Fixation (visual)|visual fixation]], or ability to move the eyes at all. The interface is based on covert [[interest (emotion)|interest]]; directing one's attention to a chosen letter on a virtual keyboard, without the need to move one's eyes to look directly at the letter. Each letter has its own (background) circle which micro-oscillates in brightness differently from all of the other letters. The letter selection is based on best fit between unintentional pupil-size oscillation and the background circle's brightness oscillation pattern. Accuracy is additionally improved by the user's mental rehearsing of the words 'bright' and 'dark' in synchrony with the brightness transitions of the letter's circle.\n\n====Functional near-infrared spectroscopy====\nIn 2014 and 2017, a BCI using [[functional near-infrared spectroscopy]] for \"locked-in\" patients with [[amyotrophic lateral sclerosis]] (ALS) was able to restore some basic ability of the patients to communicate with other people.<ref>{{cite journal | vauthors = Gallegos-Ayala G, Furdea A, Takano K, Ruf CA, Flor H, Birbaumer N | title = Brain communication in a completely locked-in patient using bedside near-infrared spectroscopy | journal = Neurology | volume = 82 | issue = 21 | pages = 1930\u20131932 | date = May 2014 | pmid = 24789862 | pmc = 4049706 | doi = 10.1212/WNL.0000000000000449 }}</ref><ref name=\"RamseyChaudhary2017\">{{cite journal | vauthors = Chaudhary U, Xia B, Silvoni S, Cohen LG, Birbaumer N | title = Brain-Computer Interface-Based Communication in the Completely Locked-In State | journal = PLOS Biology | volume = 15 | issue = 1 | pages = e1002593 | date = January 2017 | pmid = 28141803 | pmc = 5283652 | doi = 10.1371/journal.pbio.1002593 }}</ref>\n\n====Electroencephalography (EEG)-based brain-computer interfaces====\n\n[[File:ElectroEncephalogram.png|thumb|Recordings of brainwaves produced by an [[electroencephalogram]]]]\n\nAfter the BCI challenge was stated by Vidal in 1973, the initial reports on non-invasive approach included control of a cursor in 2D using VEP (Vidal 1977), control of a buzzer using CNV (Bozinovska et al. 1988, 1990), control of a physical object, a robot, using a brain rhythm (alpha) (Bozinovski et al. 1988), control of a text written on a screen using P300 (Farwell and Donchin, 1988).<ref name=\"Bozinovski1\"/>\n\nIn the early days of BCI research, another substantial barrier to using [[electroencephalography]] (EEG) as a brain\u2013computer interface was the extensive training required before users can work the technology. For example, in experiments beginning in the mid-1990s, Niels Birbaumer at the [[University of T\u00fcbingen]] in [[Germany]] trained severely paralysed people to self-regulate the ''slow cortical potentials'' in their EEG to such an extent that these signals could be used as a binary signal to control a computer cursor.<ref>{{Cite magazine |url=http://www.psychologytoday.com/articles/200307/communicating-brain-waves |title=Communicating by Brain Waves |magazine=Psychology Today |date=May 2003 |first=Jeffrey |last=Winters}}</ref> (Birbaumer had earlier trained [[epilepsy|epileptics]] to prevent impending fits by controlling this low voltage wave.) The experiment saw ten patients trained to move a computer cursor by controlling their brainwaves. The process was slow, requiring more than an hour for patients to write 100 characters with the cursor, while training often took many months. However, the slow cortical potential approach to BCIs has not been used in several years, since other approaches require little or no training, are faster and more accurate, and work for a greater proportion of users.\n\nAnother research parameter is the type of [[neural oscillation|oscillatory activity]] that is measured. Gert Pfurtscheller founded the BCI Lab 1991 and fed his research results on motor imagery in the first online BCI based on oscillatory features and classifiers. Together with Birbaumer and Jonathan Wolpaw at [[New York State University]] they focused on developing technology that would allow users to choose the brain signals they found easiest to operate a BCI, including ''[[Mu wave|mu]]'' and ''[[Beta wave|beta]]'' rhythms.\n\nA further parameter is the method of feedback used and this is shown in studies of [[P300 (Neuroscience)|P300]] signals. Patterns of P300 waves are generated involuntarily ([[Event-related potential|stimulus-feedback]]) when people see something they recognize and may allow BCIs to decode categories of thoughts without training patients first. By contrast, the [[biofeedback]] methods described above require learning to control brainwaves so the resulting brain activity can be detected.\n\nIn 2005 it was reported research on EEG emulation of digital control circuits for BCI, with example of a CNV flip-flop.<ref>Adrijan Bozinovski \"CNV flip-flop as a brain-computer interface paradigm\" In J. Kern, S. Tonkovic, et al. (Eds) Proc 7th Conference of the Croatian Association of Medical Informatics, pp. 149-154, Rijeka, 2005</ref> In 2009 it was reported noninvasive EEG control of a robotic arm using a CNV flip-flop.<ref>{{cite conference | last1=Bozinovski | first1=Adrijan | last2=Bozinovska | first2=Liljana | title=Anticipatory brain potentials in a Brain-Robot Interface paradigm | publisher=IEEE | year=2009 | doi=10.1109/ner.2009.5109330 | pages=451\u2013454 |conference=2009 4th International IEEE/EMBS Conference on Neural Engineering}}</ref> In 2011 it was reported control of two robotic arms solving Tower of Hanoi task with three disks using a CNV flip-flop.<ref>{{cite journal | last1=Bo\u017einovski | first1=Adrijan | last2=Tonkovi\u0107 | first2=Stanko | last3=I\u0161gum | first3=Velimir | last4=Bo\u017einovska | first4=Liljana | title=Robot Control Using Anticipatory Brain Potentials | journal=Automatika | volume=52 | issue=1 | year=2011 | doi=10.1080/00051144.2011.11828400 | pages=20\u201330 | s2cid=33223634 | language=en |url=https://hrcak.srce.hr/file/106106}}</ref> In 2015 it was described EEG-emulation of a Schmitt trigger, flip-flop, demultiplexer, and modem.<ref>{{cite journal | last1=Bozinovski | first1=Stevo | last2=Bozinovski | first2=Adrijan | title=Mental States, EEG Manifestations, and Mentally Emulated Digital Circuits for Brain-Robot Interaction | journal=IEEE Transactions on Autonomous Mental Development | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=7 | issue=1 | year=2015 | issn=1943-0604 | doi=10.1109/tamd.2014.2387271 | pages=39\u201351| s2cid=21464338 }}</ref>\n\n\nWhile an EEG based brain-computer interface has been pursued extensively by a number of research labs, recent advancements made by [[Bin He]] and his team at the [[University of Minnesota]] suggest the potential of an EEG based brain-computer interface to accomplish tasks close to invasive brain-computer interface. Using advanced functional neuroimaging including BOLD functional [[MRI]] and [[EEG]] source imaging, Bin He and co-workers identified the co-variation and co-localization of electrophysiological and hemodynamic signals induced by motor imagination.<ref>{{cite journal | vauthors = Yuan H, Liu T, Szarkowski R, Rios C, Ashe J, He B | title = Negative covariation between task-related responses in alpha/beta-band activity and BOLD in human sensorimotor cortex: an EEG and fMRI study of motor imagery and movements | journal = NeuroImage | volume = 49 | issue = 3 | pages = 2596\u20132606 | date = February 2010 | pmid = 19850134 | pmc = 2818527 | doi = 10.1016/j.neuroimage.2009.10.028 }}</ref>\nRefined by a neuroimaging approach and by a training protocol, Bin He and co-workers demonstrated the ability of a non-invasive EEG based brain-computer interface to control the flight of a virtual helicopter in 3-dimensional space, based upon motor imagination.<ref>{{cite journal | vauthors = Doud AJ, Lucas JP, Pisansky MT, He B | title = Continuous three-dimensional control of a virtual helicopter using a motor imagery based brain-computer interface | journal = PLOS ONE | volume = 6 | issue = 10 | pages = e26322 | year = 2011 | pmid = 22046274 | pmc = 3202533 | doi = 10.1371/journal.pone.0026322 | veditors = Gribble PL | doi-access = free | bibcode = 2011PLoSO...626322D }}</ref> In June 2013 it was announced that Bin He had developed the technique to enable a remote-control helicopter to be guided through an obstacle course.<ref>{{cite web |url=https://www.bbc.co.uk/news/science-environment-22764978 |title=Thought-guided helicopter takes off |work=BBC News |date=5 June 2013 |access-date=5 June 2013}}</ref>\n\nIn addition to a brain-computer interface based on brain waves, as recorded from scalp EEG electrodes, Bin He and co-workers explored a virtual EEG signal-based brain-computer interface by first solving the EEG [[inverse problem]] and then used the resulting virtual EEG for brain-computer interface tasks. Well-controlled studies suggested the merits of such a source analysis based brain-computer interface.<ref>{{cite journal | vauthors = Qin L, Ding L, He B | title = Motor imagery classification by means of source analysis for brain-computer interface applications | journal = Journal of Neural Engineering | volume = 1 | issue = 3 | pages = 135\u2013141 | date = September 2004 | pmid = 15876632 | pmc = 1945182 | doi = 10.1088/1741-2560/1/3/002 | bibcode = 2004JNEng...1..135Q }}</ref>\n\nA 2014 study found that severely motor-impaired patients could communicate faster and more reliably with non-invasive EEG BCI, than with any muscle-based communication channel.<ref>{{cite journal | vauthors = H\u00f6hne J, Holz E, Staiger-S\u00e4lzer P, [[Klaus-Robert M\u00fcller|M\u00fcller KR]], K\u00fcbler A, Tangermann M | title = Motor imagery for severely motor-impaired patients: evidence for brain-computer interfacing as superior control solution | journal = PLOS ONE | volume = 9 | issue = 8 | pages = e104854 | date = 2014 | pmid = 25162231 | pmc = 4146550 | doi = 10.1371/journal.pone.0104854 | doi-access = free | bibcode = 2014PLoSO...9j4854H }}</ref>\n\nA 2016 study found that the Emotiv EPOC device may be more suitable for control tasks using the attention/meditation level or eye blinking than the Neurosky MindWave device.<ref name=\"MaskeliunasDamasevicius2016\">{{cite journal | vauthors = Maskeliunas R, Damasevicius R, Martisius I, Vasiljevas M | title = Consumer-grade EEG devices: are they usable for control tasks? | journal = PeerJ | volume = 4 | pages = e1746 | year = 2016 | pmid = 27014511 | pmc = 4806709 | doi = 10.7717/peerj.1746 | doi-access = free }}</ref>\n\nA 2019 study found that the application of evolutionary algorithms could improve EEG mental state classification with a non-invasive [[Muse (headband)|Muse]] device, enabling high quality classification of data acquired by a cheap consumer-grade EEG sensing device.<ref>{{cite journal | vauthors = Bird JJ, Faria DR, Manso LJ, Ek\u00e1rt A, Buckingham CD | title=A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for Brain-Machine Interaction | journal=Complexity | publisher=Hindawi Limited | volume=2019 | date=2019-03-13 | issn=1076-2787 | doi=10.1155/2019/4316548 | pages=1\u201314| arxiv=1908.04784 | doi-access=free }}</ref>\n\nIn a 2021 systematic review of randomized controlled trials using BCI for upper-limb rehabilitation after stroke, EEG-based BCI was found to have significant efficacy in improving upper-limb motor function compared to control therapies. More specifically, BCI studies that utilized band power features, motor imagery, and functional electrical stimulation in their design were found to be more efficacious than alternatives.<ref>{{cite journal | vauthors = Mansour S, Ang KK, Nair KP, Phua KS, Arvaneh M | title = Efficacy of Brain-Computer Interface and the Impact of Its Design Characteristics on Poststroke Upper-limb Rehabilitation: A Systematic Review and Meta-analysis of Randomized Controlled Trials | journal = Clinical EEG and Neuroscience | volume = 53 | issue = 1 | pages = 79\u201390 | date = January 2022 | pmid = 33913351 | doi = 10.1177/15500594211009065 | pmc = 8619716 | s2cid = 233446181 }}</ref> Another 2021 systematic review focused on robotic-assisted EEG-based BCI for hand rehabilitation after stroke. Improvement in motor assessment scores was observed in three of eleven studies included in the systematic review.<ref>{{cite journal | vauthors = Baniqued PD, Stanyer EC, Awais M, Alazmani A, Jackson AE, Mon-Williams MA, Mushtaq F, Holt RJ | display-authors = 6 | title = Brain-computer interface robotics for hand rehabilitation after stroke: a systematic review | journal = Journal of Neuroengineering and Rehabilitation | volume = 18 | issue = 1 | pages = 15 | date = January 2021 | pmid = 33485365 | pmc = 7825186 | doi = 10.1186/s12984-021-00820-8 }}</ref>\n\n====Dry active electrode arrays====\nIn the early 1990s Babak Taheri, at [[University of California, Davis]] demonstrated the first single and also multichannel dry active electrode arrays using micro-machining. The single channel dry EEG electrode construction and results were published in 1994.<ref>{{cite journal | vauthors = Taheri BA, Knight RT, Smith RL | title = A dry electrode for EEG recording | journal = Electroencephalography and Clinical Neurophysiology | volume = 90 | issue = 5 | pages = 376\u2013383 | date = May 1994 | pmid = 7514984 | doi = 10.1016/0013-4694(94)90053-1 | url = https://zenodo.org/record/1253862 }}</ref> The arrayed electrode was also demonstrated to perform well compared to [[silver]]/[[silver chloride]] electrodes. The device consisted of four sites of sensors with integrated electronics to reduce noise by [[impedance matching]]. The advantages of such electrodes are: (1) no electrolyte used, (2) no skin preparation, (3) significantly reduced sensor size, and (4) compatibility with EEG monitoring systems. The active electrode array is an integrated system made of an array of capacitive sensors with local integrated circuitry housed in a package with batteries to power the circuitry. This level of integration was required to achieve the functional performance obtained by the electrode.\n\nThe electrode was tested on an electrical test bench and on human subjects in four modalities of EEG activity, namely: (1) spontaneous EEG, (2) sensory event-related potentials, (3) brain stem potentials, and (4) cognitive event-related potentials. The performance of the dry electrode compared favorably with that of the standard wet electrodes in terms of skin preparation, no gel requirements (dry), and higher signal-to-noise ratio.<ref>{{cite thesis | bibcode=1994PhDT........82A |title=Active Micromachined Scalp Electrode Array for Eeg Signal Recording | vauthors = Alizadeh-Taheri B | degree =PHD Thesis |year=1994|page=82}}</ref>\n\nIn 1999 researchers at [[Case Western Reserve University]], in [[Cleveland]], [[Ohio]], led by Hunter Peckham, used 64-electrode EEG skullcap to return limited hand movements to [[quadriplegic]] Jim Jatich. As Jatich concentrated on simple but opposite concepts like up and down, his beta-rhythm EEG output was analysed using software to identify patterns in the noise. A basic pattern was identified and used to control a switch: Above average activity was set to on, below average off. As well as enabling Jatich to control a computer cursor the signals were also used to drive the nerve controllers embedded in his hands, restoring some movement.<ref>{{Cite magazine |url=https://www.wired.com/wired/archive/9.08/assist_pr.html |title=The Next Brainiacs |magazine=Wired |date=August 2001 |volume=9 |issue=8 |first=John |last=Hockenberry}}</ref>\n\n==== SSVEP mobile EEG BCIs ====\nIn 2009, the NCTU Brain-Computer-Interface-headband was reported. The researchers who developed this BCI-headband also engineered silicon-based [[Microelectromechanical systems|'''m'''icro'''e'''lectro-'''m'''echanical '''s'''ystem]] (MEMS) [[Electroencephalography#Dry EEG electrodes|dry electrodes]] designed for application in non-hairy sites of the body. These electrodes were secured to the [[Data acquisition|DAQ]] board in the headband with snap-on electrode holders. The signal processing module measured [[Alpha wave|alpha]] activity and the Bluetooth enabled phone assessed the patients' alertness and capacity for cognitive performance. When the subject became drowsy, the phone sent arousing feedback to the operator to rouse them. This research was supported by the National Science Council, Taiwan, R.O.C., NSC, National Chiao-Tung University, Taiwan's Ministry of Education, and the [[United States Army Research Laboratory|U.S. Army Research Laboratory]].<ref>{{Citation| vauthors = Lin CT, Ko LW, Chang CJ, Wang YT, Chung CH, Yang FS, Duann JR, Jung TP, Chiou JC | display-authors = 6 |title=Wearable and Wireless Brain-Computer Interface and Its Applications |date=2009 |work=Foundations of Augmented Cognition. Neuroergonomics and Operational Neuroscience| series = Lecture Notes in Computer Science | volume = 5638 |pages=741\u2013748|publisher=Springer Berlin Heidelberg|doi=10.1007/978-3-642-02812-0_84|isbn=978-3-642-02811-3|s2cid=14515754}}</ref>\n\nIn 2011, researchers reported a cellular based BCI with the capability of taking EEG data and converting it into a command to cause the phone to ring. This research was supported in part by [[Abraxis BioScience|Abraxis Bioscience]] LLP, the U.S. Army Research Laboratory, and the Army Research Office. The developed technology was a wearable system composed of a four channel bio-signal acquisition/amplification [[Modular design|module]], a wireless transmission module, and a Bluetooth enabled cell phone.&nbsp; The electrodes were placed so that they pick up steady state visual evoked potentials ([[Steady state visually evoked potential|SSVEPs]]).<ref name=\":1\">{{cite journal | vauthors = Wang YT, Wang Y, Jung TP | title = A cell-phone-based brain-computer interface for communication in daily life | journal = Journal of Neural Engineering | volume = 8 | issue = 2 | pages = 025018 | date = April 2011 | pmid = 21436517 | doi = 10.1088/1741-2560/8/2/025018 | s2cid = 10943518 | bibcode = 2011JNEng...8b5018W }}</ref> SSVEPs are electrical responses to flickering visual stimuli with repetition rates over 6&nbsp;Hz<ref name=\":1\" /> that are best found in the parietal and occipital scalp regions of the visual cortex.<ref>{{cite journal | vauthors = Guger C, Allison BZ, Gro\u00dfwindhager B, Pr\u00fcckl R, Hinterm\u00fcller C, Kapeller C, Bruckner M, Krausz G, Edlinger G | display-authors = 6 | title = How Many People Could Use an SSVEP BCI? | journal = Frontiers in Neuroscience | volume = 6 | pages = 169 | date = 2012 | pmid = 23181009 | pmc = 3500831 | doi = 10.3389/fnins.2012.00169 | doi-access = free }}</ref><ref name=\":2\">{{cite journal | vauthors = Lin YP, Wang Y, Jung TP | title = A mobile SSVEP-based brain-computer interface for freely moving humans: the robustness of canonical correlation analysis to motion artifacts | journal = Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference | volume = 2013 | pages = 1350\u20131353 | year = 2013 | pmid = 24109946 | doi = 10.1109/EMBC.2013.6609759 | isbn = 978-1-4577-0216-7 | s2cid = 23136360 }}</ref><ref>{{cite journal | vauthors = Rashid M, Sulaiman N, Abdul Majeed AP, Musa RM, Ab Nasir AF, Bari BS, Khatun S | title = Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review | journal = Frontiers in Neurorobotics | volume = 14 | pages = 25 | date = 2020 | pmid = 32581758 | pmc = 7283463 | doi = 10.3389/fnbot.2020.00025 | doi-access = free }}</ref> It was reported that with this BCI setup, all study participants were able to initiate the phone call with minimal practice in natural environments.<ref>{{cite patent | country = US | number = 20130127708 | gdate = 23 May 2013 }}</ref>\n\nThe scientists claim that their studies using a single channel fast Fourier transform ([[Fast Fourier transform|FFT]]) and multiple channel system canonical correlation analysis ([[Canonical correlation|CCA]]) algorithm support the capacity of mobile BCIs.<ref name=\":1\" /><ref name=\":3\">{{cite journal | vauthors = Wang YT, Wang Y, Cheng CK, Jung TP | title = Developing stimulus presentation on mobile devices for a truly portable SSVEP-based BCI | journal = Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference | volume = 2013 | pages = 5271\u20135274 | year = 2013 | pmid = 24110925 | doi = 10.1109/EMBC.2013.6610738 | isbn = 978-1-4577-0216-7 | s2cid = 14324159 }}</ref> The CCA algorithm has been applied in other experiments investigating BCIs with claimed high performance in accuracy as well as speed.<ref>{{cite journal | vauthors = Bin G, Gao X, Yan Z, Hong B, Gao S | title = An online multi-channel SSVEP-based brain-computer interface using a canonical correlation analysis method | journal = Journal of Neural Engineering | volume = 6 | issue = 4 | pages = 046002 | date = August 2009 | pmid = 19494422 | doi = 10.1088/1741-2560/6/4/046002 | bibcode = 2009JNEng...6d6002B | s2cid = 32640699 }}</ref> While the cellular based BCI technology was developed to initiate a phone call from SSVEPs, the researchers said that it can be translated for other applications, such as picking up sensorimotor [[Mu wave|mu]]/[[Beta wave|beta]] rhythms to function as a motor-imagery based BCI.<ref name=\":1\" />\n\nIn 2013, comparative tests were performed on android cell phone, tablet, and computer based BCIs, analyzing the power [[Spectral density|spectrum density]] of resultant EEG SSVEPs. The stated goals of this study, which involved scientists supported in part by the U.S. Army Research Laboratory, were to \"increase the practicability, portability, and ubiquity of an SSVEP-based BCI, for daily use\". Citation It was reported that the stimulation frequency on all mediums was accurate, although the cell phone's signal demonstrated some instability. The amplitudes of the SSVEPs for the laptop and tablet were also reported to be larger than those of the cell phone. These two qualitative characterizations were suggested as indicators of the feasibility of using a mobile stimulus BCI.<ref name=\":3\" />\n\n==== Limitations ====\nIn 2011, researchers stated that continued work should address ease of use, performance robustness, reducing hardware and software costs.<ref name=\":1\" />\n\nOne of the difficulties with EEG readings is the large susceptibility to motion artifacts.<ref>{{cite journal | vauthors = Symeonidou ER, Nordin AD, Hairston WD, Ferris DP | title = Effects of Cable Sway, Electrode Surface Area, and Electrode Mass on Electroencephalography Signal Quality during Motion | journal = Sensors | volume = 18 | issue = 4 | pages = 1073 | date = April 2018 | pmid = 29614020 | pmc = 5948545 | doi = 10.3390/s18041073 | doi-access = free | bibcode = 2018Senso..18.1073S }}</ref> In most of the previously described research projects, the participants were asked to sit still, reducing head and eye movements as much as possible, and measurements were taken in a laboratory setting. However, since the emphasized application of these initiatives had been in creating a mobile device for daily use,<ref name=\":3\" /> the technology had to be tested in motion.\n\nIn 2013, researchers tested mobile EEG-based BCI technology, measuring SSVEPs from participants as they walked on a treadmill at varying speeds. This research was supported by the [[Office of Naval Research]], Army Research Office, and the U.S. Army Research Laboratory. Stated results were that as speed increased the SSVEP detectability using CCA decreased. As independent component analysis ([[Independent component analysis|ICA]]) had been shown to be efficient in separating EEG signals from noise,<ref>{{cite journal | vauthors = Wang Y, Wang R, Gao X, Hong B, Gao S | title = A practical VEP-based brain-computer interface | journal = IEEE Transactions on Neural Systems and Rehabilitation Engineering | volume = 14 | issue = 2 | pages = 234\u2013239 | date = June 2006 | pmid = 16792302 | doi = 10.1109/TNSRE.2006.875576 }}</ref> the scientists applied ICA to CCA extracted EEG data. They stated that the CCA data with and without ICA processing were similar. Thus, they concluded that CCA independently demonstrated a robustness to motion artifacts that indicates it may be a beneficial algorithm to apply to BCIs used in real world conditions.<ref name=\":2\" />\nOne of the major problems in EEG-based BCI applications is the low spatial resolution. Several solutions have been suggested to address this issue since 2019, which include: EEG source connectivity based on graph theory, EEG pattern recognition based on Topomap, EEG-fMRI fusion, and so on.\n\n====Prosthesis and environment control====\nNon-invasive BCIs have also been applied to enable brain-control of prosthetic upper and lower extremity devices in people with paralysis. For example, Gert Pfurtscheller of [[Graz University of Technology]] and colleagues demonstrated a BCI-controlled [[functional electrical stimulation]] system to restore upper extremity movements in a person with tetraplegia due to [[spinal cord injury]].<ref>{{cite journal | vauthors = Pfurtscheller G, M\u00fcller GR, Pfurtscheller J, Gerner HJ, Rupp R | title = 'Thought'--control of functional electrical stimulation to restore hand grasp in a patient with tetraplegia | journal = Neuroscience Letters | volume = 351 | issue = 1 | pages = 33\u201336 | date = November 2003 | pmid = 14550907 | doi = 10.1016/S0304-3940(03)00947-9 | s2cid = 38568963 }}</ref> Between 2012 and 2013, researchers at the [[University of California, Irvine]] demonstrated for the first time that it is possible to use BCI technology to restore brain-controlled walking after spinal cord injury. In their [[spinal cord injury research]] study, a person with paraplegia was able to operate a BCI-robotic gait orthosis to regain basic brain-controlled ambulation.<ref name=\"DoWang2013\">{{cite journal | vauthors = Do AH, Wang PT, King CE, Chun SN, Nenadic Z | title = Brain-computer interface controlled robotic gait orthosis | journal = Journal of Neuroengineering and Rehabilitation | volume = 10 | issue = 1 | pages = 111 | date = December 2013 | pmid = 24321081 | pmc = 3907014 | doi = 10.1186/1743-0003-10-111 }}</ref><ref>[https://www.youtube.com/watch?v=HXNCwonhjG8 Subject with Paraplegia Operates BCI-controlled RoGO (4x)] at YouTube.com</ref>\nIn 2009 Alex Blainey, an independent researcher based in the UK, successfully used the [[Emotiv]] EPOC to control a 5 axis robot arm.<ref>[https://www.youtube.com/watch?v=4Cq35VbRpTY Alex Blainey controls a cheap consumer robot arm using the EPOC headset via a serial relay port] at YouTube.com</ref> He then went on to make several demonstration mind controlled wheelchairs and [[home automation]] that could be operated by people with limited or no motor control such as those with paraplegia and cerebral palsy.\n\nResearch into military use of BCIs funded by [[DARPA]] has been ongoing since the 1970s.<ref name=\"Vidal1\" /><ref name=\"Vidal2\" /> The current focus of research is user-to-user communication through analysis of neural signals.<ref>{{cite magazine |last=Drummond |first=Katie | title = Pentagon Preps Soldier Telepathy Push| magazine =Wired |date = 14 May 2009| url =https://www.wired.com/dangerroom/2009/05/pentagon-preps-soldier-telepathy-push| access-date = 6 May 2009}}</ref>\n\n====DIY and open source BCI====\nIn 2001, The OpenEEG Project<ref>{{cite web|url=http://openeeg.sourceforge.net/doc/ |title=The OpenEEG Project |publisher=Openeeg.sourceforge.net |access-date=19 December 2016}}</ref> was initiated by a group of DIY neuroscientists and engineers. The ModularEEG was the primary device created by the OpenEEG community; it was a 6-channel signal capture board that cost between $200 and $400 to make at home. The OpenEEG Project marked a significant moment in the emergence of DIY brain-computer interfacing.\n\nIn 2010, the Frontier Nerds of NYU's ITP program published a thorough tutorial titled How To Hack Toy EEGs.<ref>{{cite web|url=http://www.frontiernerds.com/brain-hack |title=How To Hack Toy EEGs |publisher=Frontiernerds.com |access-date=19 December 2016}}</ref> The tutorial, which stirred the minds of many budding DIY BCI enthusiasts, demonstrated how to create a single channel at-home EEG with an [[Arduino]] and a Mattel [[Mindflex]] at a very reasonable price. This tutorial amplified the DIY BCI movement.\n\n====MEG and MRI====\n{{Main|Magnetoencephalography|Magnetic resonance imaging}}\n\n<noinclude>[[File:Visual stimulus reconstruction using fMRI.png|thumb|ATR Labs' reconstruction of human vision using [[functional magnetic resonance imaging|fMRI]] (top row: original image; bottom row: reconstruction from mean of combined readings)]]</noinclude>\n\n[[Magnetoencephalography]] (MEG) and [[functional magnetic resonance imaging]] (fMRI) have both been used successfully as non-invasive BCIs.<ref>Ranganatha Sitaram, Andrea Caria, Ralf Veit, Tilman Gaber, Giuseppina Rota, Andrea Kuebler and Niels Birbaumer(2007) \"[https://archive.today/20120731202844/http://mts.hindawi.com/utils/GetFile.aspx?msid=25487&vnum=2&ftype=manuscript FMRI Brain\u2013Computer Interface: A Tool for Neuroscientific Research and Treatment]\"</ref> In a widely reported experiment, fMRI allowed two users being scanned to play [[Pong]] in real-time by altering their [[haemodynamic response]] or brain blood flow through [[biofeedback]] techniques.<ref>{{cite journal|doi=10.1038/news040823-18|title=Mental ping-pong could aid paraplegics|journal=News@nature|date=27 August 2004 | last = Peplow |first=Mark }}</ref>\n\nfMRI measurements of haemodynamic responses in real time have also been used to control robot arms with a seven-second delay between thought and movement.<ref>{{cite web | url = http://techon.nikkeibp.co.jp/english/NEWS_EN/20060525/117493/ | title = To operate robot only with brain, ATR and Honda develop BMI base technology | work = Tech-on | date = 26 May 2006 | access-date = 22 September 2006 | archive-date = 23 June 2017 | archive-url = https://web.archive.org/web/20170623060519/http://techon.nikkeibp.co.jp/english/NEWS_EN/20060525/117493/ | url-status = dead }}</ref>\n\nIn 2008 research developed in the Advanced Telecommunications Research (ATR) [[Computational Neuroscience]] Laboratories in [[Kyoto]], Japan, allowed the scientists to reconstruct images directly from the brain and display them on a computer in black and white at a [[Display resolution|resolution]] of 10x10 [[pixels]]. The article announcing these achievements was the [[Article (publishing)|cover story]] of the journal [[Neuron (journal)|Neuron]] of 10 December 2008.<ref>{{cite journal | vauthors = Miyawaki Y, Uchida H, Yamashita O, Sato MA, Morito Y, Tanabe HC, Sadato N, Kamitani Y | display-authors = 6 | title = Visual image reconstruction from human brain activity using a combination of multiscale local image decoders | journal = Neuron | volume = 60 | issue = 5 | pages = 915\u2013929 | date = December 2008 | pmid = 19081384 | doi = 10.1016/j.neuron.2008.11.004 | s2cid = 17327816 | doi-access = free }}</ref>\n\nIn 2011 researchers from [[University of California, Berkeley|UC Berkeley]] published<ref>{{cite journal | vauthors = Nishimoto S, Vu AT, Naselaris T, Benjamini Y, Yu B, Gallant JL | title = Reconstructing visual experiences from brain activity evoked by natural movies | journal = Current Biology | volume = 21 | issue = 19 | pages = 1641\u20131646 | date = October 2011 | pmid = 21945275 | pmc = 3326357 | doi = 10.1016/j.cub.2011.08.031 }}</ref> a study reporting second-by-second reconstruction of videos watched by the study's subjects, from fMRI data. This was achieved by creating a statistical model relating visual patterns in videos shown to the subjects, to the brain activity caused by watching the videos. This model was then used to look up the 100 one-second video segments, in a database of 18 million seconds of random [[YouTube]] videos, whose visual patterns most closely matched the brain activity recorded when subjects watched a new video. These 100 one-second video extracts were then combined into a mashed-up image that resembled the video being watched.<ref>{{cite magazine | url = http://blogs.scientificamerican.com/observations/2011/09/22/breakthrough-could-enable-others-to-watch-your-dreams-and-memories-video/ | title= Breakthrough Could Enable Others to Watch Your Dreams and Memories | last = Yam |first=Philip | date = 22 September 2011 | magazine = Scientific American | access-date = 25 September 2011}}</ref><ref>{{cite web | url = https://sites.google.com/site/gallantlabucb/publications/nishimoto-et-al-2011 | title = Reconstructing visual experiences from brain activity evoked by natural movies (Project page) | publisher = The Gallant Lab at [[UC Berkeley]] | access-date = 25 September 2011 |url-status=dead |archiveurl=https://web.archive.org/web/20110925024037/https://sites.google.com/site/gallantlabucb/publications/nishimoto-et-al-2011 |archivedate=2011-09-25}}</ref><ref>{{cite web | url= http://newscenter.berkeley.edu/2011/09/22/brain-movies/| title= Scientists use brain imaging to reveal the movies in our mind |last=Anwar |first=Yasmin | date= 22 September 2011 | publisher = [[UC Berkeley]] News Center| access-date = 25 September 2011}}</ref>\n\n====BCI control strategies in neurogaming====\n\n=====Motor imagery=====\n\n[[Motor imagery]] involves the imagination of the movement of various body parts resulting in [[sensorimotor cortex]] activation, which modulates sensorimotor oscillations in the EEG. This can be detected by the BCI to infer a user's intent. Motor imagery typically requires a number of sessions of training before acceptable control of the BCI is acquired. These training sessions may take a number of hours over several days before users can consistently employ the technique with acceptable levels of precision. Regardless of the duration of the training session, users are unable to master the control scheme. This results in very slow pace of the gameplay.<ref name=\"ieeexplore.ieee.org\">{{cite journal| vauthors = Marshall D, Coyle D, Wilson S, Callaghan M |title=Games, Gameplay, and BCI: The State of the Art|journal=IEEE Transactions on Computational Intelligence and AI in Games|volume=5|issue=2|page = 83|doi=10.1109/TCIAIG.2013.2263555 |year=2013|s2cid=206636315}}</ref> Advanced machine learning methods were recently developed to compute a subject-specific model for detecting the performance of motor imagery. The top performing algorithm from BCI Competition IV<ref>{{cite web|url=http://www.bbci.de/competition/iv/|title=Goals of the organizers|publisher=BBC|access-date=19 December 2022}}</ref> dataset 2 for motor imagery is the Filter Bank Common Spatial Pattern, developed by Ang et al. from [[A*STAR]], [[Singapore]].<ref>{{cite journal | vauthors = Ang KK, Chin ZY, Wang C, Guan C, Zhang H | title = Filter Bank Common Spatial Pattern Algorithm on BCI Competition IV Datasets 2a and 2b | journal = Frontiers in Neuroscience | volume = 6 | page = 39 | date = 1 January 2012 | pmid = 22479236 | pmc = 3314883 | doi = 10.3389/fnins.2012.00039 | doi-access = free }}</ref>\n\n=====Bio/neurofeedback for passive BCI designs=====\nBiofeedback is used to monitor a subject's mental relaxation. In some cases, biofeedback does not monitor electroencephalography (EEG), but instead bodily parameters such as [[electromyography]] (EMG), [[galvanic skin response|galvanic skin resistance]] (GSR), and [[heart rate variability]] (HRV). Many biofeedback systems are used to treat certain disorders such as [[Attention deficit hyperactivity disorder|attention deficit hyperactivity disorder (ADHD)]], sleep problems in children, teeth grinding, and chronic pain. EEG biofeedback systems typically monitor four different bands (theta: 4\u20137&nbsp;Hz, alpha:8\u201312&nbsp;Hz, SMR: 12\u201315&nbsp;Hz, beta: 15\u201318&nbsp;Hz) and challenge the subject to control them. Passive BCI<ref name=\":0\" /> involves using BCI to enrich human\u2013machine interaction with implicit information on the actual user's state, for example, simulations to detect when users intend to push brakes during an emergency car stopping procedure. Game developers using passive BCIs need to acknowledge that through repetition of game levels the user's cognitive state will change or adapt. Within the first play\nof a level, the user will react to things differently from during the second play: for example, the user will be less surprised at an event in the game if they are expecting it.<ref name=\"ieeexplore.ieee.org\"/>\n\n=====Visual evoked potential (VEP)=====\n\nA VEP is an electrical potential recorded after a subject is presented with a type of visual stimuli. There are several types of VEPs.\n\n[[Steady state visually evoked potential|Steady-state visually evoked potential]]s (SSVEPs) use potentials generated by exciting the [[retina]], using visual stimuli modulated at certain frequencies. SSVEP's stimuli are often formed from alternating checkerboard patterns and at times simply use flashing images. The frequency of the phase reversal of the stimulus used can be clearly distinguished in the spectrum of an EEG; this makes detection of SSVEP stimuli relatively easy. SSVEP has proved to be successful within many BCI systems. This is due to several factors, the signal elicited is measurable in as large a population as the transient VEP and blink movement and electrocardiographic artefacts do not affect the frequencies monitored. In addition, the SSVEP signal is exceptionally robust; the topographic organization of the primary visual cortex is such that a broader area obtains afferents from the central or fovial region of the visual field. SSVEP does have several problems however. As SSVEPs use flashing stimuli to infer a user's intent, the user must gaze at one of the flashing or iterating symbols in order to interact with the system. It is, therefore, likely that the symbols could become irritating and uncomfortable to use during longer play sessions, which can often last more than an hour which may not be an ideal gameplay.\n\nAnother type of VEP used with applications is the [[P300 (neuroscience)|P300 potential]]. The P300 event-related potential is a positive peak in the EEG that occurs at roughly 300 ms after the appearance of a target stimulus (a stimulus for which the user is waiting or seeking) or [[Oddball paradigm|oddball stimuli]]. The P300 amplitude decreases as the target stimuli and the ignored stimuli grow more similar.The P300 is thought to be related to a higher level attention process or an orienting response using P300 as a control scheme has the advantage of the participant only having to attend limited training sessions. The first application to use the P300 model was the P300 matrix. Within this system, a subject would choose a letter from a grid of 6 by 6 letters and numbers. The rows and columns of the grid flashed sequentially and every time the selected \"choice letter\" was illuminated the user's P300 was (potentially) elicited. However, the communication process, at approximately 17 characters per minute, was quite slow. The P300 is a BCI that offers a discrete selection rather than a continuous control mechanism. The advantage of P300 use within games is that the player does not have to teach himself/herself how to use a completely new control system and so only has to undertake short training instances, to learn the gameplay mechanics and basic use of the BCI paradigm.<ref name=\"ieeexplore.ieee.org\"/>\n\n===Synthetic telepathy/silent communication===\nIn a $6.3 million US Army initiative to invent devices for telepathic communication, [[Gerwin Schalk]], underwritten in a $2.2 million grant, found the use of ECoG signals can discriminate the vowels and consonants embedded in spoken and imagined words, shedding light on the distinct mechanisms associated with production of vowels and consonants, and could provide the basis for brain-based communication using imagined speech.<ref name=\"TelepathicCommVowel\" /><ref name=\"TelepathicComm\">{{cite news |last=Kennedy |first=Pagan |title=The Cyborg in Us All |url=https://www.nytimes.com/2011/09/18/magazine/the-cyborg-in-us-all.html |work=[[The New York Times]] |date=18 September 2011 |access-date=28 January 2012 }}</ref>\n\nIn 2002 [[Kevin Warwick]] had an array of 100 electrodes fired into his nervous system in order to link his nervous system into the Internet to investigate enhancement possibilities. With this in place Warwick successfully carried out a series of experiments. With electrodes also implanted into his wife's nervous system, they conducted the first direct electronic communication experiment between the nervous systems of two humans.<ref>{{cite web |first1=Jocelyn |last1=Selim |first2=Pete |last2=Drinkell |date=1 November 2002 |url=http://discovermagazine.com/2002/nov/featbionic/ |title=The Bionic Connection |work=[[Discover (magazine)|Discover]] |archive-url=https://web.archive.org/web/20080106135544/http://discovermagazine.com:80/2002/nov/featbionic |archive-date=6 January 2008}}</ref><ref>{{cite web|url=http://www.atlasobscura.com/articles/nervous-system-hookup-leads-to-telepathic-hand-holding|title=Nervous System Hookup Leads to Telepathic Hand-Holding|date=10 June 2015 |work=Atlas Obscura |first=Cara |last=Giaimo}}</ref><ref>Warwick, K, Gasson, M, Hutt, B, Goodhew, I, Kyberd, P, Schulzrinne, H and Wu, X: \"Thought Communication and Control: A First Step using Radiotelegraphy\", [[Institution of Electrical Engineers|IEE]] Proceedings on Communications, 151(3), pp.185\u2013189, 2004</ref><ref name=\"doi10.1001/archneur.60.10.1369|noedit\">{{cite journal | vauthors = Warwick K, Gasson M, Hutt B, Goodhew I, Kyberd P, Andrews B, Teddy P, Shad A | display-authors = 6 | title = The application of implant technology for cybernetic systems | journal = Archives of Neurology | volume = 60 | issue = 10 | pages = 1369\u20131373 | date = October 2003 | pmid = 14568806 | doi = 10.1001/archneur.60.10.1369 | doi-access = free }}</ref>\n\nAnother group of researchers was able to achieve conscious brain-to-brain communication between two people separated by a distance using non-invasive technology that was in contact with the scalp of the participants. The words were encoded by binary streams using the sequences of 0's and 1's by the imaginary motor input of the person \"emitting\" the information. As the result of this experiment, pseudo-random bits of the information carried encoded words \"hola\" (\"hi\" in Spanish) and \"ciao\" (\"goodbye\" in Italian) and were transmitted mind-to-mind between humans separated by a distance, with blocked motor and sensory systems, which has low to no probability of this happening by chance.[https://doi.org/10.1371/journal.pone.0105225 Conscious Brain-to-Brain Communication in Humans Using Non-Invasive Technologies]\n\nIn the 1960s a researcher was successful after some training in using EEG to create Morse code using their brain alpha waves. Research funded by the US army is being conducted with the goal of allowing users to compose a message in their head, then transfer that message with just the power of thought to a particular individual.<ref name= Telepathy>{{cite news|title= Army Developing 'synthetic telepathy'|url= http://www.nbcnews.com/id/27162401/|access-date=13 October 2008 |newspaper=Discovery News|date=13 October 2008 |last=Bland |first=Eric }}</ref> On 27 February 2013 the group with [[Miguel Nicolelis]] at [[Duke University]] and IINN-ELS successfully connected the brains of two rats with electronic interfaces that allowed them to directly share information, in [[Miguel Nicolelis#Brain to brain|the first-ever direct brain-to-brain interface]].<ref name=\"srep01319\">{{cite journal | vauthors = Pais-Vieira M, Lebedev M, Kunicki C, Wang J, Nicolelis MA | title = A brain-to-brain interface for real-time sharing of sensorimotor information | journal = Scientific Reports | volume = 3 | pages = 1319 | date = 28 February 2013 | pmid = 23448946 | pmc = 3584574 | doi = 10.1038/srep01319 | bibcode = 2013NatSR...3E1319P }}</ref><ref>{{cite news|title=One Rat Thinks, and Another Reacts |last=Gorman |first=James  |url= https://www.nytimes.com/2013/03/01/science/new-research-suggests-two-rat-brains-can-be-linked.html |work=The New York Times|date=28 February 2013|access-date=28 February 2013}}</ref><ref>{{cite web|url=https://www.theguardian.com/science/2013/feb/28/brains-rats-connected-share-information|title=Brain-to-brain interface lets rats share information via internet|website=The Guardian|date=1 March 2013 |first=Ian |last=Sample |access-date=2 March 2013}}</ref>\n\n==Cell-culture BCIs==\n{{Main|Cultured neuronal network}}\n\nResearchers have built devices to interface with neural cells and entire neural networks in cultures outside animals. As well as furthering research on animal implantable devices, experiments on cultured neural tissue have focused on building problem-solving networks, constructing basic computers and manipulating robotic devices. Research into techniques for stimulating and recording from individual neurons grown on semiconductor chips is sometimes referred to as neuroelectronics or [[neurochip]]s.<ref>{{cite journal | vauthors = Mazzatenta A, Giugliano M, Campidelli S, Gambazzi L, Businaro L, Markram H, Prato M, Ballerini L | display-authors = 6 | title = Interfacing neurons with carbon nanotubes: electrical signal transfer and synaptic stimulation in cultured brain circuits | journal = The Journal of Neuroscience | volume = 27 | issue = 26 | pages = 6931\u20136936 | date = June 2007 | pmid = 17596441 | pmc = 6672220 | doi = 10.1523/JNEUROSCI.1051-07.2007 }}</ref>\n\n<noinclude>[[File:CaltechNeuroChip.jpg|thumb|The world's first [[Neurochip]], developed by [[Caltech]] researchers Jerome Pine and Michael Maher]]</noinclude>\n\nDevelopment of the first working neurochip was claimed by a Caltech team led by Jerome Pine and Michael Maher in 1997.<ref>[http://www.caltech.edu/news/caltech-scientists-devise-first-neurochip-213 Caltech Scientists Devise First Neurochip], Caltech, 26 October 1997</ref> The Caltech chip had room for 16 neurons.\n\nIn 2003 a team led by Theodore Berger, at the [[University of Southern California]], started work on a neurochip designed to function as an artificial or prosthetic [[hippocampus]]. The neurochip was designed to function in rat brains and was intended as a prototype for the eventual development of higher-brain prosthesis. The hippocampus was chosen because it is thought to be the most ordered and structured part of the brain and is the most studied area. Its function is to encode experiences for storage as long-term memories elsewhere in the brain.<ref>{{Cite web |url=https://www.wired.com/news/technology/medtech/0,65422-0.html |title=Coming to a brain near you |archiveurl=https://web.archive.org/web/20060910201747/http://www.wired.com/news/technology/medtech/0%2C65422-0.html |archivedate=10 September 2006 |url-status=dead |work=Wired News |date=22 October 2004 |first=Lakshmi |last=Sandhana}}</ref>\n\nIn 2004 Thomas DeMarse at the [[University of Florida]] used a culture of 25,000 neurons taken from a rat's brain to fly a [[F-22]] fighter jet [[aircraft simulator]].<ref>{{Cite news |url=http://www.cnn.com/2004/TECH/11/02/brain.dish/ |title='Brain' in a dish flies flight simulator |work=CNN |date=4 November 2004}}</ref> After collection, the cortical neurons were cultured in a [[petri dish]] and rapidly began to reconnect themselves to form a living neural network. The cells were arranged over a grid of 60 electrodes and used to control the [[Aircraft principal axes|pitch]] and [[Aircraft principal axes|yaw]] functions of the simulator. The study's focus was on understanding how the human brain performs and learns computational tasks at a cellular level.\n\n==Collaborative BCIs==\nThe idea of combining/integrating brain signals from multiple individuals was introduced at Humanity+ @Caltech, in December 2010, by a [[Caltech]] researcher at [[Jet Propulsion Laboratory|JPL]], Adrian Stoica; Stoica referred to the concept as multi-brain aggregation.<ref>{{Cite web|date=2017-10-05|title=David Pearce \u2013 Humanity Plus|url=https://activistjourneys.wordpress.com/david-pearce-humanity-plus/|access-date=2021-12-30|language=en}}</ref><ref>{{Cite web|vauthors=Stoica A|date=2010|title=Speculations on Robots, Cyborgs & Telepresence|website=[[YouTube]]|url=https://www.youtube.com/watch?v=nqByb7VEnZk|url-status=live|archive-url=https://web.archive.org/web/20211228222826/https://www.youtube.com/watch?v=nqByb7VEnZk|archive-date=28 December 2021|access-date=28 December 2021}}</ref><ref>{{Cite web|title=Experts to 'redefine the future' at Humanity+ @ CalTech |website=Kurzweil|url=https://www.kurzweilai.net/experts-to-redefine-the-future-at-humanity-caltech|access-date=2021-12-30|language=en-US}}</ref> A provisional patent application was filed on January 19, 2011, with the non-provisional patent following one year later.<ref>{{Cite patent|number=WO2012100081A2|title=Aggregation of bio-signals from multiple individuals to achieve a collective outcome|gdate=2012-07-26|invent1=Stoica|inventor1-first=Adrian|url=https://patents.google.com/patent/WO2012100081A2/en}}</ref> In May 2011, Yijun Wang and Tzyy-Ping Jung published, ''\"A Collaborative Brain-Computer Interface for Improving Human Performance\"'', and in January 2012 Miguel Eckstein published, ''\"Neural decoding of collective wisdom with multi-brain computing\"''.<ref>{{cite journal | vauthors = Wang Y, Jung TP | title = A collaborative brain-computer interface for improving human performance | journal = PLOS ONE | volume = 6 | issue = 5 | pages = e20422 | date = 2011-05-31 | pmid = 21655253 | pmc = 3105048 | doi = 10.1371/journal.pone.0020422 | bibcode = 2011PLoSO...620422W | doi-access = free }}</ref><ref>{{cite journal | vauthors = Eckstein MP, Das K, Pham BT, Peterson MF, Abbey CK, Sy JL, Giesbrecht B | title = Neural decoding of collective wisdom with multi-brain computing | journal = NeuroImage | volume = 59 | issue = 1 | pages = 94\u2013108 | date = January 2012 | pmid = 21782959 | doi = 10.1016/j.neuroimage.2011.07.009 | s2cid = 14930969 }}</ref> Stoica's first paper on the topic appeared in 2012, after the publication of his patent application.<ref>{{Cite journal| vauthors = Stoica A |date= September 2012 |title= MultiMind: Multi-Brain Signal Fusion to Exceed the Power of a Single Brain |url= https://ieeexplore.ieee.org/document/6328091 |journal=2012 Third International Conference on Emerging Security Technologies |pages=94\u201398 |doi=10.1109/EST.2012.47|isbn= 978-0-7695-4791-6 |s2cid= 6783719 }}</ref> Given the timing of the publications between the patent and papers, Stoica, Wang & Jung, and Eckstein independently pioneered the concept, and are all considered as founders of the field. Later, Stoica would collaborate with [[University of Essex]] researchers, Riccardo Poli and Caterina Cinel.<ref>{{Cite journal| vauthors = Poli R, Cinel C, Matran-Fernandez A, Sepulveda F, Stoica A |date=2013-03-19|title=Towards cooperative brain-computer interfaces for space navigation |journal=Proceedings of the 2013 International Conference on Intelligent User Interfaces|series=IUI '13|location=New York, NY, USA|publisher=Association for Computing Machinery|pages=149\u2013160|doi=10.1145/2449396.2449417|isbn=978-1-4503-1965-2|s2cid=13201979}}</ref><ref>{{Cite journal| vauthors = Poli R, Cinel C, Sepulveda F, Stoica A |date=February 2013|title=Improving decision-making based on visual perception via a collaborative brain-computer interface |url= https://ieeexplore.ieee.org/document/6523816 |journal=2013 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)|location=San Diego, CA|publisher=IEEE|pages=1\u20138|doi=10.1109/CogSIMA.2013.6523816|isbn=978-1-4673-2437-3|s2cid=25136642}}</ref> The work was continued by Poli and Cinel, and their students: Ana Matran-Fernandez, Davide Valeriani, and Saugat Bhattacharyya.<ref>{{Cite journal| vauthors = Matran-Fernandez A, Poli R, Cinel C |date=November 2013|title=Collaborative brain-computer interfaces for the automatic classification of images|url=https://ieeexplore.ieee.org/document/6696128|journal=2013 6th International IEEE/EMBS Conference on Neural Engineering (NER)|pages=1096\u20131099|doi=10.1109/NER.2013.6696128|isbn=978-1-4673-1969-0|s2cid=40341170}}</ref><ref>{{cite journal | vauthors = Valeriani D, Cinel C, Poli R | title = Group Augmentation in Realistic Visual-Search Decisions via a Hybrid Brain-Computer Interface | journal = Scientific Reports | volume = 7 | issue = 1 | pages = 7772 | date = August 2017 | pmid = 28798411 | pmc = 5552884 | doi = 10.1038/s41598-017-08265-7 | bibcode = 2017NatSR...7.7772V }}</ref><ref>{{cite journal | vauthors = Bhattacharyya S, Valeriani D, Cinel C, Citi L, Poli R | title = Anytime collaborative brain-computer interfaces for enhancing perceptual group decision-making | journal = Scientific Reports | volume = 11 | issue = 1 | pages = 17008 | date = August 2021 | pmid = 34417494 | pmc = 8379268 | doi = 10.1038/s41598-021-96434-0 | bibcode = 2021NatSR..1117008B }}</ref>\n\n== Ethical considerations==\nSources:<ref name=\"nature.com\">{{cite journal | vauthors = Clausen J | title = Man, machine and in between | journal = Nature | volume = 457 | issue = 7233 | pages = 1080\u20131081 | date = February 2009 | pmid = 19242454 | doi = 10.1038/4571080a | s2cid = 205043226 | bibcode = 2009Natur.457.1080C }}</ref><ref name=\"sciencedirect.com\">{{cite journal | vauthors = Haselager P, Vlek R, Hill J, Nijboer F | title = A note on ethical aspects of BCI | journal = Neural Networks | volume = 22 | issue = 9 | pages = 1352\u20131357 | date = November 2009 | pmid = 19616405 | doi = 10.1016/j.neunet.2009.06.046 }}</ref><ref>{{cite journal| vauthors = Tamburrini G |title=Brain to Computer Communication: Ethical Perspectives on Interaction Models|journal=Neuroethics|volume=2|pages=137\u2013149|year=2009|doi=10.1007/s12152-009-9040-1|issue=3|s2cid=143780006}}</ref><ref name=\"Attiah\">{{cite journal | vauthors = Attiah MA, Farah MJ | title = Minds, motherboards, and money: futurism and realism in the neuroethics of BCI technologies | journal = Frontiers in Systems Neuroscience | volume = 8 | issue = 86 | pages = 86 | date = 15 May 2014 | pmid = 24860445 | pmc = 4030132 | doi = 10.3389/fnsys.2014.00086 | doi-access = free }}</ref><ref name=\"Neuroethics\">{{cite journal | vauthors = Nijboer F, Clausen J, Allison BZ, Haselager P | title = The Asilomar Survey: Stakeholders' Opinions on Ethical Issues Related to Brain-Computer Interfacing | journal = Neuroethics | volume = 6 | issue = 3 | pages = 541\u2013578 | year = 2011 | pmid = 24273623 | pmc = 3825606 | doi = 10.1007/s12152-011-9132-6 }}</ref>\n\n===User-centric issues===\n* Long-term effects to the user remain largely unknown.\n* Obtaining informed consent from people who have difficulty communicating.\n* The consequences of BCI technology for the quality of life of patients and their families.\n* Health-related side-effects (e.g. neurofeedback of sensorimotor rhythm training is reported to affect sleep quality).\n* Therapeutic applications and their potential misuse.\n*Safety risks\n*Non-convertibility of some of the changes made to the brain\n\n===Legal and social===\n* Issues of accountability and responsibility: claims that the influence of BCIs overrides free will and control over sensory-motor actions, claims that cognitive intention was inaccurately translated due to a BCI malfunction.\n* Personality changes involved caused by deep-brain stimulation.\n*Concerns regarding the state of becoming a \"cyborg\" - having parts of the body that are living and parts that are mechanical.\n*Questions personality: what does it mean to be a human?\n* Blurring of the division between human and machine and inability to distinguish between human vs. machine-controlled actions.\n* Use of the technology in advanced interrogation techniques by governmental authorities.\n* Selective enhancement and social stratification.\n* Questions of research ethics regarding animal experimentation\n* Questions of research ethics that arise when progressing from animal experimentation to application in human subjects.\n*Moral questions\n* [[Thought identification|Mind reading]] and privacy.\n*Tracking and \"tagging system\"\n* [[Mind control]].\n*Movement control\n*Emotion control\n\nIn their current form, most BCIs are far removed from the ethical issues considered above. They are actually similar to corrective therapies in function. Clausen stated in 2009 that \"BCIs pose ethical challenges, but these are conceptually similar to those that bioethicists have addressed for other realms of therapy\".<ref name=\"nature.com\"/> Moreover, he suggests that bioethics is well-prepared to deal with the issues that arise with BCI technologies. Haselager and colleagues<ref name=\"sciencedirect.com\"/> pointed out that expectations of BCI efficacy and value play a great role in ethical analysis and the way BCI scientists should approach media. Furthermore, standard protocols can be implemented to ensure ethically sound informed-consent procedures with locked-in patients.\n\nThe case of BCIs today has parallels in medicine, as will its evolution. Similar to how pharmaceutical science began as a balance for impairments and is now used to increase focus and reduce need for sleep, BCIs will likely transform gradually from therapies to enhancements.<ref name= \"Attiah\"/> Efforts are made inside the BCI community to create consensus on ethical guidelines for BCI research, development and dissemination.<ref name=\"Neuroethics\"/> As innovation continues, ensuring equitable access to BCIs will be crucial, failing which generational inequalities can arise which can adversely affect the right to human flourishing.<ref>{{Cite journal| vauthors = Sengupta S |date=2021|title=Invasive Brain Computer Interface Systems and the Right to Human Flourishing: Extent of Sufficiency of Article 8 of the European Convention of Human Rights to regulate Invasive Brain Computer Interface Systems to ensure the Right to Human Flourishing|url=http://rgdoi.net/10.13140/RG.2.2.36656.28163|doi=10.13140/RG.2.2.36656.28163}}</ref>\n\nThe ethical considerations of BCIs are essential to the development of future implanted devices. End-users, ethicists, researchers, funding agencies, physicians, corporations, and all others involved in BCI use should consider the anticipated, and unanticipated, changes that BCIs will have on human autonomy, identity, privacy, and more.<ref name=\":5\" />\n\n==Low-cost BCI-based interfaces==\n{{main|Consumer brain\u2013computer interfaces}}\nRecently a number of companies have scaled back medical grade EEG technology to create inexpensive BCIs for research as well as entertainment purposes. For example, toys such as the NeuroSky and Mattel MindFlex have seen some commercial success.\n* In 2006 [[Sony]] patented a neural interface system allowing radio waves to affect signals in the neural cortex.<ref name=\"Sony patent neural interface\">{{cite news|url=http://www.wikipatents.com/US-Patent-6729337/method-and-system-for-generating-sensory-data-onto-the-human-neural |title=Sony patent neural interface |url-status=dead |archive-url=https://web.archive.org/web/20120407071853/http://www.wikipatents.com/US-Patent-6729337/method-and-system-for-generating-sensory-data-onto-the-human-neural |archive-date=7 April 2012 |df=dmy }}</ref>\n* In 2007 [[NeuroSky]] released the first affordable consumer based EEG along with the game NeuroBoy. This was also the first large scale EEG device to use dry sensor technology.<ref>{{cite news|url= http://www.economist.com/science/displaystory.cfm?story_id=8847846 |title=Mind Games |date= 23 March 2007 |newspaper=The Economist}}</ref>\n* In 2008 [[OCZ Technology]] developed a device for use in video games relying primarily on [[electromyography]].<ref>{{cite web|url=http://www.ocztechnology.com/nia-game-controller.html |title=nia Game Controller Product Page |publisher=OCZ Technology Group |access-date=30 January 2013}}</ref>\n*In 2008 [[Final Fantasy]] developer [[Square Enix]] announced that it was partnering with NeuroSky to create a game, Judecca.<ref name=\"Mind reading is on the market\">{{cite news|url=https://www.latimes.com/business/la-fi-mind-reader-20100808,0,6235181,full.story|archive-url=https://archive.today/20130104065206/http://www.latimes.com/business/la-fi-mind-reader-20100808,0,6235181,full.story|url-status=dead|archive-date=4 January 2013|title= Mind reading is on the market |date=8 August 2010 |work=[[Los Angeles Times]] | vauthors = Li S }}</ref><ref>{{Cite web |url=https://www.engadget.com/2008/10/09/brains-on-with-neurosky-and-squareenixs-judecca-mind-control-ga |title=Brains-on with NeuroSky and Square Enix's Judecca mind-control game |website=Engadget |date=9 October 2008 |first=Joshua |last=Fruhlinger |accessdate=29 May 2012}}</ref>\n* In 2009 [[Mattel]] partnered with NeuroSky to release the [[Mindflex]], a game that used an EEG to steer a ball through an obstacle course. It is by far the best selling consumer based EEG to date.<ref name=\"Mind reading is on the market\"/><ref>[https://web.archive.org/web/20111108025937/http://www.physorg.com/news150781868.html New games powered by brain waves]. Physorg.com (10 January 2009). Retrieved on 12 September 2010.</ref>\n* In 2009 [[Uncle Milton Industries]] partnered with NeuroSky to release the [[Star Wars]] [[Force Trainer]], a game designed to create the illusion of possessing [[the Force]].<ref name=\"Mind reading is on the market\"/><ref>{{cite news| url=https://www.usatoday.com/life/lifestyle/2009-01-06-force-trainer-toy_N.htm | work=USA Today | title=Toy trains 'Star Wars' fans to use The Force |last=Snider |first=Mike | date=7 January 2009 |\naccess-date=1 May 2010}}</ref>\n* In 2009 [[Emotiv]] released the EPOC, a 14 channel EEG device that can read 4 mental states, 13 conscious states, facial expressions, and head movements. The EPOC is the first commercial BCI to use dry sensor technology, which can be dampened with a saline solution for a better connection.<ref name=\"emotive\">{{cite web|url=http://emotiv.com/|title=Emotiv Homepage|publisher=Emotiv.com|access-date=29 December 2009}}</ref>\n* In November 2011 ''[[Time (magazine)|Time]]'' magazine selected \"necomimi\" produced by [[Neurowear]] as one of the best inventions of the year. The company announced that it expected to launch a consumer version of the garment, consisting of catlike ears controlled by a brain-wave reader produced by [[NeuroSky]], in spring 2012.<ref>{{cite web |url=http://neurowear.com/?p=153 |title='necomimi' selected 'Time Magazine / The 50 best invention of the year' |publisher=Neurowear |date=22 November 2011 |archive-url=https://web.archive.org/web/20120125122705/http://neurowear.com/?p=153 |archive-date=25 January 2012}}</ref>\n* In February 2014 They Shall Walk (a nonprofit organization fixed on constructing exoskeletons, dubbed LIFESUITs, for paraplegics and quadriplegics) began a partnership with James W. Shakarji on the development of a wireless BCI.<ref>{{cite web|url=http://www.theyshallwalk.org/category/lifesuit-updates-and-news/ |title=LIFESUIT Updates & News \u2013 They Shall Walk |publisher=Theyshallwalk.org |access-date=19 December 2016}}</ref>\n* In 2016, a group of hobbyists developed an open-source BCI board that sends neural signals to the audio jack of a smartphone, dropping the cost of entry-level BCI to \u00a320.<ref>{{cite web|url=https://github.com/icibici/smartphone-bci-hardware/ |title=SmartphoneBCI |website=[[GitHub]] |access-date=5 June 2018}}</ref> Basic diagnostic software is available for [[Android (operating system)|Android]] devices, as well as a text entry app for [[Unity (game engine)|Unity]].<ref>{{cite web|url=https://github.com/ryanlintott/SSVEP_keyboard/ |title=SSVEP_keyboard |website=[[GitHub]] |access-date=5 April 2017}}</ref>\n* In 2020, [[NextMind]] released a dev kit including an EEG headset with dry electrodes at $399.<ref>{{cite web|date=2020-12-08|title=NextMind ships its real-time brain computer interface Dev Kit for $399|url=https://venturebeat.com/2020/12/07/nextmind-real-time-brain-computer-interface-dev-kit/ |first=Emil |last=Protalinski |access-date=2021-09-08|website=VentureBeat|language=en-US}}</ref><ref>{{cite web|title=NextMind's Dev Kit for mind-controlled computing offers a rare 'wow' factor in tech|url=https://social.techcrunch.com/2020/12/21/nextminds-dev-kit-for-mind-controlled-computing-offers-a-rare-wow-factor-in-tech/|access-date=2021-09-08|website=TechCrunch |date=December 21, 2020 |first=Darrell |last=Etherington |language=en-US}}</ref> The device can be played with some demo applications or developers can create their own use cases using the provided Software Development Kit.\n\n==Future directions==\n[[File:Brain-computer interface.jpeg|thumb|right|Brain-computer interface]]\nA consortium consisting of 12 European partners has completed a roadmap to support the European Commission in their funding decisions for the new framework program [[Horizon 2020]]. The project, which was funded by the European Commission, started in November 2013 and published a roadmap in April 2015.<ref>{{cite web|url=http://bnci-horizon-2020.eu/roadmap|title=Roadmap - BNCI Horizon 2020|website=bnci-horizon-2020.eu|access-date=2019-05-05}}</ref> A 2015 publication led by Dr. Clemens Brunner describes some of the analyses and achievements of this project, as well as the emerging Brain-Computer Interface Society.<ref name=\"bncihorizon2020\">{{cite journal|title=BNCI Horizon 2020: towards a roadmap for the BCI community|doi=10.1080/2326263X.2015.1008956 | volume=2 | journal=Brain-Computer Interfaces|pages=1\u201310|year=2015 | vauthors = Brunner C, Birbaumer N, Blankertz B, Guger C, K\u00fcbler A, Mattia D, Mill\u00e1n JD, Miralles F, Nijholt A, Opisso E, Ramsey N | display-authors = 6 |hdl=1874/350349 |s2cid=15822773 |url=http://infoscience.epfl.ch/record/205169 }}</ref> For example, this article reviewed work within this project that further defined BCIs and applications, explored recent trends, discussed ethical issues, and evaluated different directions for new BCIs.\n\nOther recent publications too have explored future BCI directions for new groups of disabled users (e.g.,<ref name=\"Wolpaw, J.R 2012\"/><ref>{{cite book | vauthors = Allison BZ, Dunne S, Leeb R, Millan J, Nijholt A| date = 2013 | title = Towards Practical Brain-Computer Interfaces: Bridging the Gap from Research to Real-World Applications. | publisher = Springer Verlag | location = Berlin Heidelberg |isbn=978-3-642-29746-5}}</ref>)\n\n===Disorders of consciousness (DOC)===\nSome persons have a [[disorder of consciousness]] (DOC). This state is defined to include persons with coma, as well as persons in a vegetative state (VS) or minimally conscious state (MCS). New BCI research seeks to help persons with DOC in different ways. A key initial goal is to identify patients who are able to perform basic cognitive tasks, which would of course lead to a change in their diagnosis. That is, some persons who are diagnosed with DOC may in fact be able to process information and make important life decisions (such as whether to seek therapy, where to live, and their views on end-of-life decisions regarding them). Some persons who are diagnosed with DOC die as a result of end-of-life decisions, which may be made by family members who sincerely feel this is in the patient's best interests. Given the new prospect of allowing these patients to provide their views on this decision, there would seem to be a strong ethical pressure to develop this research direction to guarantee that DOC patients are given an opportunity to decide whether they want to live.<ref>{{cite book | vauthors = Edlinger G, Allison BZ, Guger C | chapter = How many people could use a BCI system? | pages = 33\u201366 | veditors = Kansaku K, Cohen L, Birbaumer N |title=Clinical Systems Neuroscience |date=2015 |location=Tokyo  | publisher = pringer Verlag Japan |isbn=978-4-431-55037-2}}</ref><ref>{{cite journal | vauthors = Chatelle C, Chennu S, Noirhomme Q, Cruse D, Owen AM, Laureys S | title = Brain-computer interfacing in disorders of consciousness | journal = Brain Injury | volume = 26 | issue = 12 | pages = 1510\u20131522 | year = 2012 | pmid = 22759199 | doi = 10.3109/02699052.2012.698362 | s2cid = 6498232 | hdl = 2268/162403 }}</ref>\n\nThese and other articles describe new challenges and solutions to use BCI technology to help persons with DOC. One major challenge is that these patients cannot use BCIs based on vision. Hence, new tools rely on auditory and/or vibrotactile stimuli. Patients may wear headphones and/or vibrotactile stimulators placed on the wrists, neck, leg, and/or other locations. Another challenge is that patients may fade in and out of consciousness, and can only communicate at certain times. This may indeed be a cause of mistaken diagnosis. Some patients may only be able to respond to physicians' requests during a few hours per day (which might not be predictable ahead of time) and thus may have been unresponsive during diagnosis. Therefore, new methods rely on tools that are easy to use in field settings, even without expert help, so family members and other persons without any medical or technical background can still use them. This reduces the cost, time, need for expertise, and other burdens with DOC assessment. Automated tools can ask simple questions that patients can easily answer, such as \"Is your father named George?\" or \"Were you born in the USA?\" Automated instructions inform patients that they may convey yes or no by (for example) focusing their attention on stimuli on the right vs. left wrist. This focused attention produces reliable changes in [[electroencephalography|EEG patterns]] that can help determine that the patient is able to communicate. The results could be presented to physicians and therapists, which could lead to a revised diagnosis and therapy. In addition, these patients could then be provided with BCI-based communication tools that could help them convey basic needs, adjust bed position and [[HVAC]] (heating, ventilation, and air conditioning), and otherwise empower them to make major life decisions and communicate.<ref name=BolyMassimini2012>{{cite journal | vauthors = Boly M, Massimini M, Garrido MI, Gosseries O, Noirhomme Q, Laureys S, Soddu A | title = Brain connectivity in disorders of consciousness | journal = Brain Connectivity | volume = 2 | issue = 1 | pages = 1\u201310 | year = 2012 | pmid = 22512333 | doi = 10.1089/brain.2011.0049 | hdl-access = free | s2cid = 6447538 | hdl = 2268/131984 }}</ref><ref>{{cite journal | vauthors = Gibson RM, Fern\u00e1ndez-Espejo D, Gonzalez-Lara LE, Kwan BY, Lee DH, Owen AM, Cruse D | title = Multiple tasks and neuroimaging modalities increase the likelihood of detecting covert awareness in patients with disorders of consciousness | journal = Frontiers in Human Neuroscience | volume = 8 | pages = 950 | year = 2014 | pmid = 25505400 | pmc = 4244609 | doi = 10.3389/fnhum.2014.00950 | doi-access = free }}</ref><ref>{{cite journal | vauthors = Risetti M, Formisano R, Toppi J, Quitadamo LR, Bianchi L, Astolfi L, Cincotti F, Mattia D | display-authors = 6 | title = On ERPs detection in disorders of consciousness rehabilitation | journal = Frontiers in Human Neuroscience | volume = 7 | pages = 775 | year = 2013 | pmid = 24312041 | pmc = 3834290 | doi = 10.3389/fnhum.2013.00775 | doi-access = free }}</ref>\n\n===Motor recovery===\nPeople may lose some of their ability to move due to many causes, such as stroke or injury. Research in recent years has demonstrated the utility of EEG-based BCI systems in aiding motor recovery and neurorehabilitation in patients who have had a stroke.<ref>{{cite journal | vauthors = Silvoni S, Ramos-Murguialday A, Cavinato M, Volpato C, Cisotto G, Turolla A, Piccione F, Birbaumer N | display-authors = 6 | title = Brain-computer interface in stroke: a review of progress | journal = Clinical EEG and Neuroscience | volume = 42 | issue = 4 | pages = 245\u2013252 | date = October 2011 | pmid = 22208122 | doi = 10.1177/155005941104200410 | s2cid = 37902399 }}</ref><ref>{{cite journal | vauthors = Leamy DJ, Kocijan J, Domijan K, Duffin J, Roche RA, Commins S, Collins R, Ward TE | display-authors = 6 | title = An exploration of EEG features during recovery following stroke - implications for BCI-mediated neurorehabilitation therapy | journal = Journal of Neuroengineering and Rehabilitation | volume = 11 | pages = 9 | date = January 2014 | pmid = 24468185 | pmc = 3996183 | doi = 10.1186/1743-0003-11-9 | first8 = Tomas E }}</ref><ref>{{cite journal | vauthors = Tung SW, Guan C, Ang KK, Phua KS, Wang C, Zhao L, Teo WP, Chew E | display-authors = 6 | title = Motor imagery BCI for upper limb stroke rehabilitation: An evaluation of the EEG recordings using coherence analysis | journal = Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference | volume = 2013 | pages = 261\u2013264 | date = July 2013 | pmid = 24109674 | doi = 10.1109/EMBC.2013.6609487 | isbn = 978-1-4577-0216-7 | s2cid = 5071115 }}</ref><ref>{{cite journal | vauthors = Bai Z, Fong KN, Zhang JJ, Chan J, Ting KH | title = Immediate and long-term effects of BCI-based rehabilitation of the upper extremity after stroke: a systematic review and meta-analysis | journal = Journal of Neuroengineering and Rehabilitation | volume = 17 | issue = 1 | pages = 57 | date = April 2020 | pmid = 32334608 | pmc = 7183617 | doi = 10.1186/s12984-020-00686-2 }}</ref> Several groups have explored systems and methods for motor recovery that include BCIs.<ref>{{cite journal | vauthors = Remsik A, Young B, Vermilyea R, Kiekhoefer L, Abrams J, Evander Elmore S, Schultz P, Nair V, Edwards D, Williams J, Prabhakaran V | display-authors = 6 | title = A review of the progression and future implications of brain-computer interface therapies for restoration of distal upper extremity motor function after stroke | journal = Expert Review of Medical Devices | volume = 13 | issue = 5 | pages = 445\u2013454 | date = May 2016 | pmid = 27112213 | pmc = 5131699 | doi = 10.1080/17434440.2016.1174572 }}</ref><ref>{{cite journal | vauthors = Monge-Pereira E, Iba\u00f1ez-Pereda J, Alguacil-Diego IM, Serrano JI, Spottorno-Rubio MP, Molina-Rueda F | title = Use of Electroencephalography Brain-Computer Interface Systems as a Rehabilitative Approach for Upper Limb Function After a Stroke: A Systematic Review | journal = PM&R | volume = 9 | issue = 9 | pages = 918\u2013932 | date = September 2017 | pmid = 28512066 | doi = 10.1016/j.pmrj.2017.04.016 | s2cid = 20808455 | url = https://discovery.ucl.ac.uk/id/eprint/10042536/ }}</ref><ref>{{Cite book| vauthors = Sabathiel N, Irimia DC, Allison BZ, Guger C, Edlinger G |date=17 July 2016| chapter = Paired Associative Stimulation with Brain-Computer Interfaces: A New Paradigm for Stroke Rehabilitation|journal=Foundations of Augmented Cognition: Neuroergonomics and Operational Neuroscience|series=Lecture Notes in Computer Science|volume=9743|pages=261\u2013272|doi=10.1007/978-3-319-39955-3_25|isbn=978-3-319-39954-6}}</ref><ref>{{cite book | vauthors = Riccio A, Pichiorri F, Schettini F, Toppi J, Risetti M, Formisano R, Molinari M, Astolfi L, Cincotti F, Mattia D | title = Brain-Computer Interfaces: Lab Experiments to Real-World Applications | display-authors = 6 | chapter = Interfacing brain with computer to improve communication and rehabilitation after brain damage | volume = 228 | pages = 357\u2013387 | year = 2016 | pmid = 27590975 | doi = 10.1016/bs.pbr.2016.04.018 | isbn = 978-0-12-804216-8 | series = Progress in Brain Research }}</ref> In this approach, a BCI measures motor activity while the patient imagines or attempts movements as directed by a therapist. The BCI may provide two benefits: (1) if the BCI indicates that a patient is not imagining a movement correctly (non-compliance), then the BCI could inform the patient and therapist; and (2) rewarding feedback such as functional stimulation or the movement of a virtual avatar also depends on the patient's correct movement imagery.\n\nSo far, BCIs for motor recovery have relied on the EEG to measure the patient's motor imagery. However, studies have also used fMRI to study different changes in the brain as persons undergo BCI-based stroke rehab training.<ref>{{cite journal | vauthors = V\u00e1rkuti B, Guan C, Pan Y, Phua KS, Ang KK, Kuah CW, Chua K, Ang BT, Birbaumer N, Sitaram R | display-authors = 6 | title = Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke | journal = Neurorehabilitation and Neural Repair | volume = 27 | issue = 1 | pages = 53\u201362 | date = January 2013 | pmid = 22645108 | doi = 10.1177/1545968312445910 | s2cid = 7120989 }}</ref><ref>{{cite journal | vauthors = Young BM, Nigogosyan Z, Remsik A, Walton LM, Song J, Nair VA, Grogan SW, Tyler ME, Edwards DF, Caldera K, Sattin JA, Williams JC, Prabhakaran V | display-authors = 6 | title = Changes in functional connectivity correlate with behavioral gains in stroke patients after therapy using a brain-computer interface device | journal = Frontiers in Neuroengineering | volume = 7 | pages = 25 | date = 2014 | pmid = 25071547 | pmc = 4086321 | doi = 10.3389/fneng.2014.00025 | doi-access = free }}</ref><ref name=\":6\">{{cite journal | vauthors = Yuan K, Chen C, Wang X, Chu WC, Tong RK | title = BCI Training Effects on Chronic Stroke Correlate with Functional Reorganization in Motor-Related Regions: A Concurrent EEG and fMRI Study | journal = Brain Sciences | volume = 11 | issue = 1 | pages = 56 | date = January 2021 | pmid = 33418846 | doi = 10.3390/brainsci11010056 | pmc = 7824842 | doi-access = free }}</ref> Imaging studies combined with EEG-based BCI systems hold promise for investigating neuroplasticity during motor recovery post-stroke.<ref name=\":6\" /> Future systems might include the fMRI and other measures for real-time control, such as functional near-infrared, probably in tandem with EEGs. Non-invasive brain stimulation has also been explored in combination with BCIs for motor recovery.<ref>{{cite journal | vauthors = Mrachacz-Kersting N, Voigt M, Stevenson AJ, Aliakbaryhosseinabadi S, Jiang N, Dremstrup K, Farina D | title = The effect of type of afferent feedback timed with motor imagery on the induction of cortical plasticity | journal = Brain Research | volume = 1674 | pages = 91\u2013100 | date = November 2017 | pmid = 28859916 | doi = 10.1016/j.brainres.2017.08.025 | hdl-access = free | s2cid = 5866337 | hdl = 10012/12325 }}</ref> In 2016, scientists out of the [[University of Melbourne]] published preclinical proof-of-concept data related to a potential brain-computer interface technology platform being developed for patients with paralysis to facilitate control of external devices such as robotic limbs, computers and exoskeletons by translating brain activity.<ref>{{cite web | vauthors = Opie N |title=Research Overview |url=https://medicine.unimelb.edu.au/research-groups/medicine-and-radiology-research/royal-melbourne-hospital/the-vascular-bionics-laboratory |website=University of Melbourne Medicine |date=2 April 2019 |publisher=University of Melbourne |access-date=5 December 2019}}</ref><ref>{{cite journal | vauthors = Oxley TJ, Opie NL, John SE, Rind GS, Ronayne SM, Wheeler TL, Judy JW, McDonald AJ, Dornom A, Lovell TJ, Steward C, Garrett DJ, Moffat BA, Lui EH, Yassi N, Campbell BC, Wong YT, Fox KE, Nurse ES, Bennett IE, Bauquier SH, Liyanage KA, van der Nagel NR, Perucca P, Ahnood A, Gill KP, Yan B, Churilov L, French CR, Desmond PM, Horne MK, Kiers L, Prawer S, Davis SM, Burkitt AN, Mitchell PJ, Grayden DB, May CN, O'Brien TJ | display-authors = 6 | title = Minimally invasive endovascular stent-electrode array for high-fidelity, chronic recordings of cortical neural activity | journal = Nature Biotechnology | volume = 34 | issue = 3 | pages = 320\u2013327 | date = March 2016 | pmid = 26854476 | doi = 10.1038/nbt.3428 | s2cid = 205282364 }}</ref> Clinical trials are currently underway.<ref>{{cite web |title=Synchron begins trialling Stentrode neural interface technology |date=22 September 2019 |url=https://www.medicaldevice-network.com/news/synchron-stentrode-study/ |publisher=Verdict Medical Devices |access-date=5 December 2019}}</ref>\n\n===Functional brain mapping===\nEach year, about 400,000 people undergo [[brain mapping]] during neurosurgery. This procedure is often required for people with tumors or epilepsy that do not respond to [[medication]].<ref>{{cite journal | vauthors = Radzik I, Miziak B, Dudka J, Chro\u015bci\u0144ska-Krawczyk M, Czuczwar SJ | title = Prospects of epileptogenesis prevention | journal = Pharmacological Reports | volume = 67 | issue = 3 | pages = 663\u2013668 | date = June 2015 | pmid = 25933984 | doi = 10.1016/j.pharep.2015.01.016 }}</ref> During this procedure, electrodes are placed on the brain to precisely identify the locations of structures and functional areas. Patients may be awake during neurosurgery and asked to perform certain tasks, such as moving fingers or repeating words. This is necessary so that surgeons can remove only the desired tissue while sparing other regions, such as critical movement or language regions. Removing too much brain tissue can cause permanent damage, while removing too little tissue can leave the underlying condition untreated and require additional neurosurgery. Thus, there is a strong need to improve both methods and systems to map the brain as effectively as possible.\n\nIn several recent publications, BCI research experts and medical doctors have collaborated to explore new ways to use BCI technology to improve neurosurgical mapping. This work focuses largely on high gamma activity, which is difficult to detect with non-invasive means. Results have led to improved methods for identifying key areas for movement, language, and other functions. A recent article addressed advances in functional brain mapping and summarizes a workshop.<ref>{{cite journal | vauthors = Ritaccio A, Brunner P, Gunduz A, Hermes D, Hirsch LJ, Jacobs J, Kamada K, Kastner S, Knight RT, Lesser RP, Miller K, Sejnowski T, Worrell G, Schalk G | display-authors = 6 | title = Proceedings of the Fifth International Workshop on Advances in Electrocorticography | journal = Epilepsy & Behavior | volume = 41 | pages = 183\u2013192 | date = December 2014 | pmid = 25461213 | pmc = 4268064 | doi = 10.1016/j.yebeh.2014.09.015 }}</ref>\n\n===Flexible devices===\n[[Flexible electronics]] are [[polymer]]s or other flexible materials (e.g. [[silk]],<ref name=\"KimSilk\">{{cite journal | vauthors = Kim DH, Viventi J, Amsden JJ, Xiao J, Vigeland L, Kim YS, Blanco JA, Panilaitis B, Frechette ES, Contreras D, Kaplan DL, Omenetto FG, Huang Y, Hwang KC, Zakin MR, Litt B, Rogers JA | display-authors = 6 | title = Dissolvable films of silk fibroin for ultrathin conformal bio-integrated electronics | journal = Nature Materials | volume = 9 | issue = 6 | pages = 511\u2013517 | date = June 2010 | pmid = 20400953 | pmc = 3034223 | doi = 10.1038/nmat2745 | bibcode = 2010NatMa...9..511K }}</ref> [[pentacene]], [[polydimethylsiloxane|PDMS]], [[Parylene]], [[polyimide]]<ref name=\"Boppart\">{{cite journal | vauthors = Boppart SA, Wheeler BC, Wallace CS | title = A flexible perforated microelectrode array for extended neural recordings | journal = IEEE Transactions on Bio-Medical Engineering | volume = 39 | issue = 1 | pages = 37\u201342 | date = January 1992 | pmid = 1572679 | doi = 10.1109/10.108125 | s2cid = 36593459 }}</ref>) that are printed with [[electronic circuit|circuitry]]; the flexible nature of the [[organic compound|organic]] background materials allowing the electronics created to bend, and the [[semiconductor device fabrication|fabrication techniques]] used to create these devices resembles those used to create [[integrated circuit]]s and [[microelectromechanical systems]] (MEMS).{{Citation needed|date=December 2019|reason=removing citation to predatory publisher content}} Flexible electronics were first developed in the 1960s and 1970s, but research interest increased in the mid-2000s.<ref name=\"KimBME\">{{cite journal | vauthors = Kim DH, Ghaffari R, Lu N, Rogers JA | title = Flexible and stretchable electronics for biointegrated devices | journal = Annual Review of Biomedical Engineering | volume = 14 | pages = 113\u2013128 | year = 2012 | pmid = 22524391 | doi = 10.1146/annurev-bioeng-071811-150018 | s2cid = 5223203 }}</ref>\n\nFlexible neural interfaces have been extensively tested in recent years in an effort to minimize brain tissue trauma related to mechanical mismatch between electrode and tissue.<ref>{{cite journal | vauthors = Thompson CH, Zoratti MJ, Langhals NB, Purcell EK | title = Regenerative Electrode Interfaces for Neural Prostheses | journal = Tissue Engineering. Part B, Reviews | volume = 22 | issue = 2 | pages = 125\u2013135 | date = April 2016 | pmid = 26421660 | doi = 10.1089/ten.teb.2015.0279 }}</ref> Minimizing tissue trauma could, in theory, extend the lifespan of BCIs relying on flexible electrode-tissue interfaces.\n\n===Neural dust===\n{{main|Neural dust}}\n[[Neural dust]] is a term used to refer to millimeter-sized devices operated as [[Wireless power transfer|wirelessly powered]] nerve sensors that were proposed in a 2011 paper from the [[University of California, Berkeley]] Wireless Research Center, which described both the challenges and outstanding benefits of creating a long lasting wireless BCI.<ref name=Rabaey>{{Cite book| vauthors = Rabaey JM |date=September 2011 |doi=10.1109/essderc.2011.6044240|isbn=978-1-4577-0707-0|chapter=Brain-machine interfaces as the new frontier in extreme miniaturization|title=2011 Proceedings of the European Solid-State Device Research Conference (ESSDERC)|pages=19\u201324|s2cid=47542923}}</ref><ref>{{Cite journal| vauthors = Warneke B, Last M, Liebowitz B, Pister KS |s2cid=21557|date=January 2001|title=Smart Dust: communicating with a cubic-millimeter computer|journal=Computer|volume=34|issue=1|pages=44\u201351|doi=10.1109/2.895117|issn=0018-9162}}</ref> In one proposed model of the neural dust sensor, the transistor model allowed for a method of separating between [[local field potential]]s and [[action potential]] \"spikes\", which would allow for a greatly diversified wealth of data acquirable from the recordings.<ref name=Rabaey/>\n\n== See also ==\n\n{{div col|colwidth=18em}}\n* [[Informatics]]\n* [[AlterEgo]], a system that reads unspoken verbalizations and responds with bone-conduction headphones\n* [[Augmented learning]]\n* [[Biological machine]]\n* [[Cortical implants]]\n* [[Deep brain stimulation]]\n* [[sense|Human senses]]\n* [[Kernel (neurotechnology company)]]\n* [[Lie detection]]\n* [[Microwave auditory effect]]\n* [[Neural engineering]]\n* [[Neuralink]]\n* [[Neurorobotics]]\n* [[Neurostimulation]]\n* [[Nootropic]]\n* [[Project Cyborg]]\n* [[Simulated reality]]\n* [[Telepresence]]\n* [[Thought identification]]\n* [[Wetware computer]] (Uses similar technology for IO)\n* [[Whole brain emulation]]\n{{div col end}}\n\n== Notes ==\n{{reflist|group=note}}\n\n== References ==\n{{Reflist|30em}}\n\n== Further reading ==\n*Brouse, Andrew. [http://cec.sonus.ca/econtact/14_2/brouse_brainwavemusic.html \"A Young Person's Guide to Brainwave Music: Forty years of audio from the human EEG\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n*Gupta, Cota Navin and Ramaswamy Palanappian. [https://econtact.ca/14_2/gupta-palaniappan_interfacedesign.html \"Using High-Frequency Electroencephalogram in Visual and Auditory-Based Brain-Computer Interface Designs\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n*Ouzounian, Gascia. [https://econtact.ca/14_2/ouzounian_biomuse.html \"The Biomuse Trio in Conversation: An Interview with R. Benjamin Knapp and Eric Lyon\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n\n== External links ==\n{{Commons category|Brain-computer interfaces}}\n{{Scholia|topic}}\n*[https://web.archive.org/web/20131117040218/http://unlockproject.org/ The Unlock Project]\n\n{{BCI}}\n{{Neuroscience}}\n{{Footer Neuropsychology}}\n{{emerging technologies|topics=yes|neuro=yes|infocom=yes}}\n{{Authority control}}\n\n<noinclude>\n{{DEFAULTSORT:Brain-computer interface}}\n[[Category:Brain\u2013computer interfacing| ]]\n[[Category:DARPA projects]]\n[[Category:Human\u2013computer interaction]]\n[[Category:Implants (medicine)]]\n[[Category:Neuroprosthetics|*]]\n[[Category:Neural engineering|*]]\n[[Category:User interface techniques]]\n[[Category:Virtual reality]]\n</noinclude>"}