{"title": "Brain\u2013computer interface", "page_id": 623686, "revision_id": 1226546691, "revision_timestamp": "2024-05-31T10:02:42Z", "content": "{{for|direct brain control of prosthetic devices|Neuroprosthetics}}\n{{Use dmy dates|date=December 2022}}\n{{Short description|Direct communication pathway between an enhanced or wired brain and an external device}}\n{{Neuropsychology}}\nA '''brain\u2013computer interface''' ('''BCI'''), sometimes called a '''brain\u2013machine interface''' ('''BMI'''), is a direct communication link between the [[brain]]'s electrical activity and an external device, most commonly a computer or robotic limb. BCIs are often directed at researching, [[Brain mapping|mapping]], assisting, [[Augmented cognition|augmenting]], or repairing human [[Cognitive skill|cognitive]] or [[Sensory-motor coupling|sensory-motor functions]].<ref name=\"Krucoff 584\">{{cite journal | vauthors = Krucoff MO, Rahimpour S, Slutzky MW, Edgerton VR, Turner DA | title = Enhancing Nervous System Recovery through Neurobiologics, Neural Interface Training, and Neurorehabilitation | journal = Frontiers in Neuroscience | volume = 10 | page = 584 |year=2016 | pmid = 28082858 | pmc = 5186786 | doi = 10.3389/fnins.2016.00584 | doi-access = free }}</ref> They are often conceptualized as a [[human\u2013machine interface]] that skips the intermediary of moving body parts (hands...), although they also raise the possibility of [[cyborg|erasing the distinction between brain and machine]]. BCI implementations range from non-invasive ([[EEG]], [[Magnetoencephalography|MEG]], [[MRI]]) and partially invasive ([[ECoG]] and endovascular) to invasive ([[microelectrode array]]), based on how physically close electrodes are to brain tissue.<ref name=\":7\">{{Cite journal |last=Martini |first=Michael L. |last2=Oermann |first2=Eric Karl |last3=Opie |first3=Nicholas L. |last4=Panov |first4=Fedor |last5=Oxley |first5=Thomas |last6=Yaeger |first6=Kurt |date=February 2020 |title=Sensor Modalities for Brain-Computer Interface Technology: A Comprehensive Literature Review |url=https://journals.lww.com/neurosurgery/abstract/2020/02000/sensor_modalities_for_brain_computer_interface.22.aspx |journal=Neurosurgery |language=en-US |volume=86 |issue=2 |pages=E108 |doi=10.1093/neuros/nyz286 |issn=0148-396X}}</ref>\n\nResearch on BCIs began in the 1970s by Jacques Vidal at the [[University of California, Los Angeles]] (UCLA) under a grant from the [[National Science Foundation]], followed by a contract from [[DARPA]].<ref name=\"Vidal1\">{{cite journal | vauthors = Vidal JJ | title = Toward direct brain-computer communication | journal = Annual Review of Biophysics and Bioengineering | volume = 2 | issue = 1 | pages = 157\u2013180 | year = 1973 | pmid = 4583653 | doi = 10.1146/annurev.bb.02.060173.001105 | doi-access = free }}</ref><ref name=\"Vidal2\">{{cite journal| vauthors = Vidal J |title=Real-Time Detection of Brain Events in EEG|journal= Proceedings of the IEEE|year=1977|volume=65|pages=633\u2013641|doi=10.1109/PROC.1977.10542|issue=5|s2cid=7928242}}</ref> Vidal's 1973 paper introduced the expression ''brain\u2013computer interface'' into scientific literature.\n\nDue to the [[cortical plasticity]] of the brain, signals from implanted [[prostheses]] can, after adaptation, be handled by the brain like natural sensor or effector channels.<ref>{{cite journal | vauthors = Levine SP, Huggins JE, BeMent SL, Kushwaha RK, Schuh LA, Rohde MM, Passaro EA, Ross DA, Elisevich KV, Smith BJ | display-authors = 6 | title = A direct brain interface based on event-related potentials | journal = IEEE Transactions on Rehabilitation Engineering | volume = 8 | issue = 2 | pages = 180\u2013185 | date = June 2000 | pmid = 10896180 | doi = 10.1109/86.847809 }}</ref> Following years of animal experimentation, the first [[neuroprosthetic]] devices were implanted in humans in the mid-1990s.\n\nStudies in [[human-computer interaction]] via the application of [[machine learning]] to statistical temporal features extracted from the [[frontal lobe]] ([[Electroencephalography|EEG brainwave]]) data has achieved success in classifying [[mental state]]s (relaxed, neutral, concentrating),<ref>{{cite book | vauthors = Bird JJ, Manso LJ, Ribeiro EP, Ek\u00e1rt A, Faria DR |title=A Study on Mental State Classification using EEG-based Brain-Machine Interface |date=September 2018 |publisher=9th international Conference on Intelligent Systems 2018 |location=Madeira Island, Portugal |url=https://www.researchgate.net/publication/328615252 |access-date=3 December 2018 |ref=birdeegmentalstates}}</ref> mental emotional states (negative, neutral, positive),<ref>{{cite book | vauthors = Bird JJ, Ekart A, Buckingham CD, Faria DR |title=Mental Emotional Sentiment Classification with an EEG-based Brain-Machine Interface |date=2019 |publisher=The International Conference on Digital Image and Signal Processing (DISP'19) |location=St Hugh's College, University of Oxford, United Kingdom |url=https://www.disp-conference.org |access-date=3 December 2018 |ref=birdeegemotions |archive-url=https://web.archive.org/web/20181203202733/https://www.disp-conference.org/ |archive-date=3 December 2018 |url-status=dead }}</ref> and [[thalamocortical dysrhythmia]].<ref>{{cite journal | vauthors = Vanneste S, Song JJ, De Ridder D | title = Thalamocortical dysrhythmia detected by machine learning | language = En | journal = Nature Communications | volume = 9 | issue = 1 | pages = 1103 | date = March 2018 | pmid = 29549239 | pmc = 5856824 | doi = 10.1038/s41467-018-02820-0 | bibcode = 2018NatCo...9.1103V }}</ref>\n\n{{TOC limit|4}}\n\n==History==\nThe history of brain\u2013computer interfaces (BCIs) starts with [[Hans Berger]]'s discovery of the brain's electrical activity and the development of [[electroencephalography]] (EEG). In 1924 Berger was the first to record human brain activity by means of EEG. Berger was able to identify [[neural oscillation|oscillatory activity]], such as the [[alpha wave]] (8\u201313&nbsp;Hz), by analyzing EEG traces.\n\nBerger's first recording device was rudimentary. He inserted [[silver]] wires under the scalps of his patients. These were later replaced by silver foils attached to the patient's head by rubber bandages. Berger connected these sensors to a [[Lippmann electrometer|Lippmann capillary electrometer]], with disappointing results. However, more sophisticated measuring devices, such as the [[Siemens]] double-coil recording [[galvanometer]], which displayed [[voltages]] as small as 10<sup>-4</sup> volt, led to success.\n\nBerger analyzed the interrelation of alternations in his EEG wave diagrams with [[brain diseases]]. EEGs permitted completely new possibilities for brain research.\n\nAlthough the term had not yet been coined, one of the earliest examples of a working brain-machine interface was the piece ''Music for Solo Performer'' (1965) by American composer [[Alvin Lucier]]. The piece makes use of EEG and [[analog signal processing]] hardware (filters, amplifiers, and a mixing board) to stimulate acoustic percussion instruments. Performing the piece requires producing [[alpha waves]] and thereby \"playing\" the various instruments via loudspeakers that are placed near or directly on the instruments.<ref>{{cite journal | vauthors = Straebel V, Thoben W | author-link1 = Volker Straebel |title = Alvin Lucier's music for solo performer: experimental music beyond sonification |url= https://depositonce.tu-berlin.de//handle/11303/7085|journal = Organised Sound |volume = 19 |issue =1 |year = 2014 |pages = 17\u201329|doi = 10.1017/S135577181300037X |s2cid = 62506825 }}</ref>\n\nVidal coined the term \"BCI\" and produced the first peer-reviewed publications on this topic.<ref name=\"Vidal1\"/><ref name=\"Vidal2\"/> He is widely recognized as the inventor of BCIs.<ref name=\"Wolpaw, J.R 2012\">Wolpaw, J.R. and Wolpaw, E.W. (2012). \"Brain-Computer Interfaces: Something New Under the Sun\". In: ''Brain-Computer Interfaces: Principles and Practice'', Wolpaw, J.R. and Wolpaw (eds.), E.W. Oxford University Press.</ref><ref>{{cite journal | vauthors = Wolpaw JR, Birbaumer N, McFarland DJ, Pfurtscheller G, Vaughan TM | title = Brain-computer interfaces for communication and control | journal = Clinical Neurophysiology | volume = 113 | issue = 6 | pages = 767\u2013791 | date = June 2002 | pmid = 12048038 | doi = 10.1016/s1388-2457(02)00057-3 | s2cid = 17571592 }}</ref><ref>{{cite journal | vauthors = Allison BZ, Wolpaw EW, Wolpaw JR | title = Brain-computer interface systems: progress and prospects | journal = Expert Review of Medical Devices | volume = 4 | issue = 4 | pages = 463\u2013474 | date = July 2007 | pmid = 17605682 | doi = 10.1586/17434440.4.4.463 | s2cid = 4690450 }}</ref> A review pointed out that Vidal's 1973 paper stated the \"BCI challenge\"<ref name=\"Bozinovski1\">{{cite journal | vauthors = Bozinovski S, Bozinovska L | year = 2019 | title = Brain-computer interface in Europe: The thirtieth anniversary | journal = Automatika | volume = 60 | issue = 1| pages = 36\u201347 | doi = 10.1080/00051144.2019.1570644 | doi-access = free }}</ref> of controlling external objects using EEG signals, and especially use of [[Contingent negative variation|Contingent Negative Variation (CNV)]] potential as a challenge for BCI control. Vidal's 1977 experiment was the first application of BCI after his 1973 BCI challenge. It was a noninvasive EEG (actually [[Evoked potential|Visual Evoked Potentials]] (VEP)) control of a cursor-like graphical object on a computer screen. The demonstration was movement in a maze.<ref>{{cite journal |last1=Vidal |first1=Jacques J. |title=Real-time detection of brain events in EEG |journal=Proceedings of the IEEE |date=1977 |volume=65 |issue=5 |pages=633\u2013641 |doi=10.1109/PROC.1977.10542 |s2cid=7928242 |url=http://web.cs.ucla.edu/~vidal/Real_Time_Detection.pdf| url-status=dead |access-date=4 November 2022 |language=en |archive-url=https://web.archive.org/web/20150719005915/http://web.cs.ucla.edu/~vidal/Real_Time_Detection.pdf |archive-date=19 July 2015}}</ref>\n\n1988 was the first demonstration of noninvasive EEG control of a physical object, a robot. The experiment demonstrated EEG control of multiple start-stop-restart cycles of movement, along an arbitrary trajectory defined by a line drawn on a floor. The line-following behavior was the default robot behavior, utilizing autonomous intelligence and an autonomous energy source.<ref>S. Bozinovski, M. Sestakov, L. Bozinovska: Using EEG alpha rhythm to control a mobile robot, In G. Harris, C. Walker (eds.) ''Proc. IEEE Annual Conference of Medical and Biological Society'', p. 1515-1516, New Orleans, 1988</ref><ref>S. Bozinovski: Mobile robot trajectory control: From fixed rails to direct bioelectric control, In O. Kaynak (ed.) ''Proc. IEEE Workshop on Intelligent Motion Control'', p. 63-67, Istanbul, 1990</ref><ref>M. Lebedev: Augmentation of sensorimotor functions with neural prostheses. Opera Medica and Physiologica. Vol. 2 (3): 211-227, 2016</ref><ref>M. Lebedev, M. Nicolelis: Brain-machine interfaces: from basic science to neuroprostheses and neurorehabilitation, Physiological Review 97:737-867, 2017</ref>\n\nIn 1990, a report was given on a closed loop, bidirectional, adaptive BCI controlling a computer buzzer by an anticipatory brain potential, the Contingent Negative Variation (CNV) potential.<ref>L. Bozinovska, G. Stojanov, M. Sestakov, S. Bozinovski: CNV pattern recognition: step toward a cognitive wave observation, In L. Torres, E. Masgrau, E. Lagunas (eds.) Signal Processing V: Theories and Applications, Proc. EUSIPCO-90: Fifth European Signal Processing Conference, Elsevier, p. 1659-1662, Barcelona, 1990</ref><ref>L. Bozinovska, S. Bozinovski, G. Stojanov, Electroexpectogram: experimental design and algorithms, In Proc IEEE International Biomedical Engineering Days, p. 55-60, Istanbul, 1992</ref> The experiment described how an expectation state of the brain, manifested by CNV, used a feedback loop to control the S2 buzzer in the S1-S2-CNV paradigm. The resulting cognitive wave representing the expectation learning in the brain was termed Electroexpectogram (EXG). The CNV brain potential was part of the Vidal's 1973 challenge.\n\nStudies in the 2010s suggested neural stimulation's potential to restore functional connectivity and associated behaviors through modulation of molecular mechanisms.<ref>{{cite journal | vauthors = Miranda RA, Casebeer WD, Hein AM, Judy JW, Krotkov EP, Laabs TL, Manzo JE, Pankratz KG, Pratt GA, Sanchez JC, Weber DJ, Wheeler TL, Ling GS | display-authors = 6 | title = DARPA-funded efforts in the development of novel brain-computer interface technologies | journal = Journal of Neuroscience Methods | volume = 244 | pages = 52\u201367 | date = April 2015 | pmid = 25107852 | doi = 10.1016/j.jneumeth.2014.07.019 | s2cid = 14678623 | doi-access = free }}</ref><ref>{{cite journal | vauthors = Jacobs M, Premji A, Nelson AJ | title = Plasticity-inducing TMS protocols to investigate somatosensory control of hand function | journal = Neural Plasticity | volume = 2012 | pages = 350574 | date = 16 May 2012 | pmid = 22666612 | pmc = 3362131 | doi = 10.1155/2012/350574 | doi-access = free }}</ref> This opened the door for the concept that BCI technologies may be able to restore function.\n\nBeginning in 2013, [[DARPA]] funded BCI technology through the BRAIN initiative, which supported work out of teams including [[University of Pittsburgh Medical Center]],<ref>{{cite web |last=Fox |first=Maggie |title=Brain Chip Helps Paralyzed Man Feel His Fingers |url=https://www.nbcnews.com/health/health-news/brain-chip-helps-paralyzed-man-feel-his-fingers-n665881 |website=NBC News |date=October 13, 2016 |access-date=23 March 2021}}</ref> Paradromics,<ref>{{cite web |last=Hatmaker |first=Taylor |title=DARPA awards $65 million to develop the perfect, tiny two-way brain-computer inerface |url= https://techcrunch.com/2017/07/10/darpa-nesd-grants-paradromics/ |website=Tech Crunch |date=July 10, 2017 |access-date=23 March 2021}}</ref> Brown,<ref>{{cite news |first=Kevin |last=Stacey |title=Brown to receive up to $19M to engineer next-generation brain-computer interface |url=https://www.brown.edu/news/2017-07-10/neurograins |website=Brown University |date=July 10, 2017 |access-date=23 March 2021}}</ref> and Synchron.<ref>{{cite web |title=Minimally Invasive \"Stentrode\" Shows Potential as Neural Interface for Brain |url= https://www.darpa.mil/news-events/2016-02-08 |website=Defense Advanced Research Projects Agency (DARPA) |date=2016-02-08 |access-date=23 March 2021}}</ref> \n\n==Neuroprosthetics==\n{{Main|Neuroprosthetics}}\n\nNeuroprosthetics is an area of [[neuroscience]] concerned with neural prostheses, that is, using artificial devices to replace the function of impaired nervous systems and brain-related problems, or of sensory or other organs (bladder, diaphragm, etc.). As of December 2010, [[cochlear implants]] had been implanted as neuroprosthetic devices in some 736,900 people worldwide.<ref>{{cite web|url= https://www.nidcd.nih.gov/health/cochlear-implants|title= Cochlear Implants|date=February 2016|access-date=1 April 2024|publisher= [[National Institute on Deafness and Other Communication Disorders]]}}</ref> Other neuroprosthetic devices aim to restore vision, including [[retinal implant]]s. The first neuroprosthetic device, however, was the [[pacemaker]].\n\nThe terms are sometimes used interchangeably. Neuroprosthetics and BCIs seek to achieve the same aims, such as restoring sight, hearing, movement, ability to communicate, and even [[cognitive function]].<ref name=\"Krucoff 584\"/> Both use similar experimental methods and surgical techniques.\n\n==Animal research==\n{{See also|Remote control animal}}\nSeveral laboratories have managed to read signals from monkey and rat [[cerebral cortices]] to operate BCIs to produce movement. Monkeys have moved [[Cursor (computers)|computer cursors]] and commanded robotic arms to perform simple tasks simply by thinking about the task and seeing the results, without motor output.<ref>Miguel Nicolelis et al. (2001) [http://www.dukemedicine.org/AboutUs/Facts_and_Statistics/historical_highlights/index/view Duke neurobiologist has developed system that allows monkeys to control robot arms via brain signals] {{webarchive |url=https://web.archive.org/web/20081219060005/http://www.dukemedicine.org/AboutUs/Facts_and_Statistics/historical_highlights/index/view |date=19 December 2008 }}</ref> In May 2008 photographs that showed a monkey at the [[University of Pittsburgh Medical Center]] operating a robotic arm by thinking were published in multiple studies.<ref>{{cite web| vauthors = Baum M | title = Monkey Uses Brain Power to Feed Itself With Robotic Arm| publisher = Pitt Chronicle| date = 6 September 2008| url = http://www.chronicle.pitt.edu/?p=1478| access-date = 6 July 2009| url-status = dead| archive-url = https://web.archive.org/web/20090910034547/http://www.chronicle.pitt.edu/?p=1478| archive-date = 10 September 2009| df = dmy-all}}</ref> Sheep have also been used to evaluate BCI technology including Synchron's Stentrode.\n\nIn 2020, [[Elon Musk]]'s [[Neuralink]] was successfully implanted in a pig.<ref>{{cite web | vauthors = Lewis T |title= Elon Musk's Pig-Brain Implant Is Still a Long Way from 'Solving Paralysis' |url= https://www.scientificamerican.com/article/elon-musks-pig-brain-implant-is-still-a-long-way-from-solving-paralysis/ |website=[[Scientific American]] |date= November 2020 |access-date=23 March 2021}}</ref> In 2021, Musk announced that the company had successfully enabled a monkey to play video games using Neuralink's device.<ref>{{cite web | vauthors = Shead S |title=Elon Musk says his start-up Neuralink has wired up a monkey to play video games using its mind |url=https://www.cnbc.com/2021/02/01/elon-musk-neuralink-wires-up-monkey-to-play-video-games-using-mind.html |website=CNBC |date=February 2021 |access-date=23 March 2021}}</ref>\n\n===Early work===\n[[File:Monkey using a robotic arm.jpg|thumb|Monkey operating a robotic arm with brain\u2013computer interfacing (Schwartz lab, University of Pittsburgh)]]\nIn 1969 [[operant conditioning]] studies by Fetz et.al. at the Regional Primate Research Center and Department of Physiology and Biophysics, [[University of Washington School of Medicine]] showed that monkeys could learn to control the deflection of a [[biofeedback]] arm with neural activity.<ref>{{cite journal | vauthors = Fetz EE | title = Operant conditioning of cortical unit activity | journal = Science | volume = 163 | issue = 3870 | pages = 955\u2013958 | date = February 1969 | pmid = 4974291 | doi = 10.1126/science.163.3870.955 | s2cid = 45427819 | bibcode = 1969Sci...163..955F }}</ref> Similar work in the 1970s established that monkeys could learn to control the firing rates of individual and multiple neurons in the primary [[motor cortex]] if they were rewarded accordingly.<ref>{{cite journal | vauthors = Schmidt EM, McIntosh JS, Durelli L, Bak MJ | title = Fine control of operantly conditioned firing patterns of cortical neurons | journal = Experimental Neurology | volume = 61 | issue = 2 | pages = 349\u2013369 | date = September 1978 | pmid = 101388 | doi = 10.1016/0014-4886(78)90252-2 | s2cid = 37539476 }}</ref>\n\n[[Algorithms]] to reconstruct movements from [[motor cortex]] [[neurons]], which control movement, date back to the 1970s. In the 1980s, Georgopoulos at [[Johns Hopkins University]] found a mathematical relationship between the electrical responses of single motor cortex neurons in [[rhesus macaque|rhesus macaque monkeys]] and the direction in which they moved their arms. He also found that dispersed groups of neurons, in different areas of the monkey's brains, collectively controlled motor commands. He was able to record the firings of neurons in only one area at a time, due to equipment limitations.<ref>{{cite journal | vauthors = Georgopoulos AP, Lurito JT, Petrides M, Schwartz AB, Massey JT | title = Mental rotation of the neuronal population vector | journal = Science | volume = 243 | issue = 4888 | pages = 234\u2013236 | date = January 1989 | pmid = 2911737 | doi = 10.1126/science.2911737 | s2cid = 37161168 | bibcode = 1989Sci...243..234G }}</ref>\n\nSeveral groups have been able to capture complex brain motor cortex signals by recording from [[neural ensemble]]s (groups of neurons) and using these to control external devices.{{Cn|date=May 2024}}\n\n===Research ===\n\n====Kennedy and Yang Dan====\nPhillip Kennedy (Neural Signals founder (1987) and colleagues built the first intracortical brain\u2013computer interface by implanting neurotrophic-cone [[electrodes]] into monkeys.{{Citation needed|date=February 2012}}[[File:LGN Cat Vison Recording.jpg|thumb|Yang Dan and colleagues' recordings of cat vision using a BCI implanted in the [[lateral geniculate nucleus]] (top row: original image; bottom row: recording)]]In 1999, [[Yang Dan (neuroscientist)|Yang Dan]] et.al. at [[University of California, Berkeley]] decoded neuronal firings to reproduce images from cats. The team used an array of electrodes embedded in the [[thalamus]] (which integrates the brain's sensory input). Researchers targeted 177 brain cells in the thalamus [[lateral geniculate nucleus]] area, which decodes signals from the [[retina]]. Neuron firings were recorded from watching eight short movies. Using mathematical filters, the researchers decoded the signals to reconstruct recognizable scenes and moving objects.<ref>{{cite journal | vauthors = Stanley GB, Li FF, Dan Y | title = Reconstruction of natural scenes from ensemble responses in the lateral geniculate nucleus | journal = The Journal of Neuroscience | volume = 19 | issue = 18 | pages = 8036\u20138042 | date = September 1999 | pmid = 10479703 | pmc = 6782475 | doi = 10.1523/JNEUROSCI.19-18-08036.1999 }}</ref> \n====Nicolelis====\n{{See also|Walk Again Project}}\n[[Duke University]] professor [[Miguel Nicolelis]] advocates using multiple electrodes spread over a greater area of the brain to obtain neuronal signals.\n\nAfter initial studies in rats during the 1990s, Nicolelis and colleagues developed BCIs that decoded brain activity in [[owl monkeys]] and used the devices to reproduce monkey movements in robotic arms. Monkeys' advanced reaching and grasping abilities and hand manipulation skills, made them good test subjects.\n\nBy 2000, the group succeeded in building a BCI that reproduced owl monkey movements while the monkey operated a [[joystick]] or reached for food.<ref>{{cite journal | vauthors = Wessberg J, Stambaugh CR, Kralik JD, Beck PD, Laubach M, Chapin JK, Kim J, Biggs SJ, Srinivasan MA, Nicolelis MA | display-authors = 6 | title = Real-time prediction of hand trajectory by ensembles of cortical neurons in primates | journal = Nature | volume = 408 | issue = 6810 | pages = 361\u2013365 | date = November 2000 | pmid = 11099043 | doi = 10.1038/35042582 | s2cid = 795720 | bibcode = 2000Natur.408..361W }}</ref> The BCI operated in real time and could remotely control a separate robot. But the monkeys received no feedback ([[open-loop controller|open-loop]] BCI).\n\n[[File:Brain-computer interface (schematic).jpg|thumb|Diagram of the BCI developed by Miguel Nicolelis and colleagues for use on [[rhesus monkeys]]]]\n\nLater experiments on [[rhesus monkeys]] included [[feedback]] and reproduced monkey reaching and grasping movements in a robot arm. Their deeply cleft and furrowed brains made them better models for human [[neurophysiology]] than owl monkeys. The monkeys were trained to reach and grasp objects on a computer screen by manipulating a joystick while corresponding movements by a robot arm were hidden.<ref name=carmena2003>{{cite journal | vauthors = Carmena JM, Lebedev MA, Crist RE, O'Doherty JE, Santucci DM, Dimitrov DF, Patil PG, Henriquez CS, Nicolelis MA | display-authors = 6 | title = Learning to control a brain-machine interface for reaching and grasping by primates | journal = PLOS Biology | volume = 1 | issue = 2 | pages = E42 | date = November 2003 | pmid = 14624244 | pmc = 261882 | doi = 10.1371/journal.pbio.0000042 | doi-access = free }}</ref><ref name=lebedev2005>{{cite journal | vauthors = Lebedev MA, Carmena JM, O'Doherty JE, Zacksenhouse M, Henriquez CS, Principe JC, Nicolelis MA | title = Cortical ensemble adaptation to represent velocity of an artificial actuator controlled by a brain-machine interface | journal = The Journal of Neuroscience | volume = 25 | issue = 19 | pages = 4681\u20134693 | date = May 2005 | pmid = 15888644 | pmc = 6724781 | doi = 10.1523/JNEUROSCI.4088-04.2005 }}</ref> The monkeys were later shown the robot and learned to control it by viewing its movements. The BCI used velocity predictions to control reaching movements and simultaneously predicted [[Grip strength|gripping force]]. \n\nIn 2011 O'Doherty and colleagues showed a BCI with sensory feedback with rhesus monkeys. The monkey controlled the position of an avatar arm while receiving sensory feedback through direct [[Cortical stimulation mapping|intracortical stimulation (ICMS)]] in the arm representation area of the [[sensory cortex]].<ref name=\"Odoherty2003\">{{cite journal | vauthors = O'Doherty JE, Lebedev MA, Ifft PJ, Zhuang KZ, Shokur S, Bleuler H, Nicolelis MA | title = Active tactile exploration using a brain-machine-brain interface | journal = Nature | volume = 479 | issue = 7372 | pages = 228\u2013231 | date = October 2011 | pmid = 21976021 | pmc = 3236080 | doi = 10.1038/nature10489 | bibcode = 2011Natur.479..228O }}</ref>\n\n====Donoghue, Schwartz, and Andersen====\n[[File:164_Angell_Street.jpg|thumb|BCIs are a core focus of the [[Carney Institute for Brain Science]] at [[Brown University]]. ]]\nOther laboratories that have developed BCIs and algorithms that decode neuron signals include [[John Donoghue (neuroscientist)|John Donoghue]] at the [[Carney Institute for Brain Science]] at [[Brown University]], Andrew Schwartz at the [[University of Pittsburgh]], and [[Richard A. Andersen (neuroscientist)|Richard Andersen]] at [[Caltech]]. These researchers produced working BCIs using recorded signals from far fewer neurons than Nicolelis (15\u201330 neurons versus 50\u2013200 neurons).\n\nThe Carney Institute reported training rhesus monkeys to use a BCI to track visual targets on a computer screen (closed-loop BCI) with or without a joystick.<ref>{{cite journal | vauthors = Serruya MD, Hatsopoulos NG, Paninski L, Fellows MR, Donoghue JP | title = Instant neural control of a movement signal | journal = Nature | volume = 416 | issue = 6877 | pages = 141\u2013142 | date = March 2002 | pmid = 11894084 | doi = 10.1038/416141a | s2cid = 4383116 | bibcode = 2002Natur.416..141S }}</ref> The group created a BCI for three-dimensional tracking in virtual reality and reproduced BCI control in a robotic arm.<ref>{{cite journal | vauthors = Taylor DM, Tillery SI, Schwartz AB | title = Direct cortical control of 3D neuroprosthetic devices | journal = Science | volume = 296 | issue = 5574 | pages = 1829\u20131832 | date = June 2002 | pmid = 12052948 | doi = 10.1126/science.1070291 | s2cid = 9402759 | citeseerx = 10.1.1.1027.4335 | bibcode = 2002Sci...296.1829T }}</ref> The same group demonstrated that a monkey could feed itself pieces of fruit and marshmallows using a robotic arm controlled by the animal's brain signals.<ref>[http://www.pittsburghlive.com:8000/x/tribunereview/s_469059.html Pitt team to build on brain-controlled arm] {{webarchive |url=https://web.archive.org/web/20070704125118/http://www.pittsburghlive.com:8000/x/tribunereview/s_469059.html |date=4 July 2007 }}, ''Pittsburgh Tribune Review'', 5 September 2006.</ref><ref>{{YouTube|wxIgdOlT2cY}}</ref><ref>{{cite journal | vauthors = Velliste M, Perel S, Spalding MC, Whitford AS, Schwartz AB | title = Cortical control of a prosthetic arm for self-feeding | journal = Nature | volume = 453 | issue = 7198 | pages = 1098\u20131101 | date = June 2008 | pmid = 18509337 | doi = 10.1038/nature06996 | s2cid = 4404323 | bibcode = 2008Natur.453.1098V | url = https://zenodo.org/record/891045 }}</ref>\n\nAndersen's group used recordings of [[premovement neuronal activity|premovement activity]] from the [[posterior parietal cortex]], including signals created when experimental animals anticipated receiving a reward.<ref>{{cite journal | vauthors = Musallam S, Corneil BD, Greger B, Scherberger H, Andersen RA | title = Cognitive control signals for neural prosthetics | journal = Science | volume = 305 | issue = 5681 | pages = 258\u2013262 | date = July 2004 | pmid = 15247483 | doi = 10.1126/science.1097938 | s2cid = 3112034 | bibcode = 2004Sci...305..258M | url = https://resolver.caltech.edu/CaltechAUTHORS:20141121-110153014 }}</ref>\n\n====Other research====\nIn addition to predicting [[kinematic]] and [[kinetic energy|kinetic]] parameters of limb movements, BCIs that predict [[electromyographic]] or electrical activity of the muscles of primates are in process.<ref>{{cite journal | vauthors = Santucci DM, Kralik JD, Lebedev MA, Nicolelis MA | title = Frontal and parietal cortical ensembles predict single-trial muscle activity during reaching movements in primates | journal = The European Journal of Neuroscience | volume = 22 | issue = 6 | pages = 1529\u20131540 | date = September 2005 | pmid = 16190906 | doi = 10.1111/j.1460-9568.2005.04320.x | s2cid = 31277881 }}</ref> Such BCIs could restore mobility in paralyzed limbs by electrically stimulating muscles.\n\nNicolelis and colleagues demonstrated that large neural ensembles can predict arm position. This work allowed BCIs to read arm movement intentions and translate them into actuator movements. Carmena and colleagues<ref name=carmena2003/> programmed a BCI that allowed a monkey to control reaching and grasping movements by a robotic arm. Lebedev and colleagues argued that brain networks reorganize to create a new representation of the robotic appendage in addition to the representation of the animal's own limbs.<ref name=\"lebedev2005\" />\n\nIn 2019, a study reported a BCI that had the potential to help patients with speech impairment caused by neurological disorders. Their BCI used high-density [[electrocorticography]] to tap neural activity from a patient's brain and used [[deep learning]] to synthesize speech.<ref>{{cite journal | vauthors = Anumanchipalli GK, Chartier J, Chang EF | title = Speech synthesis from neural decoding of spoken sentences | journal = Nature | volume = 568 | issue = 7753 | pages = 493\u2013498 | date = April 2019 | pmid = 31019317 | doi = 10.1038/s41586-019-1119-1 | pmc = 9714519 | s2cid = 129946122 | bibcode = 2019Natur.568..493A }}</ref><ref>{{cite journal | vauthors = Pandarinath C, Ali YH | title = Brain implants that let you speak your mind | language = EN | journal = Nature | volume = 568 | issue = 7753 | pages = 466\u2013467 | date = April 2019 | pmid = 31019323 | doi = 10.1038/d41586-019-01181-y | doi-access = free | bibcode = 2019Natur.568..466P }}</ref> In 2021, those researchers reported the potential of a BCI to decode words and sentences in an [[anarthric]] patient who had been unable to speak for over 15 years.<ref name=\"Neuroprosthesis for Decoding Speech\">{{cite journal | vauthors = Moses DA, Metzger SL, Liu JR, Anumanchipalli GK, Makin JG, Sun PF, Chartier J, Dougherty ME, Liu PM, Abrams GM, Tu-Chan A, Ganguly K, Chang EF | display-authors = 6 | title = Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria | journal = The New England Journal of Medicine | volume = 385 | issue = 3 | pages = 217\u2013227 | date = July 2021 | pmid = 34260835 | doi = 10.1056/NEJMoa2027540 | pmc = 8972947 | s2cid = 235907121 }}</ref><ref>Belluck, Pam (14 July 2021). [https://www.nytimes.com/2021/07/14/health/speech-brain-implant-computer.html \"Tapping Into the Brain to Help a Paralyzed Man Speak\"]. ''The New York Times''.</ref>\n\nThe biggest impediment to BCI technology is the lack of a sensor modality that provides safe, accurate and robust access to brain signals. The use of a better sensor expands the range of communication functions that can be provided using a BCI.\n\nDevelopment and implementation of a BCI system is complex and time-consuming. In response to this problem, Gerwin Schalk has been developing [[BCI2000]], a general-purpose system for BCI research, since 2000.<ref>{{cite web|url=https://www.neurotechcenter.org/publications/2010/using-bci2000-bci-research|title=Using BCI2000 in BCI Research|publisher=National Center for Adaptive Neurotechnology|accessdate=5 December 2023}}</ref>\n\nA new 'wireless' approach uses [[light-gated ion channel]]s such as [[channelrhodopsin]] to control the activity of genetically defined subsets of neurons ''[[in vivo]]''. In the context of a simple learning task, illumination of [[transfected]] cells in the [[Somatosensory system|somatosensory cortex]] influenced decision-making in mice.<ref>{{cite journal | vauthors = Huber D, Petreanu L, Ghitani N, Ranade S, Hrom\u00e1dka T, Mainen Z, Svoboda K|author7-link=Karel Svoboda (scientist) | title = Sparse optical microstimulation in barrel cortex drives learned behaviour in freely moving mice | journal = Nature | volume = 451 | issue = 7174 | pages = 61\u201364 | date = January 2008 | pmid = 18094685 | pmc = 3425380 | doi = 10.1038/nature06445 | bibcode = 2008Natur.451...61H }}</ref>\n\nBCIs led to a deeper understanding of neural networks and the [[central nervous system]]. Research has reported that despite neuroscientists' inclination to believe that neurons have the most effect when working together, single neurons can be conditioned through the use of BCIs to fire in a pattern that allows primates to control motor outputs. BCIs led to development of the single neuron insufficiency principle that states that even with a well-tuned firing rate, single neurons can only carry limited information and therefore the highest level of accuracy is achieved by recording ensemble firings. Other principles discovered with BCIs include the neuronal multitasking principle, the neuronal mass principle, the neural degeneracy principle, and the plasticity principle.<ref>{{cite journal | vauthors = Nicolelis MA, Lebedev MA | title = Principles of neural ensemble physiology underlying the operation of brain-machine interfaces | journal = Nature Reviews. Neuroscience | volume = 10 | issue = 7 | pages = 530\u2013540 | date = July 2009 | pmid = 19543222 | doi = 10.1038/nrn2653 | s2cid = 9290258 }}</ref>\n\nBCIs are proposed to be applied by users without disabilities. Passive BCIs allow for assessing and interpreting changes in the user state during Human-Computer Interaction ([[Human-Computer Interaction|HCI]]). In a secondary, implicit control loop, the system adapts to its user, improving its [[usability]].<ref name=\":0\">{{cite journal |vauthors=Zander TO, Kothe C |date=April 2011 |title=Towards passive brain-computer interfaces: applying brain-computer interface technology to human-machine systems in general |journal=Journal of Neural Engineering |volume=8 |issue=2 |pages=025005 |bibcode=2011JNEng...8b5005Z |doi=10.1088/1741-2560/8/2/025005 |pmid=21436512 |s2cid=37168897}}</ref>\n\nBCI systems can potentially be used to encode signals from the periphery. These sensory BCI devices enable real-time, behaviorally-relevant decisions based upon closed-loop neural stimulation.<ref>{{cite journal | vauthors = Richardson AG, Ghenbot Y, Liu X, Hao H, Rinehart C, DeLuccia S, Torres Maldonado S, Boyek G, Zhang M, Aflatouni F, Van der Spiegel J, Lucas TH | display-authors = 6 | title = Learning active sensing strategies using a sensory brain-machine interface | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 116 | issue = 35 | pages = 17509\u201317514 | date = August 2019 | pmid = 31409713 | pmc = 6717311 | doi = 10.1073/pnas.1909953116 | bibcode = 2019PNAS..11617509R | doi-access = free }}</ref>\n\n====The BCI Award====\nThe [[Annual BCI Research Award|BCI Research Award]] is awarded annually in recognition of innovative research. Each year, a renowned research laboratory is asked to judge projects. The jury consists of BCI experts recruited by that laboratory. The jury selects twelve nominees, then chooses a first, second, and third-place winner, who receive awards of $3,000, $2,000, and $1,000, respectively.\n\n==Human research==\n\n===Invasive BCIs===\nInvasive BCI requires surgery to implant electrodes under the scalp for accessing brain signals. The main advantage is to increase accuracy. Downsides include side effects from the surgery, including scar tissue that can obstruct brain signals or the body may not accept the implanted electrodes.<ref>{{cite journal |vauthors=Abdulkader SN, Atia A, Mostafa MS |date=July 2015 |title=Brain computer interfacing: Applications and challenges |journal=Egyptian Informatics Journal |volume=16 |issue=2 |pages=213\u2013230 |doi=10.1016/j.eij.2015.06.002 |issn=1110-8665 |doi-access=free}}</ref>\n\n==== Vision ====\nInvasive BCI research has targeted repairing damaged sight and providing new functionality for people with paralysis. Invasive BCIs are implanted directly into the [[grey matter]] of the brain during neurosurgery. Because they lie in the grey matter, invasive devices produce the highest quality signals of BCI devices but are prone to [[scar|scar-tissue]] build-up, causing the signal to weaken, or disappear, as the body reacts to the foreign object.<ref>{{cite journal | vauthors = Polikov VS, Tresco PA, Reichert WM | title = Response of brain tissue to chronically implanted neural electrodes | journal = Journal of Neuroscience Methods | volume = 148 | issue = 1 | pages = 1\u201318 | date = October 2005 | pmid = 16198003 | doi = 10.1016/j.jneumeth.2005.08.015 | s2cid = 11248506 }}</ref>\n\nIn [[vision science]], direct [[brain implant]]s have been used to treat non-[[congenital]] (acquired) blindness. One of the first scientists to produce a working brain interface to restore sight was private researcher [[William Dobelle]]. Dobelle's first prototype was implanted into \"Jerry\", a man blinded in adulthood, in 1978. A single-array BCI containing 68 electrodes was implanted onto Jerry's [[visual cortex]] and succeeded in producing [[phosphenes]], the sensation of seeing light. The system included cameras mounted on glasses to send signals to the implant. Initially, the implant allowed Jerry to see shades of grey in a limited field of vision at a low frame-rate. This also required him to be hooked up to a [[mainframe computer]], but shrinking electronics and faster computers made his artificial eye more portable and now enable him to perform simple tasks unassisted.<ref>[https://www.wired.com/wired/archive/10.09/vision.html \"Vision quest\"]. ''[[Wired (magazine)|Wired]]''. (September 2002).</ref>\n\n[[File:BrainGate.jpg|thumb|Dummy unit illustrating the design of a [[BrainGate]] interface]]\n\nIn 2002, Jens Naumann, also blinded in adulthood, became the first in a series of 16 paying patients to receive Dobelle's second generation implant, one of the earliest commercial uses of BCIs. The second generation device used a more sophisticated implant enabling better mapping of phosphenes into coherent vision. Phosphenes are spread out across the visual field in what researchers call \"the starry-night effect\". Immediately after his implant, Jens was able to use his imperfectly restored vision to [[driving|drive]] an automobile slowly around the parking area of the research institute.<ref>{{Cite news| vauthors = Kotler S |title=Vision Quest|language=en-US|magazine=Wired|url=https://www.wired.com/2002/09/vision/|access-date=2021-11-10|issn=1059-1028}}</ref> Dobelle died in 2004 before his processes and developments were documented, leaving no one to continue his work.<ref>{{cite web |date=1 November 2004 |title=Dr. William Dobelle, Artificial Vision Pioneer, Dies at 62 |url=https://www.nytimes.com/2004/11/01/obituaries/01dobelle.html |work=The New York Times |vauthors=Tuller D}}</ref> Subsequently, Naumann and the other patients in the program began having problems with their vision, and eventually lost their \"sight\" again.<ref name=\"Naumann,_2012\">{{cite book | vauthors = Naumann J |title=Search for Paradise: A Patient's Account of the Artificial Vision Experiment. |date=2012 |publisher=Xlibris |isbn=978-1-4797-0920-5}}</ref><ref>{{cite web|author=nurun.com |url=http://www.thewhig.com/2012/11/28/mans-high-tech-paradise-lost |title=Mr. Jen Naumann's high-tech paradise lost |publisher=Thewhig.com |date= 28 November 2012|access-date=19 December 2016}}</ref>\n\n====Movement====\nBCIs focusing on motor neuroprosthetics aim to restore movement in individuals with paralysis or provide devices to assist them, such as interfaces with computers or robot arms.\n\nKennedy and Bakay were first to install a human brain implant that produced signals of high enough quality to simulate movement. Their patient, Johnny Ray (1944\u20132002), developed '[[locked-in syndrome]]' after a brain-stem [[stroke]] in 1997. Ray's implant was installed in 1998 and he lived long enough to start working with the implant, eventually learning to control a computer cursor; he died in 2002 of a [[brain aneurysm]].<ref>{{cite journal | vauthors = Kennedy PR, Bakay RA | title = Restoration of neural output from a paralyzed patient by a direct brain connection | journal = NeuroReport | volume = 9 | issue = 8 | pages = 1707\u20131711 | date = June 1998 | pmid = 9665587 | doi = 10.1097/00001756-199806010-00007 | s2cid = 5681602 }}</ref>\n\n[[Tetraplegic]] [[Matt Nagle]] became the first person to control an artificial hand using a BCI in 2005 as part of the first nine-month human trial of [[Cyberkinetics]]'s [[BrainGate]] chip-implant. Implanted in Nagle's right [[precentral gyrus]] (area of the motor cortex for arm movement), the 96-electrode implant allowed Nagle to control a robotic arm by thinking about moving his hand as well as a computer cursor, lights and TV.<ref>{{cite journal | vauthors = Hochberg LR, Serruya MD, Friehs GM, Mukand JA, Saleh M, Caplan AH, Branner A, Chen D, Penn RD, Donoghue JP | display-authors = 6 | title = Neuronal ensemble control of prosthetic devices by a human with tetraplegia | journal = Nature | volume = 442 | issue = 7099 | pages = 164\u2013171 | date = July 2006 | pmid = 16838014 | doi = 10.1038/nature04970 | s2cid = 4347367 | bibcode = 2006Natur.442..164H | others = Gerhard M. Friehs, Jon A. Mukand, Maryam Saleh, Abraham H. Caplan, Almut Branner, David Chen, Richard D. Penn and John P. Donoghue }}</ref> One year later, Jonathan Wolpaw received the [[Altran Foundation for Innovation]] prize for developing a Brain Computer Interface with electrodes located on the surface of the skull, instead of directly in the brain.<ref>{{cite web|author=Martins Iduwe|url=https://www.academia.edu/32267156|title=Brain Computer Interface|publisher=Academia.edu|accessdate=5 December 2023}}</ref>\n\nResearch teams led by the BrainGate group and another at [[University of Pittsburgh Medical Center]], both in collaborations with the [[United States Department of Veterans Affairs]] (VA), demonstrated control of prosthetic limbs with many degrees of freedom using direct connections to arrays of neurons in the motor cortex of tetraplegia patients.<ref>{{cite journal | vauthors = Hochberg LR, Bacher D, Jarosiewicz B, Masse NY, Simeral JD, Vogel J, Haddadin S, Liu J, Cash SS, van der Smagt P, Donoghue JP | display-authors = 6 | title = Reach and grasp by people with tetraplegia using a neurally controlled robotic arm | journal = Nature | volume = 485 | issue = 7398 | pages = 372\u2013375 | date = May 2012 | pmid = 22596161 | pmc = 3640850 | doi = 10.1038/nature11076 | bibcode = 2012Natur.485..372H }}</ref><ref>{{cite journal | vauthors = Collinger JL, Wodlinger B, Downey JE, Wang W, Tyler-Kabara EC, Weber DJ, McMorland AJ, Velliste M, Boninger ML, Schwartz AB | display-authors = 6 | title = High-performance neuroprosthetic control by an individual with tetraplegia | journal = Lancet | volume = 381 | issue = 9866 | pages = 557\u2013564 | date = February 2013 | pmid = 23253623 | pmc = 3641862 | doi = 10.1016/S0140-6736(12)61816-9 }}</ref>\n\n====Communication====\nIn May 2021, a Stanford University team reported a successful proof-of-concept test that enabled a quadraplegic participant to produce English sentences at about 86 characters per minute and 18 words per minute. The participant imagined moving his hand to write letters, and the system performed handwriting recognition on electrical signals detected in the motor cortex, utilizing [[Hidden Markov models]] and [[recurrent neural networks]].<ref>{{cite journal | vauthors = Willett FR, Avansino DT, Hochberg LR, Henderson JM, Shenoy KV | title = High-performance brain-to-text communication via handwriting | journal = Nature | volume = 593 | issue = 7858 | pages = 249\u2013254 | date = May 2021 | pmid = 33981047 | pmc = 8163299 | doi = 10.1038/s41586-021-03506-2 | bibcode = 2021Natur.593..249W }}</ref><ref>{{cite book | vauthors = Willett FR |title=Brain-Computer Interface Research: A State-of-the-Art Summary 10|chapter=A High-Performance Handwriting BCI|date=2021 |pages=105\u2013109| veditors = Guger C, Allison BZ, Gunduz A |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing|language=en|doi=10.1007/978-3-030-79287-9_11|isbn=978-3-030-79287-9 |s2cid=239736609}}</ref>\n\nA 2021 study reported that a paralyzed patient was able to communicate 15 words per minute using a brain implant that analyzed vocal tract motor neurons.<ref>{{cite web | vauthors = Hamliton J | date = 14 July 2021 | url = https://www.npr.org/sections/health-shots/2021/07/14/1016028911/experimental-brain-implant-lets-man-with-paralysis-turn-his-thoughts-into-words | title = Experimental Brain Implant Lets Man With Paralysis Turn His Thoughts Into Words | work =  All Things Considered | publisher = NPR }}</ref><ref name=\"Neuroprosthesis for Decoding Speech\"/>\n\nIn a review article, authors wondered whether human information transfer rates can surpass that of language with BCIs. Language research has reported that information transfer rates are relatively constant across many languages. This may reflect the brain's information processing limit. Alternatively, this limit may be intrinsic to language itself, as a modality for information transfer.<ref name=\":5\">{{cite journal | vauthors = Pandarinath C, Bensmaia SJ | title = The science and engineering behind sensitized brain-controlled bionic hands | journal = Physiological Reviews | date = September 2021 | volume = 102 | issue = 2 | pages = 551\u2013604 | pmid = 34541898 | doi = 10.1152/physrev.00034.2020 | pmc = 8742729 | s2cid = 237574228 }}</ref>\n\nIn 2023 two studies used BCIs with recurrent neural network to decode speech at a record rate of 62 words per minute and 78 words per minute.<ref>{{Cite journal |last1=Willett |first1=Francis R. |last2=Kunz |first2=Erin M. |last3=Fan |first3=Chaofei |last4=Avansino |first4=Donald T. |last5=Wilson |first5=Guy H. |last6=Choi |first6=Eun Young |last7=Kamdar |first7=Foram |last8=Glasser |first8=Matthew F. |last9=Hochberg |first9=Leigh R. |last10=Druckmann |first10=Shaul |last11=Shenoy |first11=Krishna V. |last12=Henderson |first12=Jaimie M. |date=2023-08-23 |title=A high-performance speech neuroprosthesis |journal=Nature |volume=620 |issue=7976 |language=en |pages=1031\u20131036 |doi=10.1038/s41586-023-06377-x |pmid=37612500 |pmc=10468393 |bibcode=2023Natur.620.1031W |issn=1476-4687}}</ref><ref>{{Cite journal |last1=Metzger |first1=Sean L. |last2=Littlejohn |first2=Kaylo T. |last3=Silva |first3=Alexander B. |last4=Moses |first4=David A. |last5=Seaton |first5=Margaret P. |last6=Wang |first6=Ran |last7=Dougherty |first7=Maximilian E. |last8=Liu |first8=Jessie R. |last9=Wu |first9=Peter |last10=Berger |first10=Michael A. |last11=Zhuravleva |first11=Inga |last12=Tu-Chan |first12=Adelyn |last13=Ganguly |first13=Karunesh |last14=Anumanchipalli |first14=Gopala K. |last15=Chang |first15=Edward F. |date=2023-08-23 |title=A high-performance neuroprosthesis for speech decoding and avatar control |journal=Nature |volume=620 |issue=7976 |language=en |pages=1037\u20131046 |doi=10.1038/s41586-023-06443-4 |pmid=37612505 |pmc=10826467 |bibcode=2023Natur.620.1037M |s2cid=261098775 |issn=1476-4687}}</ref><ref>{{Cite journal |last=Naddaf |first=Miryam |date=2023-08-23 |title=Brain-reading devices allow paralysed people to talk using their thoughts |url=https://www.nature.com/articles/d41586-023-02682-7 |journal=Nature |volume=620 |issue=7976 |pages=930\u2013931 |language=en |doi=10.1038/d41586-023-02682-7|pmid=37612493 |bibcode=2023Natur.620..930N |s2cid=261099321 }}</ref>\n\n==== Technical challenges ====\nThere exist a number of technical challenges to recording brain activity with invasive BCIs. Advances in [[CMOS]] technology are pushing and enabling integrated, invasive BCI designs with smaller size, lower power requirements, and higher signal acquisition capabilities.<ref>{{Cite journal| vauthors = Zhang M, Tang Z, Liu X, Van der Spiegel J |date= April 2020 |title=Electronic neural interfaces |journal=Nature Electronics |language=en |volume=3 |issue=4 |pages=191\u2013200 |doi=10.1038/s41928-020-0390-3 |s2cid= 216508360 |issn=2520-1131 }}</ref> Invasive BCIs involve electrodes that penetrate brain tissue in an attempt to record [[action potential]] signals (also known as spikes) from individual, or small groups of, neurons near the electrode. The interface between a recording electrode and the electrolytic solution surrounding neurons has been modelled using the [[Hodgkin-Huxley model]].<ref>{{cite journal | vauthors = Hodgkin AL, Huxley AF | title = A quantitative description of membrane current and its application to conduction and excitation in nerve | journal = The Journal of Physiology | volume = 117 | issue = 4 | pages = 500\u2013544 | date = August 1952 | pmid = 12991237 | pmc = 1392413 | doi = 10.1113/jphysiol.1952.sp004764 }}</ref><ref name=\"Revealing neuronal function through\">{{cite journal | vauthors = Obien ME, Deligkaris K, Bullmann T, Bakkum DJ, Frey U | title = Revealing neuronal function through microelectrode array recordings | journal = Frontiers in Neuroscience | volume = 8 | pages = 423 | date = 2015 | pmid = 25610364 | doi = 10.3389/fnins.2014.00423 | pmc = 4285113 | doi-access = free }}</ref>\n\nElectronic limitations to invasive BCIs have been an active area of research in recent decades. While [[Patch clamp|intracellular recordings]] of neurons reveal action potential voltages on the scale of hundreds of millivolts, chronic invasive BCIs rely on recording extracellular voltages which typically are three orders of magnitude smaller, existing at hundreds of microvolts.<ref name=\":8\">{{Cite journal| vauthors = Harrison RR |date= July 2008 |title=The Design of Integrated Circuits to Observe Brain Activity |journal=Proceedings of the IEEE|volume=96|issue=7|pages=1203\u20131216|doi=10.1109/JPROC.2008.922581|s2cid= 7020369 |issn=1558-2256}}</ref> Further adding to the challenge of detecting signals on the scale of microvolts is the fact that the electrode-tissue interface has a high [[capacitance]] at small voltages. Due to the nature of these small signals, for BCI systems that incorporate functionality onto an integrated circuit, each electrode requires its own [[amplifier]] and [[Analog-to-digital converter|ADC]], which convert analog extracellular voltages into digital signals.<ref name=\":8\" /> Because a typical neuron action potential lasts for one millisecond, BCIs measuring spikes must have sampling rates ranging from 300&nbsp;Hz to 5&nbsp;kHz. Yet another concern is that invasive BCIs must be low-power, so as to dissipate less heat to surrounding tissue; at the most basic level more power is traditionally needed to optimize [[signal-to-noise ratio]].<ref name=\"Revealing neuronal function through\"/> Optimal battery design is an active area of research in BCIs.<ref>{{Cite book| vauthors = Haci D, Liu Y, Ghoreishizadeh SS, Constandinou TG |title= 2020 IEEE 11th Latin American Symposium on Circuits & Systems (LASCAS) |chapter= Key Considerations for Power Management in Active Implantable Medical Devices |date= February 2020 |pages=1\u20134|doi=10.1109/LASCAS45839.2020.9069004|isbn= 978-1-7281-3427-7 |s2cid= 215817530 |chapter-url= https://discovery.ucl.ac.uk/id/eprint/10090175/ }}</ref>[[File:Invasive and partially invasive BCIs.png|thumb|Illustration of invasive and partially invasive BCIs: electrocorticography (ECoG), endovascular, and intracortical microelectrode.|248x248px]]Challenges existing in the area of [[material science]] are central to the design of invasive BCIs. Variations in signal quality over time have been commonly observed with implantable microelectrodes.<ref>{{cite journal | vauthors = Downey JE, Schwed N, Chase SM, Schwartz AB, Collinger JL | title = Intracortical recording stability in human brain-computer interface users | journal = Journal of Neural Engineering | volume = 15 | issue = 4 | pages = 046016 | date = August 2018 | pmid = 29553484 | doi = 10.1088/1741-2552/aab7a0 | bibcode = 2018JNEng..15d6016D | s2cid = 3961913 }}</ref><ref>{{cite journal | vauthors = Freire MA, Morya E, Faber J, Santos JR, Guimaraes JS, Lemos NA, Sameshima K, Pereira A, Ribeiro S, Nicolelis M | title = Comprehensive analysis of tissue preservation and recording quality from chronic multielectrode implants. | journal = PLOS ONE | volume = 6 | issue = 11 | pages = e27554 | date = November 2011 | pmid = 26098896 | doi = 10.1371/journal.pone.0027554 | pmc = 4476592 | bibcode = 2011PLoSO...627554F | doi-access = free }}</ref> Optimal material and mechanical characteristics for long term signal stability in invasive BCIs has been an active area of research.<ref>{{cite journal | vauthors = Szostak KM, Grand L, Constandinou TG | title = Neural Interfaces for Intracortical Recording: Requirements, Fabrication Methods, and Characteristics | journal = Frontiers in Neuroscience | volume = 11 | pages = 665 | date = 2017 | pmid = 29270103 | doi = 10.3389/fnins.2017.00665 | pmc = 5725438 | doi-access = free }}</ref> It has been proposed that the formation of [[glial scar]]ring, secondary to damage at the electrode-tissue interface, is likely responsible for electrode failure and reduced recording performance.<ref name=\":10\" /> Research has suggested that [[blood-brain barrier]] leakage, either at the time of insertion or over time, may be responsible for the inflammatory and glial reaction to chronic microelectrodes implanted in the brain.<ref name=\":10\">{{cite journal | vauthors = Saxena T, Karumbaiah L, Gaupp EA, Patkar R, Patil K, Betancur M, Stanley GB, Bellamkonda RV | display-authors = 6 | title = The impact of chronic blood-brain barrier breach on intracortical electrode function | journal = Biomaterials | volume = 34 | issue = 20 | pages = 4703\u20134713 | date = July 2013 | pmid = 23562053 | doi = 10.1016/j.biomaterials.2013.03.007 }}</ref><ref>{{cite journal | vauthors = Nolta NF, Christensen MB, Crane PD, Skousen JL, Tresco PA | title = BBB leakage, astrogliosis, and tissue loss correlate with silicon microelectrode array recording performance | journal = Biomaterials | volume = 53 | pages = 753\u2013762 | date = 2015-06-01 | pmid = 25890770 | doi = 10.1016/j.biomaterials.2015.02.081 }}</ref> As a result, flexible<ref>{{cite journal | vauthors = Robinson JT, Pohlmeyer E, Gather MC, Kemere C, Kitching JE, Malliaras GG, Marblestone A, Shepard KL, Stieglitz T, Xie C | display-authors = 6 | title = Developing Next-generation Brain Sensing Technologies - A Review | journal = IEEE Sensors Journal | volume = 19 | issue = 22 | pages = 10163\u201310175 | date = November 2019 | pmid = 32116472 | doi = 10.1109/JSEN.2019.2931159 | pmc = 7047830 }}</ref><ref>{{cite journal | vauthors = Luan L, Wei X, Zhao Z, Siegel JJ, Potnis O, Tuppen CA, Lin S, Kazmi S, Fowler RA, Holloway S, Dunn AK, Chitwood RA, Xie C | display-authors = 6 | title = Ultraflexible nanoelectronic probes form reliable, glial scar-free neural integration | journal = Science Advances | volume = 3 | issue = 2 | pages = e1601966 | date = February 2017 | pmid = 28246640 | pmc = 5310823 | doi = 10.1126/sciadv.1601966 | bibcode = 2017SciA....3E1966L }}</ref><ref>{{cite journal | vauthors = Frank JA, Antonini MJ, Anikeeva P | title = Next-generation interfaces for studying neural function | journal = Nature Biotechnology | volume = 37 | issue = 9 | pages = 1013\u20131023 | date = September 2019 | pmid = 31406326 | pmc = 7243676 | doi = 10.1038/s41587-019-0198-8 }}</ref> and tissue-like designs<ref name=\":9\">{{cite journal | vauthors = Hong G, Viveros RD, Zwang TJ, Yang X, Lieber CM | title = Tissue-like Neural Probes for Understanding and Modulating the Brain | journal = Biochemistry | volume = 57 | issue = 27 | pages = 3995\u20134004 | date = July 2018 | pmid = 29529359 | pmc = 6039269 | doi = 10.1021/acs.biochem.8b00122 }}</ref><ref>{{cite journal | vauthors = Viveros RD, Zhou T, Hong G, Fu TM, Lin HG, Lieber CM | title = Advanced One- and Two-Dimensional Mesh Designs for Injectable Electronics | journal = Nano Letters | volume = 19 | issue = 6 | pages = 4180\u20134187 | date = June 2019 | pmid = 31075202 | pmc = 6565464 | doi = 10.1021/acs.nanolett.9b01727 | bibcode = 2019NanoL..19.4180V }}</ref> have been researched and developed to minimize [[foreign-body reaction]] by means of matching the [[Young's modulus]] of the electrode closer to that of brain tissue.<ref name=\":9\" />\n\n===Partially invasive BCIs===\nPartially invasive BCI devices are implanted inside the skull but rest outside the brain rather than within the grey matter. They produce higher resolution signals than non-invasive BCIs where the bone tissue of the cranium deflects and deforms signals and have a lower risk of forming scar-tissue in the brain than fully invasive BCIs. Preclinical demonstration of intracortical BCIs from the stroke perilesional cortex has been conducted.<ref name=\"robust neuroprosthetic\">{{cite journal | vauthors = Gulati T, Won SJ, Ramanathan DS, Wong CC, Bodepudi A, Swanson RA, Ganguly K | title = Robust neuroprosthetic control from the stroke perilesional cortex | journal = The Journal of Neuroscience | volume = 35 | issue = 22 | pages = 8653\u20138661 | date = June 2015 | pmid = 26041930 | pmc = 6605327 | doi = 10.1523/JNEUROSCI.5007-14.2015 }}</ref>\n\n====Endovascular====\nA systematic review published in 2020 detailed multiple clinical and non-clinical studies investigating the feasibility of endovascular BCIs.<ref>{{cite journal | vauthors = Soldozy S, Young S, Kumar JS, Capek S, Felbaum DR, Jean WC, Park MS, Syed HR | display-authors = 6 | title = A systematic review of endovascular stent-electrode arrays, a minimally invasive approach to brain-machine interfaces | language = en-US | journal = Neurosurgical Focus | volume = 49 | issue = 1 | pages = E3 | date = July 2020 | pmid = 32610291 | doi = 10.3171/2020.4.FOCUS20186 | s2cid = 220308983 | doi-access = free }}</ref>\n\nIn 2010, researchers affiliated with University of Melbourne began developing a BCI that could be inserted via the vascular system. Australian neurologist [[Thomas Oxley (Mount Sinai Hospital)|Thomas Oxley]] conceived the idea for this BCI, called Stentrode, earning funding from [[DARPA]]. Preclinical studies evaluated the technology in sheep.<ref name=\":7\" />\n\n[[Stentrode]] is a monolithic [[Stent-electrode recording array|stent electrode array]], is designed to be delivered via an intravenous catheter under image-guidance to the [[superior sagittal sinus]], in the region which lies adjacent to the [[motor cortex]].<ref name=\":4\">{{cite book | vauthors = Opie N | title = Brain-Computer Interface Research| chapter = The StentrodeTM Neural Interface System|date=2021 |pages=127\u2013132| veditors = Guger C, Allison BZ, Tangermann M |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing |doi=10.1007/978-3-030-60460-8_13 |isbn = 978-3-030-60460-8 | s2cid = 234102889}}</ref> This proximity enables Stentrode to measure neural activity. The procedure is most similar to how venous sinus stents are placed for the treatment of [[idiopathic intracranial hypertension]].<ref>{{cite journal | vauthors = Teleb MS, Cziep ME, Lazzaro MA, Gheith A, Asif K, Remler B, Zaidat OO | title = Idiopathic Intracranial Hypertension. A Systematic Analysis of Transverse Sinus Stenting | journal = Interventional Neurology | volume = 2 | issue = 3 | pages = 132\u2013143 | date = May 2014 | pmid = 24999351 | pmc = 4080637 | doi = 10.1159/000357503 }}</ref> Stentrode communicates neural activity to a battery-less telemetry unit implanted in the chest, which communicates wirelessly with an external telemetry unit capable of power and data transfer. While an endovascular BCI benefits from avoiding a [[craniotomy]] for insertion, risks such as [[Thrombus|clotting]] and [[venous thrombosis]] exist.<!--In pre-clinical animal studies implanted with Stentrode, twenty animals showed no evidence of thrombus formation after 190 days, possibly due to endothelial incorporation of the Stentrode into the vessel wall.<ref name=\":4\" />-->\n\nHuman trials with Stentrode were underway as of 2021.<ref name=\":4\" /> In November 2020, two participants with [[amyotrophic lateral sclerosis]] were able to wirelessly control an operating system to text, email, shop, and bank using direct thought using Stentrode,<ref>{{cite web | vauthors = Bryson S |title=Stentrode Device Allows Computer Control by ALS Patients with Partial Upper Limb Paralysis |url=https://alsnewstoday.com/news-posts/2020/11/05/stentrode-device-allows-computer-control-by-als-patients-with-partial-upper-limb-paralysis |website=ALS News Today|date=5 November 2020 }}</ref> marking the first time a brain-computer interface was implanted via the patient's blood vessels, eliminating the need for brain surgery. In January 2023, researchers reported no serious adverse events during the first year for all four patients, who could use it to operate computers.<ref>{{cite news |last1=Lanese |first1=Nicoletta |title=New 'thought-controlled' device reads brain activity through the jugular |url=https://www.livescience.com/brain-computer-interface-through-vein-safety |access-date=16 February 2023 |work=livescience.com |date=12 January 2023 |language=en |archive-date=16 February 2023 |archive-url=https://web.archive.org/web/20230216220922/https://www.livescience.com/brain-computer-interface-through-vein-safety |url-status=live }}</ref><ref>{{cite journal |last1=Mitchell |first1=Peter |last2=Lee |first2=Sarah C. M. |last3=Yoo |first3=Peter E. |last4=Morokoff |first4=Andrew |last5=Sharma |first5=Rahul P. |last6=Williams |first6=Daryl L. |last7=MacIsaac |first7=Christopher |last8=Howard |first8=Mark E. |last9=Irving |first9=Lou |last10=Vrljic |first10=Ivan |last11=Williams |first11=Cameron |last12=Bush |first12=Steven |last13=Balabanski |first13=Anna H. |last14=Drummond |first14=Katharine J. |last15=Desmond |first15=Patricia |last16=Weber |first16=Douglas |last17=Denison |first17=Timothy |last18=Mathers |first18=Susan |last19=O'Brien |first19=Terence J. |last20=Mocco |first20=J. |last21=Grayden |first21=David B. |last22=Liebeskind |first22=David S. |last23=Opie |first23=Nicholas L. |last24=Oxley |first24=Thomas J. |last25=Campbell |first25=Bruce C. V. |title=Assessment of Safety of a Fully Implanted Endovascular Brain-Computer Interface for Severe Paralysis in 4 Patients: The Stentrode With Thought-Controlled Digital Switch (SWITCH) Study |journal=JAMA Neurology |date=9 January 2023 |volume=80 |issue=3 |pages=270\u2013278 |doi=10.1001/jamaneurol.2022.4847 |pmid=36622685 |pmc=9857731 |s2cid=255545643 |issn=2168-6149|url=https://jamanetwork.com/journals/jamaneurology/article-abstract/2799839|url-access=subscription}}</ref>\n\n==== Electrocorticography ====\n[[Electrocorticography]] (ECoG) measures brain electrical activity from beneath the skull in a way similar to non-invasive electroencephalography, using electrodes embedded in a thin plastic pad placed above the cortex, beneath the [[dura mater]].<ref>{{cite book | last1=Serruya | first1=Mijail | last2=Donoghue | first2=John | chapter = Chapter III: Design Principles of a Neuromotor Prosthetic Device | title = Neuroprosthetics: Theory and Practice | veditors = Horch KW, Dhillon GS | publisher = Imperial College Press | year=2004 |pages=1158\u20131196 | doi=10.1142/9789812561763_0040 | archive-url=https://web.archive.org/web/20050404155139/http://donoghue.neuro.brown.edu/pubs/2003-SerruyaDonoghue-Chap3-preprint.pdf | archive-date=4 April 2005 |chapter-url=http://donoghue.neuro.brown.edu/pubs/2003-SerruyaDonoghue-Chap3-preprint.pdf}}</ref> ECoG technologies were first trialled in humans in 2004 by Eric Leuthardt and Daniel Moran from [[Washington University in St. Louis]]. In a later trial, the researchers enabled a teenage boy to play [[Space Invaders]].<ref>{{cite web | url = http://news-info.wustl.edu/news/page/normal/7800.html | title = Teenager moves video icons just by imagination | work = Press release | publisher = Washington University in St Louis | date = 9 October 2006 }}</ref> This research indicates that control is rapid, requires minimal training, balancing signal fidelity and level of invasiveness.{{refn|group=note|These electrodes had not been implanted in the patient with the intention of developing a BCI. The patient had had severe [[epilepsy]] and the electrodes were temporarily implanted to help his physicians localize seizure foci; the BCI researchers simply took advantage of this.<ref>{{cite journal | vauthors = Schalk G, Miller KJ, Anderson NR, Wilson JA, Smyth MD, Ojemann JG, Moran DW, Wolpaw JR, Leuthardt EC | display-authors = 6 | title = Two-dimensional movement control using electrocorticographic signals in humans | journal = Journal of Neural Engineering | volume = 5 | issue = 1 | pages = 75\u201384 | date = March 2008 | pmid = 18310813 | pmc = 2744037 | doi = 10.1088/1741-2560/5/1/008 | bibcode = 2008JNEng...5...75S }}</ref>}}\n\nSignals can be either subdural or epidural, but are not taken from within the brain [[parenchyma]]. Patients are required to have invasive monitoring for localization and resection of an epileptogenic focus.{{Cn|date=May 2024}}\n\nECoG offers higher spatial resolution, better signal-to-noise ratio, wider frequency range, and less training requirements than scalp-recorded EEG, and at the same time has lower technical difficulty, lower clinical risk, and may have superior long-term stability than intracortical single-neuron recording.<ref>{{cite journal | vauthors = Nicolas-Alonso LF, Gomez-Gil J | title = Brain computer interfaces, a review | journal = Sensors | volume = 12 | issue = 2 | pages = 1211\u20131279 | date = 2012-01-31 | pmid = 22438708 | pmc = 3304110 | doi = 10.3390/s120201211 | bibcode = 2012Senso..12.1211N | doi-access = free }}</ref> This feature profile and evidence of the high level of control with minimal training requirements shows potential for real world application for people with motor disabilities.<ref name=Mondeofuse>{{cite news | vauthors = Yanagisawa T |title=Electrocorticographic Control of Prosthetic Arm in Paralyzed Patients |doi=10.1002/ana.22613 |quote= ECoG- Based BCI has advantage in signal and durability that are absolutely necessary for clinical application|work=[[American Neurological Association]] |year= 2011 |volume=71 |issue=3 |pages=353\u2013361 }}</ref><ref name=TelepathicCommVowel>{{cite news | vauthors = Pei X |title=Decoding Vowels and Consonants in Spoken and Imagined Words Using Electrocorticographic Signals in Humans |pmid=21750369 |quote= Justin Williams, a biomedical engineer at the university, has already transformed the ECoG implant into a micro device that can be installed with a minimum of fuss. It has been tested in animals for a long period of time \u2013 the micro ECoG stays in place and doesn't seem to negatively affect the immune system.|work=J Neural Eng 046028th ser. 8.4 |year=2011 }}</ref> \n\n[[Edward Chang (neurosurgeon)|Edward Chang]] and Joseph Makin from [[UCSF Medical Center|UCSF]] reported that ECoG signals could be used to decode speech from epilepsy patients implanted with high-density ECoG arrays over the peri-Sylvian cortices.<ref>{{cite book | vauthors = Makin JG, Moses DA, Chang EF | title = Brain-Computer Interface Research | veditors = Guger C, Allison BZ, Gunduz A | chapter = Speech Decoding as Machine Translation|date=2021 |pages=23\u201333 |series=SpringerBriefs in Electrical and Computer Engineering|place=Cham|publisher=Springer International Publishing |language=en |doi=10.1007/978-3-030-79287-9_3 |isbn=978-3-030-79287-9 | s2cid = 239756345 }}</ref><ref>{{cite journal | vauthors = Makin JG, Moses DA, Chang EF | title = Machine translation of cortical activity to text with an encoder-decoder framework | journal = Nature Neuroscience | volume = 23 | issue = 4 | pages = 575\u2013582 | date = April 2020 | pmid = 32231340 | doi = 10.1038/s41593-020-0608-8 | pmc = 10560395 | s2cid = 214704481 }}</ref> They reported word error rates of 3% (a marked improvement from prior efforts) utilizing an encoder-decoder [[neural network]], which translated ECoG data into one of fifty sentences composed of 250 unique words.\n\n===Non-invasive BCIs===\nHuman experiments have used [[non-invasive]] [[neuroimaging]] interfaces. The majority of published BCI research involves noninvasive EEG-based BCIs. EEG-based technologies and interfaces have been used for the broadest variety of applications. Although EEG-based interfaces are easy to wear and do not require surgery, they have relatively poor spatial resolution and cannot effectively use higher-frequency signals because the skull interferes, dispersing and blurring the electromagnetic waves created by the neurons. EEG-based interfaces also require some time and effort prior to each usage session, while others require no prior-usage training. The choice of a specific BCI for a patient depends on numerous factors.\n\n====Functional near-infrared spectroscopy====\nIn 2014 and 2017, a BCI using [[functional near-infrared spectroscopy]] for \"locked-in\" patients with [[amyotrophic lateral sclerosis]] (ALS) was able to restore basic ability to communicate.<ref>{{cite journal | vauthors = Gallegos-Ayala G, Furdea A, Takano K, Ruf CA, Flor H, Birbaumer N | title = Brain communication in a completely locked-in patient using bedside near-infrared spectroscopy | journal = Neurology | volume = 82 | issue = 21 | pages = 1930\u20131932 | date = May 2014 | pmid = 24789862 | pmc = 4049706 | doi = 10.1212/WNL.0000000000000449 }}</ref><ref name=\"RamseyChaudhary2017\">{{cite journal | vauthors = Chaudhary U, Xia B, Silvoni S, Cohen LG, Birbaumer N | title = Brain-Computer Interface-Based Communication in the Completely Locked-In State | journal = PLOS Biology | volume = 15 | issue = 1 | pages = e1002593 | date = January 2017 | pmid = 28141803 | pmc = 5283652 | doi = 10.1371/journal.pbio.1002593 | doi-access = free }}</ref>\n\n====Electroencephalography (EEG)-based brain-computer interfaces====\n\n[[File:ElectroEncephalogram.png|thumb|Recordings of brainwaves produced by an [[electroencephalogram]]]]\n\nAfter Vidal stated the BCI challenge, the initial reports on non-invasive approaches included control of a cursor in 2D using VEP,<ref>Vidal 1977</ref> control of a buzzer using CNV,<ref>Bozinovska et al. 1988, 1990</ref> control of a physical object, a robot, using a brain rhythm (alpha),<ref>Bozinovski et al. 1988</ref> control of a text written on a screen using P300.<ref>Farwell and Donchin, 1988</ref><ref name=\"Bozinovski12\">{{cite journal |vauthors=Bozinovski S, Bozinovska L |year=2019 |title=Brain-computer interface in Europe: The thirtieth anniversary |journal=Automatika |volume=60 |issue=1 |pages=36\u201347 |doi=10.1080/00051144.2019.1570644 |doi-access=free}}</ref>\n\nIn the early days of BCI research, another substantial barrier to using EEG was that extensive training ws required. For example, in experiments beginning in the mid-1990s, Niels Birbaumer at the [[University of T\u00fcbingen]] in [[Germany]] trained paralysed people to self-regulate the slow cortical potentials in their EEG to such an extent that these signals could be used as a binary signal to control a computer cursor. (Birbaumer had earlier trained [[Epilepsy|epileptics]] to prevent impending fits by controlling this low voltage wave.) The experiment trained ten patients to move a computer cursor. The process was slow, requiring more than an hour for patients to write 100 characters with the cursor, while training often took months. The slow cortical potential approach has fallen away in favor of approaches that require little or no training, are faster and more accurate, and work for a greater proportion of users.<ref>{{Cite magazine |last=Winters |first=Jeffrey |date=May 2003 |title=Communicating by Brain Waves |url=http://www.psychologytoday.com/articles/200307/communicating-brain-waves |magazine=Psychology Today}}</ref>\n\nAnother research parameter is the type of [[Neural oscillation|oscillatory activity]] that is measured. Gert Pfurtscheller founded the BCI Lab 1991 and conducted the first online BCI based on oscillatory features and classifiers. Together with Birbaumer and Jonathan Wolpaw at [[New York State University]] they focused on developing technology that would allow users to choose the brain signals they found easiest to operate a BCI, including ''[[Mu wave|mu]]'' and ''[[Beta wave|beta]]'' rhythms.{{Cn|date=May 2024}}\n\nA further parameter is the method of feedback used as shown in studies of [[P300 (Neuroscience)|P300]] signals. Patterns of P300 waves are generated involuntarily ([[Event-related potential|stimulus-feedback]]) when people see something they recognize and may allow BCIs to decode categories of thoughts without training.{{Cn|date=May 2024}}\n\nA 2005 study reported EEG emulation of digital control circuits, using a CNV flip-flop.<ref>Adrijan Bozinovski \"CNV flip-flop as a brain-computer interface paradigm\" In J. Kern, S. Tonkovic, et al. (Eds) Proc 7th Conference of the Croatian Association of Medical Informatics, pp. 149-154, Rijeka, 2005</ref> A 2009 study reported noninvasive EEG control of a robotic arm using a CNV flip-flop.<ref>{{cite conference |last1=Bozinovski |first1=Adrijan |last2=Bozinovska |first2=Liljana |year=2009 |title=Anticipatory brain potentials in a Brain-Robot Interface paradigm |conference=2009 4th International IEEE/EMBS Conference on Neural Engineering |publisher=IEEE |pages=451\u2013454 |doi=10.1109/ner.2009.5109330}}</ref> A 2011 study reported control of two robotic arms solving [[Tower of Hanoi]] task with three disks using a CNV flip-flop.<ref>{{cite journal |last1=Bo\u017einovski |first1=Adrijan |last2=Tonkovi\u0107 |first2=Stanko |last3=I\u0161gum |first3=Velimir |last4=Bo\u017einovska |first4=Liljana |year=2011 |title=Robot Control Using Anticipatory Brain Potentials |url=https://hrcak.srce.hr/file/106106 |journal=Automatika |language=en |volume=52 |issue=1 |pages=20\u201330 |doi=10.1080/00051144.2011.11828400 |s2cid=33223634 |doi-access=free}}</ref> A 2015 study described EEG-emulation of a [[Schmitt trigger]], flip-flop, [[demultiplexer]], and [[modem]].<ref>{{cite journal |last1=Bozinovski |first1=Stevo |last2=Bozinovski |first2=Adrijan |year=2015 |title=Mental States, EEG Manifestations, and Mentally Emulated Digital Circuits for Brain-Robot Interaction |journal=IEEE Transactions on Autonomous Mental Development |publisher=Institute of Electrical and Electronics Engineers (IEEE) |volume=7 |issue=1 |pages=39\u201351 |doi=10.1109/tamd.2014.2387271 |issn=1943-0604 |s2cid=21464338 |doi-access=free}}</ref>\n\nAdvances by [[Bin He]] and his team at [[University of Minnesota]] suggest the potential of EEG-based brain-computer interfaces to accomplish tasks close to invasive brain-computer interfaces. Using advanced functional neuroimaging including BOLD functional [[MRI]] and [[EEG]] source imaging, They identified the co-variation and co-localization of [[electrophysiological]] and [[hemodynamic]] signals.<ref>{{cite journal |vauthors=Yuan H, Liu T, Szarkowski R, Rios C, Ashe J, He B |date=February 2010 |title=Negative covariation between task-related responses in alpha/beta-band activity and BOLD in human sensorimotor cortex: an EEG and fMRI study of motor imagery and movements |journal=NeuroImage |volume=49 |issue=3 |pages=2596\u20132606 |doi=10.1016/j.neuroimage.2009.10.028 |pmc=2818527 |pmid=19850134}}</ref> Refined by a neuroimaging approach and a training protocol, They fashioned a non-invasive EEG based brain-computer interface to control the flight of a virtual helicopter in 3-dimensional space, based upon motor imagination.<ref>{{cite journal |vauthors=Doud AJ, Lucas JP, Pisansky MT, He B |year=2011 |title=Continuous three-dimensional control of a virtual helicopter using a motor imagery based brain-computer interface |journal=PLOS ONE |volume=6 |issue=10 |pages=e26322 |bibcode=2011PLoSO...626322D |doi=10.1371/journal.pone.0026322 |pmc=3202533 |pmid=22046274 |doi-access=free |veditors=Gribble PL}}</ref> In June 2013 they announced a technique to guide a remote-control helicopter through an obstacle course.<ref>{{cite web |date=5 June 2013 |title=Thought-guided helicopter takes off |url=https://www.bbc.co.uk/news/science-environment-22764978 |access-date=5 June 2013 |work=BBC News}}</ref> They also solved the EEG [[inverse problem]] and then used the resulting virtual EEG for BCI tasks. Well-controlled studies suggested the merits of such a source analysis-based BCI.<ref>{{cite journal |vauthors=Qin L, Ding L, He B |date=September 2004 |title=Motor imagery classification by means of source analysis for brain-computer interface applications |journal=Journal of Neural Engineering |volume=1 |issue=3 |pages=135\u2013141 |bibcode=2004JNEng...1..135Q |doi=10.1088/1741-2560/1/3/002 |pmc=1945182 |pmid=15876632}}</ref>\n\nA 2014 study reported that severely motor-impaired patients could communicate faster and more reliably with non-invasive EEG BCI than with muscle-based communication channels.<ref>{{cite journal |vauthors=H\u00f6hne J, Holz E, Staiger-S\u00e4lzer P, [[Klaus-Robert M\u00fcller|M\u00fcller KR]], K\u00fcbler A, Tangermann M |date=2014 |title=Motor imagery for severely motor-impaired patients: evidence for brain-computer interfacing as superior control solution |journal=PLOS ONE |volume=9 |issue=8 |pages=e104854 |bibcode=2014PLoSO...9j4854H |doi=10.1371/journal.pone.0104854 |pmc=4146550 |pmid=25162231 |doi-access=free}}</ref>\n\nA 2019 study reported that the application of evolutionary algorithms could improve EEG mental state classification with a non-invasive [[Muse (headband)|Muse]] device, enabling classification of data acquired by a consumer-grade sensing device.<ref>{{cite journal |vauthors=Bird JJ, Faria DR, Manso LJ, Ek\u00e1rt A, Buckingham CD |date=2019-03-13 |title=A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for Brain-Machine Interaction |journal=Complexity |publisher=Hindawi Limited |volume=2019 |pages=1\u201314 |arxiv=1908.04784 |doi=10.1155/2019/4316548 |issn=1076-2787 |doi-access=free}}</ref>\n\nIn a 2021 systematic review of [[randomized controlled trials]] using BCI for post-stroke upper-limb rehabilitation, EEG-based BCI was reported to have efficacy in improving upper-limb motor function compared to control therapies. More specifically, BCI studies that utilized band power features, [[motor imagery]], and [[functional electrical stimulation]] were reported to be more effective than alternatives.<ref>{{cite journal |vauthors=Mansour S, Ang KK, Nair KP, Phua KS, Arvaneh M |date=January 2022 |title=Efficacy of Brain-Computer Interface and the Impact of Its Design Characteristics on Poststroke Upper-limb Rehabilitation: A Systematic Review and Meta-analysis of Randomized Controlled Trials |journal=Clinical EEG and Neuroscience |volume=53 |issue=1 |pages=79\u201390 |doi=10.1177/15500594211009065 |pmc=8619716 |pmid=33913351 |s2cid=233446181}}</ref> Another 2021 systematic review focused on post-stroke robot-assisted EEG-based BCI for hand rehabilitation. Improvement in motor assessment scores was observed in three of eleven studies.<ref>{{cite journal |display-authors=6 |vauthors=Baniqued PD, Stanyer EC, Awais M, Alazmani A, Jackson AE, Mon-Williams MA, Mushtaq F, Holt RJ |date=January 2021 |title=Brain-computer interface robotics for hand rehabilitation after stroke: a systematic review |journal=Journal of Neuroengineering and Rehabilitation |volume=18 |issue=1 |pages=15 |doi=10.1186/s12984-021-00820-8 |pmc=7825186 |pmid=33485365 |doi-access=free}}</ref>\n\n====Dry active electrode arrays====\nIn the early 1990s Babak Taheri, at [[University of California, Davis]] demonstrated the first single and multichannel dry active electrode arrays.<ref>{{cite journal |vauthors=Taheri BA, Knight RT, Smith RL |date=May 1994 |title=A dry electrode for EEG recording |url=https://zenodo.org/record/1253862 |journal=Electroencephalography and Clinical Neurophysiology |volume=90 |issue=5 |pages=376\u2013383 |doi=10.1016/0013-4694(94)90053-1 |pmid=7514984}}</ref> The arrayed electrode was demonstrated to perform well compared to [[silver]]/[[silver chloride]] electrodes. The device consisted of four sensor sites with integrated electronics to reduce noise by [[impedance matching]]. The advantages of such electrodes are:\n\n* no electrolyte used,\n* no skin preparation,\n* significantly reduced sensor size,\n* compatibility with EEG monitoring systems.\n\nThe active electrode array is an integrated system containing an array of capacitive sensors with local integrated circuitry packaged with batteries to power the circuitry. This level of integration was required to achieve the result.\n\nThe electrode was tested on a test bench and on human subjects in four modalities, namely:\n\n* spontaneous EEG,\n* sensory event-related potentials,\n* brain stem potentials,\n* cognitive event-related potentials.\n\nPerformance compared favorably with that of standard wet electrodes in terms of skin preparation, no gel requirements (dry), and higher signal-to-noise ratio.<ref>{{cite thesis |bibcode=1994PhDT........82A |title=Active Micromachined Scalp Electrode Array for Eeg Signal Recording |vauthors=Alizadeh-Taheri B |degree=PHD Thesis |year=1994 |page=82}}</ref>\n\nIn 1999 Hunter Peckham and others at [[Case Western Reserve University]] used a 64-electrode EEG skullcap to return limited hand movements to a [[quadriplegic]]. As he concentrated on simple but opposite concepts like up and down. A basic pattern was identified in his beta-rhythm EEG output and used to control a switch: Above average activity was interpreted as on, below average off. The signals were also used to drive nerve controllers embedded in his hands, restoring some movement.<ref>{{Cite magazine |last=Hockenberry |first=John |date=August 2001 |title=The Next Brainiacs |url=https://www.wired.com/wired/archive/9.08/assist_pr.html |magazine=Wired |volume=9 |issue=8}}</ref>\n\n==== SSVEP mobile EEG BCIs ====\nIn 2009, the NCTU Brain-Computer-Interface-headband was reported. Those researchers also engineered silicon-based [[Microelectromechanical systems|microelectro-mechanical system]] (MEMS) [[Electroencephalography#Dry EEG electrodes|dry electrodes]] designed for application to non-hairy body sites. These electrodes were secured to the headband's [[Data acquisition|DAQ]] board with snap-on electrode holders. The signal processing module measured [[Alpha wave|alpha]] activity and transferred it over [[Bluetooth]] to a phone that assessed the patients' alertness and cognitive capacity. When the subject became drowsy, the phone sent arousing feedback to the operator to rouse them.<ref>{{Citation| vauthors = Lin CT, Ko LW, Chang CJ, Wang YT, Chung CH, Yang FS, Duann JR, Jung TP, Chiou JC | display-authors = 6 |title=Wearable and Wireless Brain-Computer Interface and Its Applications |date=2009 |work=Foundations of Augmented Cognition. Neuroergonomics and Operational Neuroscience| series = Lecture Notes in Computer Science | volume = 5638 |pages=741\u2013748|publisher=Springer Berlin Heidelberg|doi=10.1007/978-3-642-02812-0_84|isbn=978-3-642-02811-3|s2cid=14515754}}</ref>\n\nIn 2011, researchers reported a cellular based BCI that could cause phone to ring. The wearable system was composed of a four channel bio-signal acquisition/amplification [[Modular design|module]], a communication module, and a Bluetooth phone. The electrodes were placed to pick up steady state visual evoked potentials ([[Steady state visually evoked potential|SSVEPs]]).<ref name=\":1\">{{cite journal | vauthors = Wang YT, Wang Y, Jung TP | title = A cell-phone-based brain-computer interface for communication in daily life | journal = Journal of Neural Engineering | volume = 8 | issue = 2 | pages = 025018 | date = April 2011 | pmid = 21436517 | doi = 10.1088/1741-2560/8/2/025018 | s2cid = 10943518 | bibcode = 2011JNEng...8b5018W }}</ref> SSVEPs are electrical responses to flickering visual stimuli with repetition rates over 6&nbsp;Hz<ref name=\":1\" /> that are best found in the parietal and occipital scalp regions of the visual cortex.<ref>{{cite journal | vauthors = Guger C, Allison BZ, Gro\u00dfwindhager B, Pr\u00fcckl R, Hinterm\u00fcller C, Kapeller C, Bruckner M, Krausz G, Edlinger G | display-authors = 6 | title = How Many People Could Use an SSVEP BCI? | journal = Frontiers in Neuroscience | volume = 6 | pages = 169 | date = 2012 | pmid = 23181009 | pmc = 3500831 | doi = 10.3389/fnins.2012.00169 | doi-access = free }}</ref><ref name=\":2\">{{cite book | vauthors = Lin YP, Wang Y, Jung TP | title = 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) | chapter = A mobile SSVEP-based brain-computer interface for freely moving humans: The robustness of canonical correlation analysis to motion artifacts | volume = 2013 | pages = 1350\u20131353 | year = 2013 | pmid = 24109946 | doi = 10.1109/EMBC.2013.6609759 | isbn = 978-1-4577-0216-7 | s2cid = 23136360 }}</ref><ref>{{cite journal | vauthors = Rashid M, Sulaiman N, Abdul Majeed AP, Musa RM, Ab Nasir AF, Bari BS, Khatun S | title = Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review | journal = Frontiers in Neurorobotics | volume = 14 | pages = 25 | date = 2020 | pmid = 32581758 | pmc = 7283463 | doi = 10.3389/fnbot.2020.00025 | doi-access = free }}</ref> It was reported that all study participants were able to initiate the phone call with minimal practice in natural environments.<ref>{{cite patent | country = US | number = 20130127708 | gdate = 23 May 2013 }}</ref>\n\nThe scientists reported that a single channel [[fast Fourier transform]] (FFT) and multiple channel system [[canonical correlation analysis]] ([[Canonical correlation|CCA]]) algorithm can support mobile BCIs.<ref name=\":1\" /><ref name=\":3\">{{cite book | vauthors = Wang YT, Wang Y, Cheng CK, Jung TP | title = 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) | chapter = Developing stimulus presentation on mobile devices for a truly portable SSVEP-based BCI | volume = 2013 | pages = 5271\u20135274 | year = 2013 | pmid = 24110925 | doi = 10.1109/EMBC.2013.6610738 | isbn = 978-1-4577-0216-7 | s2cid = 14324159 }}</ref> The CCA algorithm has been applied in experiments investigating BCIs with claimed high accuracy and speed.<ref>{{cite journal | vauthors = Bin G, Gao X, Yan Z, Hong B, Gao S | title = An online multi-channel SSVEP-based brain-computer interface using a canonical correlation analysis method | journal = Journal of Neural Engineering | volume = 6 | issue = 4 | pages = 046002 | date = August 2009 | pmid = 19494422 | doi = 10.1088/1741-2560/6/4/046002 | bibcode = 2009JNEng...6d6002B | s2cid = 32640699 }}</ref> Cellular BCI technology can reportedly be translated for other applications, such as picking up sensorimotor [[Mu wave|mu]]/[[Beta wave|beta]] rhythms to function as a motor-imagery based BCI.<ref name=\":1\" />\n\nIn 2013, comparative tests performed on [[Android (operating system)|Android]] cell phone, tablet, and computer based BCIs, analyzed the power [[Spectral density|spectrum density]] of resultant EEG SSVEPs. The stated goals of this study were to \"increase the practicability, portability, and ubiquity of an SSVEP-based BCI, for daily use\". It was reported that the stimulation frequency on all mediums was accurate, although the phone's signal was not stable. The amplitudes of the SSVEPs for the laptop and tablet were reported to be larger than those of the cell phone. These two qualitative characterizations were suggested as indicators of the feasibility of using a mobile stimulus BCI.<ref name=\":3\" />\n\nOne of the difficulties with EEG readings is susceptibility to motion artifacts.<ref>{{cite journal | vauthors = Symeonidou ER, Nordin AD, Hairston WD, Ferris DP | title = Effects of Cable Sway, Electrode Surface Area, and Electrode Mass on Electroencephalography Signal Quality during Motion | journal = Sensors | volume = 18 | issue = 4 | pages = 1073 | date = April 2018 | pmid = 29614020 | pmc = 5948545 | doi = 10.3390/s18041073 | doi-access = free | bibcode = 2018Senso..18.1073S }}</ref> In most research projects, the participants were asked to sit still in a laboratory setting, reducing head and eye movements as much as possible. However, since these initiatives were intended to create a mobile device for daily use,<ref name=\":3\" /> the technology had to be tested in motion. In 2013, researchers tested mobile EEG-based BCI technology, measuring SSVEPs from participants as they walked on a treadmill. Reported results were that as speed increased, SSVEP detectability using CCA decreased. [[Independent component analysis]] (ICA) had been shown to be efficient in separating EEG signals from noise.<ref>{{cite journal | vauthors = Wang Y, Wang R, Gao X, Hong B, Gao S | title = A practical VEP-based brain-computer interface | journal = IEEE Transactions on Neural Systems and Rehabilitation Engineering | volume = 14 | issue = 2 | pages = 234\u2013239 | date = June 2006 | pmid = 16792302 | doi = 10.1109/TNSRE.2006.875576 }}</ref> The researchers stated that CCA data with and without ICA processing were similar. They concluded that CCA demonstrated robustness to motion artifacts.<ref name=\":2\" /> EEG-based BCI applications offer low spatial resolution. Possible solutions include: EEG source connectivity based on [[graph theory]], EEG pattern recognition based on Topomap and EEG-[[fMRI]] fusion.\n\n====Prosthesis and environment control====\nNon-invasive BCIs have been applied to prosthetic upper and lower extremity devices in people with paralysis. For example, Gert Pfurtscheller of [[Graz University of Technology]] and colleagues demonstrated a BCI-controlled [[functional electrical stimulation]] system to restore upper extremity movements in a person with tetraplegia due to [[spinal cord injury]].<ref>{{cite journal | vauthors = Pfurtscheller G, M\u00fcller GR, Pfurtscheller J, Gerner HJ, Rupp R | title = 'Thought'--control of functional electrical stimulation to restore hand grasp in a patient with tetraplegia | journal = Neuroscience Letters | volume = 351 | issue = 1 | pages = 33\u201336 | date = November 2003 | pmid = 14550907 | doi = 10.1016/S0304-3940(03)00947-9 | s2cid = 38568963 }}</ref> Between 2012 and 2013, researchers at [[University of California, Irvine]] demonstrated for the first time that BCI technology can restore brain-controlled walking after [[spinal cord injury]]. In their [[Spinal cord injury research|study]], a person with [[paraplegia]] operated a BCI-robotic gait [[orthosis]] to regain basic ambulation.<ref name=\"DoWang2013\">{{cite journal | vauthors = Do AH, Wang PT, King CE, Chun SN, Nenadic Z | title = Brain-computer interface controlled robotic gait orthosis | journal = Journal of Neuroengineering and Rehabilitation | volume = 10 | issue = 1 | pages = 111 | date = December 2013 | pmid = 24321081 | pmc = 3907014 | doi = 10.1186/1743-0003-10-111 | doi-access = free }}</ref><ref>[https://www.youtube.com/watch?v=HXNCwonhjG8 Subject with Paraplegia Operates BCI-controlled RoGO (4x)] at YouTube.com</ref> In 2009 independent researcher Alex Blainey used the [[Emotiv]] EPOC to control a 5 axis robot arm.<ref>[https://www.youtube.com/watch?v=4Cq35VbRpTY Alex Blainey controls a cheap consumer robot arm using the EPOC headset via a serial relay port] at YouTube.com</ref> He made several demonstrations of mind controlled wheelchairs and [[home automation]].\n\n==== Magnetoencephalography and fMRI ====\n{{Main|Magnetoencephalography|Functional magnetic resonance imaging}}\n\n[[File:Visual stimulus reconstruction using fMRI.png|thumb|ATR Labs' reconstruction of human vision using [[functional magnetic resonance imaging|fMRI]] (top row: original image; bottom row: reconstruction from mean of combined readings)]][[Magnetoencephalography]] (MEG) and [[functional magnetic resonance imaging]] (fMRI) have both been used as non-invasive BCIs.<ref>Ranganatha Sitaram, Andrea Caria, Ralf Veit, Tilman Gaber, Giuseppina Rota, Andrea Kuebler and Niels Birbaumer(2007) \"[https://archive.today/20120731202844/http://mts.hindawi.com/utils/GetFile.aspx?msid=25487&vnum=2&ftype=manuscript FMRI Brain\u2013Computer Interface: A Tool for Neuroscientific Research and Treatment]\"</ref> In a widely reported experiment, fMRI allowed two users to play [[Pong]] in real-time by altering their [[haemodynamic response]] or brain blood flow through [[biofeedback]].<ref>{{cite journal|doi=10.1038/news040823-18|title=Mental ping-pong could aid paraplegics|journal=News@nature|date=27 August 2004 | last = Peplow |first=Mark }}</ref>\n\nfMRI measurements of haemodynamic responses in real time have also been used to control robot arms with a seven-second delay between thought and movement.<ref>{{cite web | url = http://techon.nikkeibp.co.jp/english/NEWS_EN/20060525/117493/ | title = To operate robot only with brain, ATR and Honda develop BMI base technology | work = Tech-on | date = 26 May 2006 | access-date = 22 September 2006 | archive-date = 23 June 2017 | archive-url = https://web.archive.org/web/20170623060519/http://techon.nikkeibp.co.jp/english/NEWS_EN/20060525/117493/ | url-status = dead }}</ref>\n\nIn 2008 research developed in the Advanced Telecommunications Research (ATR) [[Computational Neuroscience]] Laboratories in [[Kyoto]], Japan, allowed researchers to reconstruct images from brain signals at a [[Display resolution|resolution]] of 10x10 [[pixels]].<ref>{{cite journal | vauthors = Miyawaki Y, Uchida H, Yamashita O, Sato MA, Morito Y, Tanabe HC, Sadato N, Kamitani Y | display-authors = 6 | title = Visual image reconstruction from human brain activity using a combination of multiscale local image decoders | journal = Neuron | volume = 60 | issue = 5 | pages = 915\u2013929 | date = December 2008 | pmid = 19081384 | doi = 10.1016/j.neuron.2008.11.004 | s2cid = 17327816 | doi-access = free }}</ref>\n\nA 2011 study reported second-by-second reconstruction of videos watched by the study's subjects, from fMRI data.<ref>{{cite journal |vauthors=Nishimoto S, Vu AT, Naselaris T, Benjamini Y, Yu B, Gallant JL |date=October 2011 |title=Reconstructing visual experiences from brain activity evoked by natural movies |journal=Current Biology |volume=21 |issue=19 |pages=1641\u20131646 |doi=10.1016/j.cub.2011.08.031 |pmc=3326357 |pmid=21945275}}</ref> This was achieved by creating a statistical model relating videos to brain activity. This model was then used to look up 100 one-second video segments, in a database of 18 million seconds of random [[YouTube]] videos, matching visual patterns to brain activity recorded when subjects watched a video. These 100 one-second video extracts were then combined into a mash-up image that resembled the video.<ref>{{cite magazine | url = http://blogs.scientificamerican.com/observations/2011/09/22/breakthrough-could-enable-others-to-watch-your-dreams-and-memories-video/ | title= Breakthrough Could Enable Others to Watch Your Dreams and Memories | last = Yam |first=Philip | date = 22 September 2011 | magazine = Scientific American | access-date = 25 September 2011}}</ref><ref>{{cite web | url = https://sites.google.com/site/gallantlabucb/publications/nishimoto-et-al-2011 | title = Reconstructing visual experiences from brain activity evoked by natural movies (Project page) | publisher = The Gallant Lab at [[UC Berkeley]] | access-date = 25 September 2011 |url-status=dead |archiveurl=https://web.archive.org/web/20110925024037/https://sites.google.com/site/gallantlabucb/publications/nishimoto-et-al-2011 |archivedate=2011-09-25}}</ref><ref>{{cite web | url= http://newscenter.berkeley.edu/2011/09/22/brain-movies/| title= Scientists use brain imaging to reveal the movies in our mind |last=Anwar |first=Yasmin | date= 22 September 2011 | publisher = [[UC Berkeley]] News Center| access-date = 25 September 2011}}</ref>\n\n====BCI control strategies in neurogaming====\n\n=====Motor imagery=====\n\n[[Motor imagery]] involves imagining the movement of body parts, activating the [[sensorimotor cortex]], which modulates sensorimotor oscillations in the EEG. This can be detected by the BCI and used to infer user intent. Motor imagery typically requires training to acquire acceptable control. Training sessions typically consume hours over several days. Regardless of the duration of the training session, users are unable to master the control scheme. This results in very slow pace of the gameplay.<ref name=\"ieeexplore.ieee.org\">{{cite journal| vauthors = Marshall D, Coyle D, Wilson S, Callaghan M |title=Games, Gameplay, and BCI: The State of the Art|journal=IEEE Transactions on Computational Intelligence and AI in Games|volume=5|issue=2|page = 83|doi=10.1109/TCIAIG.2013.2263555 |year=2013|s2cid=206636315}}</ref> Machine learning methods were used to compute a subject-specific model for detecting motor imagery performance. The top performing algorithm from BCI Competition IV in 2022<ref>{{cite web|url=http://www.bbci.de/competition/iv/|title=Goals of the organizers|publisher=BBC|access-date=19 December 2022}}</ref> dataset 2 for motor imagery was the Filter Bank Common Spatial Pattern, developed by Ang et al. from [[A*STAR]], [[Singapore]].<ref>{{cite journal | vauthors = Ang KK, Chin ZY, Wang C, Guan C, Zhang H | title = Filter Bank Common Spatial Pattern Algorithm on BCI Competition IV Datasets 2a and 2b | journal = Frontiers in Neuroscience | volume = 6 | page = 39 | date = 1 January 2012 | pmid = 22479236 | pmc = 3314883 | doi = 10.3389/fnins.2012.00039 | doi-access = free }}</ref>\n\n=====Bio/neurofeedback for passive BCI designs=====\nBiofeedback can be used to monitor a subject's mental relaxation. In some cases, biofeedback does not match EEG, while parameters such as [[electromyography]] (EMG), [[galvanic skin response|galvanic skin resistance]] (GSR), and [[heart rate variability]] (HRV) can do so. Many biofeedback systems treat disorders such as [[Attention deficit hyperactivity disorder|attention deficit hyperactivity disorder (ADHD)]], sleep problems in children, teeth grinding, and chronic pain. EEG biofeedback systems typically monitor four brainwave bands (theta: 4\u20137&nbsp;Hz, alpha:8\u201312&nbsp;Hz, SMR: 12\u201315&nbsp;Hz, beta: 15\u201318&nbsp;Hz) and challenge the subject to control them. Passive BCI uses BCI to enrich human\u2013machine interaction with information on the user's mental state, for example, simulations that detect when users intend to push brakes during emergency vehicle braking.<ref name=\":0\" /> Game developers using passive BCIs understand that through repetition of game levels the user's cognitive state adapts. During the first play of a given level, the player reacts differently than during subsequent plays: for example, the user is less surprised by an event that they expect.<ref name=\"ieeexplore.ieee.org\"/>\n\n=====Visual evoked potential (VEP)=====\n\nA VEP is an electrical potential recorded after a subject is presented with a visual stimuli. The types of VEPs include SSVEPs and P300 potential.\n\n[[Steady state visually evoked potential|Steady-state visually evoked potential]]s (SSVEPs) use potentials generated by exciting the [[retina]], using visual stimuli modulated at certain frequencies. SSVEP stimuli are often formed from alternating checkerboard patterns and at times use flashing images. The frequency of the phase reversal of the stimulus used can be distinguished by EEG; this makes detection of SSVEP stimuli relatively easy. SSVEP is used within many BCI systems. This is due to several factors. The signal elicited is measurable in as large a population as the transient VEP and blink movement. Electrocardiographic artefacts do not affect the frequencies monitored. The SSVEP signal is robust; the topographic organization of the primary visual cortex is such that a broader area obtains afferents from the visual field's central or fovial region. SSVEP comes with problems. As SSVEPs use flashing stimuli to infer user intent, the user must gaze at one of the flashing or iterating symbols in order to interact with the system. It is, therefore, likely that the symbols become irritating and uncomfortable during longer play sessions.\n\nAnother type of VEP is the [[P300 (neuroscience)|P300 potential]]. This potential is a positive peak in the EEG that occurs roughly 300 ms after the appearance of a target stimulus (a stimulus for which the user is waiting or seeking) or [[Oddball paradigm|oddball stimuli]]. P300 amplitude decreases as the target stimuli and the ignored stimuli grow more similar. P300 is thought to be related to a higher level attention process or an orienting response. Using P300 requires fewer training sessions. The first application to use it was the P300 matrix. Within this system, a subject chooses a letter from a 6 by 6 grid of letters and numbers. The rows and columns of the grid flashed sequentially and every time the selected \"choice letter\" was illuminated the user's P300 was (potentially) elicited. However, the communication process, at approximately 17 characters per minute, was slow. P300 offers a discrete selection rather than continuous control. The advantage of P300 within games is that the player does not have to learn how to use a new control system, requiring only short training instances to learn gameplay mechanics and the basic BCI paradigm.<ref name=\"ieeexplore.ieee.org\"/>\n\n==== Non-brain-based human\u2013computer interface (physiological computing) ====\nHuman-computer interaction can exploit other recording modalities, such as [[electrooculography]] and eye-tracking. These modalities do not record brain activity and therefore do not qualify as BCIs.<ref>{{Cite journal |last=Fairclough |first=Stephen H. |date=January 2009 |title=Fundamentals of physiological computing |url=https://academic.oup.com/iwc/article-lookup/doi/10.1016/j.intcom.2008.10.011 |journal=Interacting with Computers |language=en |volume=21 |issue=1\u20132 |pages=133\u2013145 |doi=10.1016/j.intcom.2008.10.011|s2cid=16314534 }}</ref>\n\n=====Electrooculography (EOG)=====\nIn 1989, a study reported control of a mobile robot by eye movement using electrooculography signals. A mobile robot was driven to a goal point using five EOG commands, interpreted as forward, backward, left, right, and stop.<ref>{{cite book |title=Advances in Robot Design and Intelligent Control |vauthors=Bozinovski S |year=2017 |isbn=978-3-319-49057-1 |series=Advances in Intelligent Systems and Computing |volume=540 |pages=449\u2013462 |chapter=Signal Processing Robotics Using Signals Generated by a Human Head: From Pioneering Works to EEG-Based Emulation of Digital Circuits |doi=10.1007/978-3-319-49058-8_49}}</ref>\n\n=====Pupil-size oscillation=====\nA 2016 article described a new non-EEG-based HCI that required no [[visual fixation]], or ability to move the eyes.<ref>{{cite journal |vauthors=Math\u00f4t S, Melmi JB, van der Linden L, Van der Stigchel S |year=2016 |title=The Mind-Writing Pupil: A Human-Computer Interface Based on Decoding of Covert Attention through Pupillometry |journal=PLOS ONE |volume=11 |issue=2 |pages=e0148805 |bibcode=2016PLoSO..1148805M |doi=10.1371/journal.pone.0148805 |pmc=4743834 |pmid=26848745 |doi-access=free}}</ref> The interface is based on covert [[interest (emotion)|interest]]; directing attention to a chosen letter on a virtual keyboard, without the need to look directly at the letter. Each letter has its own (background) circle which micro-oscillates in brightness differently from the others. Letter selection is based on best fit between unintentional pupil-size oscillation and the background circle's brightness oscillation pattern. Accuracy is additionally improved by the user's mental rehearsal of the words 'bright' and 'dark' in synchrony with the brightness transitions of the letter's circle.\n\n===Brain-to-brain communication===\nIn the 1960s a researcher after training used EEG to create [[Morse code]] using alpha waves.<ref name=\"Telepathy\">{{cite news |last=Bland |first=Eric |date=13 October 2008 |title=Army Developing 'synthetic telepathy' |url=http://www.nbcnews.com/id/27162401/ |access-date=13 October 2008 |newspaper=Discovery News}}</ref> On 27 February 2013 [[Miguel Nicolelis]]'s group at [[Duke University]] and IINN-ELS connected the brains of two rats, allowing them to share information, in [[Miguel Nicolelis#Brain to brain|the first-ever direct brain-to-brain interface]].<ref name=\"srep01319\">{{cite journal |vauthors=Pais-Vieira M, Lebedev M, Kunicki C, Wang J, Nicolelis MA |date=28 February 2013 |title=A brain-to-brain interface for real-time sharing of sensorimotor information |journal=Scientific Reports |volume=3 |pages=1319 |bibcode=2013NatSR...3E1319P |doi=10.1038/srep01319 |pmc=3584574 |pmid=23448946}}</ref><ref>{{cite news |last=Gorman |first=James |date=28 February 2013 |title=One Rat Thinks, and Another Reacts |url=https://www.nytimes.com/2013/03/01/science/new-research-suggests-two-rat-brains-can-be-linked.html |access-date=28 February 2013 |work=The New York Times}}</ref><ref>{{cite web |last=Sample |first=Ian |date=1 March 2013 |title=Brain-to-brain interface lets rats share information via internet |url=https://www.theguardian.com/science/2013/feb/28/brains-rats-connected-share-information |access-date=2 March 2013 |website=The Guardian}}</ref>\n\n[[Gerwin Schalk]] reported that ECoG signals can discriminate vowels and consonants embedded in spoken and imagined words, shedding light on the mechanisms associated with their production and could provide a basis for brain-based communication using imagined speech.<ref name=\"TelepathicCommVowel\" /><ref name=\"TelepathicComm\">{{cite news |last=Kennedy |first=Pagan |title=The Cyborg in Us All |url=https://www.nytimes.com/2011/09/18/magazine/the-cyborg-in-us-all.html |work=[[The New York Times]] |date=18 September 2011 |access-date=28 January 2012 }}</ref>\n\nIn 2002 [[Kevin Warwick]] had an array of 100 electrodes fired into his nervous system in order to link his nervous system to the Internet. Warwick carried out a series of experiments. Electrodes were implanted into his wife's nervous system, allowing them to conduct the first direct electronic communication experiment between the nervous systems of two humans.<ref>{{cite web |first1=Jocelyn |last1=Selim |first2=Pete |last2=Drinkell |date=1 November 2002 |url=http://discovermagazine.com/2002/nov/featbionic/ |title=The Bionic Connection |work=[[Discover (magazine)|Discover]] |archive-url=https://web.archive.org/web/20080106135544/http://discovermagazine.com:80/2002/nov/featbionic |archive-date=6 January 2008}}</ref><ref>{{cite web|url=http://www.atlasobscura.com/articles/nervous-system-hookup-leads-to-telepathic-hand-holding|title=Nervous System Hookup Leads to Telepathic Hand-Holding|date=10 June 2015 |work=Atlas Obscura |first=Cara |last=Giaimo}}</ref><ref>Warwick, K, Gasson, M, Hutt, B, Goodhew, I, Kyberd, P, Schulzrinne, H and Wu, X: \"Thought Communication and Control: A First Step using Radiotelegraphy\", [[Institution of Electrical Engineers|IEE]] Proceedings on Communications, 151(3), pp.185\u2013189, 2004</ref><ref name=\"doi10.1001/archneur.60.10.1369|noedit\">{{cite journal | vauthors = Warwick K, Gasson M, Hutt B, Goodhew I, Kyberd P, Andrews B, Teddy P, Shad A | display-authors = 6 | title = The application of implant technology for cybernetic systems | journal = Archives of Neurology | volume = 60 | issue = 10 | pages = 1369\u20131373 | date = October 2003 | pmid = 14568806 | doi = 10.1001/archneur.60.10.1369 | doi-access = free }}</ref>\n\nOther researchers achieved brain-to-brain communication between at a distance using non-invasive technology attached to the participants' scalps. The words were encoded in binary streams by the cognitive motor input of the person sending the information. Pseudo-random bits of the information carried encoded words \"hola\" (\"hi\" in Spanish) and \"ciao\" (\"goodbye\" in Italian) and were transmitted mind-to-mind.<ref name=\"consciousbraintobrain\">{{cite journal\n\t| vauthors = Grau C, Ginhoux R, Riera A, Nguyen TL, Chauvat H, Berg M, et al\n\t| date = 2014\n\t| title = Conscious brain-to-brain communication in humans using non-invasive technologies\n\t| journal = PLOS ONE\n\t| volume = 9\n\t| issue = 8\n\t| pages = e105225\n\t| doi = 10.1371/journal.pone.0105225\n| pmid = 25137064\n\t| pmc = 4138179\n\t| bibcode = 2014PLoSO...9j5225G\n\t| doi-access = free\n\t}}</ref>\n\n==Cell-culture BCIs==\n{{Main|Cultured neuronal network}}<noinclude>[[File:CaltechNeuroChip.jpg|thumb|The world's first [[neurochip]], developed by [[Caltech]] researchers Jerome Pine and Michael Maher]]</noinclude>\n\nResearchers have built devices to interface with neural cells and entire neural networks ''[[in vitro]]''. Experiments on cultured neural tissue focused on building problem-solving networks, constructing basic computers and manipulating robotic devices. Research into techniques for stimulating and recording individual neurons grown on semiconductor chips is neuroelectronics or [[neurochip]]s.<ref>{{cite journal | vauthors = Mazzatenta A, Giugliano M, Campidelli S, Gambazzi L, Businaro L, Markram H, Prato M, Ballerini L | display-authors = 6 | title = Interfacing neurons with carbon nanotubes: electrical signal transfer and synaptic stimulation in cultured brain circuits | journal = The Journal of Neuroscience | volume = 27 | issue = 26 | pages = 6931\u20136936 | date = June 2007 | pmid = 17596441 | pmc = 6672220 | doi = 10.1523/JNEUROSCI.1051-07.2007 }}</ref>\n\nDevelopment of the first neurochip was claimed by a Caltech team led by Jerome Pine and Michael Maher in 1997.<ref>[http://www.caltech.edu/news/caltech-scientists-devise-first-neurochip-213 Caltech Scientists Devise First Neurochip], Caltech, 26 October 1997</ref> The Caltech chip had room for 16 neurons.\n\nIn 2003 a team led by Theodore Berger, at the [[University of Southern California]], worked on a neurochip designed to function as an artificial or prosthetic [[hippocampus]]. The neurochip was designed for rat brains. The hippocampus was chosen because it is thought to be the most structured and most studied part of the brain. Its function is to encode experiences for storage as long-term memories elsewhere in the brain.<ref>{{Cite web |url=https://www.wired.com/news/technology/medtech/0,65422-0.html |title=Coming to a brain near you |archiveurl=https://web.archive.org/web/20060910201747/http://www.wired.com/news/technology/medtech/0%2C65422-0.html |archivedate=10 September 2006 |url-status=dead |work=Wired News |date=22 October 2004 |first=Lakshmi |last=Sandhana}}</ref>\n\nIn 2004 Thomas DeMarse at the [[University of Florida]] used a culture of 25,000 neurons taken from a rat's brain to fly a [[F-22]] fighter jet [[aircraft simulator]]. After collection, the cortical neurons were cultured in a [[petri dish]] and reconnected themselves to form a living neural network. The cells were arranged over a grid of 60 electrodes and used to control the [[Aircraft principal axes|pitch]] and [[Aircraft principal axes|yaw]] functions of the simulator. The study's focus was on understanding how the human brain performs and learns computational tasks at a cellular level.<ref>{{Cite news |url=http://www.cnn.com/2004/TECH/11/02/brain.dish/ |title='Brain' in a dish flies flight simulator |work=CNN |date=4 November 2004}}</ref>\n\n==Collaborative BCIs==\nThe idea of combining/integrating brain signals from multiple individuals was introduced at Humanity+ @Caltech, in December 2010, by Adrian Stoica, who referred to the concept as multi-brain aggregation.<ref>{{Cite web|date=2017-10-05|title=David Pearce \u2013 Humanity Plus|url=https://activistjourneys.wordpress.com/david-pearce-humanity-plus/|access-date=2021-12-30|language=en}}</ref><ref>{{Cite web|vauthors=Stoica A|date=2010|title=Speculations on Robots, Cyborgs & Telepresence|website=[[YouTube]]|url=https://www.youtube.com/watch?v=nqByb7VEnZk|url-status=live|archive-url=https://web.archive.org/web/20211228222826/https://www.youtube.com/watch?v=nqByb7VEnZk|archive-date=28 December 2021|access-date=28 December 2021}}</ref><ref>{{Cite web|title=Experts to 'redefine the future' at Humanity+ @ CalTech |website=Kurzweil|url=https://www.kurzweilai.net/experts-to-redefine-the-future-at-humanity-caltech|access-date=2021-12-30|language=en-US}}</ref> A patent was applied for in 2012.<ref>{{Cite patent|number=WO2012100081A2|title=Aggregation of bio-signals from multiple individuals to achieve a collective outcome|gdate=2012-07-26|invent1=Stoica|inventor1-first=Adrian|url=https://patents.google.com/patent/WO2012100081A2/en}}</ref><ref>{{cite journal | vauthors = Wang Y, Jung TP | title = A collaborative brain-computer interface for improving human performance | journal = PLOS ONE | volume = 6 | issue = 5 | pages = e20422 | date = 2011-05-31 | pmid = 21655253 | pmc = 3105048 | doi = 10.1371/journal.pone.0020422 | bibcode = 2011PLoSO...620422W | doi-access = free }}</ref><ref>{{cite journal | vauthors = Eckstein MP, Das K, Pham BT, Peterson MF, Abbey CK, Sy JL, Giesbrecht B | title = Neural decoding of collective wisdom with multi-brain computing | journal = NeuroImage | volume = 59 | issue = 1 | pages = 94\u2013108 | date = January 2012 | pmid = 21782959 | doi = 10.1016/j.neuroimage.2011.07.009 | s2cid = 14930969 }}</ref> Stoica's first paper on the topic appeared in 2012, after the publication of his patent application.<ref>{{Cite book| vauthors = Stoica A |title= 2012 Third International Conference on Emerging Security Technologies |chapter= MultiMind: Multi-Brain Signal Fusion to Exceed the Power of a Single Brain |date= September 2012 |chapter-url= https://ieeexplore.ieee.org/document/6328091 |pages=94\u201398 |doi=10.1109/EST.2012.47|isbn= 978-0-7695-4791-6 |s2cid= 6783719 }}</ref> \n\n== Ethical considerations==\nBCIs present significant ethical questions, including concerns about privacy, autonomy, consent, and the consequences of merging human cognition with external devices. Exploring these ethical considerations highlights the complex interplay between advancing technology and preserving fundamental human rights and values. The concerns can be broadly categorized into user-centric issues and legal and social issues.\n\nConcerns center on the safety and long-term effects on users. These include obtaining [[informed consent]] from individuals with communication difficulties, the impact on patients' and families' quality of life, health-related side effects, misuse of therapeutic applications, safety risks, and the non-reversible nature of some BCI-induced changes. Additionally, questions arise about access to maintenance, repair, and spare parts, particularly in the event of a company's bankruptcy<ref>{{Cite web |title=Paralyzed Again |url=https://www.technologyreview.com/2015/04/09/168424/paralyzed-again/ |access-date=2023-12-08 |website=MIT Technology Review |language=en}}</ref>\n\nThe legal and social aspects of BCIs complicate mainstream adoption. Concerns include issues of accountability and responsibility, such as claims that BCI influence overrides free will and control over actions, inaccurate translation of cognitive intentions, personality changes resulting from deep-brain stimulation, and the blurring of the line between human and machine.<ref>{{Cite web |title=Gale - Product Login |url=https://galeapps.gale.com/apps/auth?userGroupName=nysl_ca_arg&sid=googleScholar&da=true&origURL=https%3A%2F%2Fgo.gale.com%2Fps%2Fi.do%3Fid%3DGALE%257CA594456959%26sid%3DgoogleScholar%26v%3D2.1%26it%3Dr%26linkaccess%3Dabs%26issn%3D00280836%26p%3DAONE%26sw%3Dw%26userGroupName%3Dnysl_ca_arg%26aty%3Dip&prodId=AONE |access-date=2023-12-08 |website=galeapps.gale.com}}</ref> Other concerns involve the use of BCIs in advanced interrogation techniques, unauthorized access (\"brain hacking\"),<ref>{{Cite journal |last1=Ienca |first1=Marcello |last2=Haselager |first2=Pim |date=June 2016 |title=Hacking the brain: brain-computer interfacing technology and the ethics of neurosecurity |url=https://dx.doi.org/10.1007/s10676-016-9398-9 |journal=Ethics & Information Technology |volume=18 |issue=2 |pages=117\u2013129 |doi=10.1007/s10676-016-9398-9 |s2cid=5132634}}</ref> social stratification through selective enhancement, privacy issues related to mind-reading, tracking and \"tagging\" systems, and the potential for mind, movement, and emotion control.<ref>{{Cite journal |last1=Steinert |first1=Steffen |last2=Friedrich |first2=Orsolya |date=2020-02-01 |title=Wired Emotions: Ethical Issues of Affective Brain\u2013Computer Interfaces |url=https://doi.org/10.1007/s11948-019-00087-2 |journal=Science and Engineering Ethics |language=en |volume=26 |issue=1 |pages=351\u2013367 |doi=10.1007/s11948-019-00087-2 |issn=1471-5546 |pmc=6978299 |pmid=30868377}}</ref> Researchers have also theorized that BCIs could exacerbate existing social inequalities.\n\nIn their current form, most BCIs are more akin to corrective therapies that engage few of such ethical issues. Bioethics is well-equipped to address the challenges posed by BCI technologies, with Clausen suggesting in 2009 that \"BCIs pose ethical challenges, but these are conceptually similar to those that bioethicists have addressed for other realms of therapy.\"<ref>{{Cite journal |last=Clausen |first=Jens |date=2009-02-01 |title=Man, machine and in between |url=https://ui.adsabs.harvard.edu/abs/2009Natur.457.1080C |journal=Nature |volume=457 |issue=7233 |pages=1080\u20131081 |bibcode=2009Natur.457.1080C |doi=10.1038/4571080a |issn=0028-0836 |pmid=19242454 |s2cid=205043226}}</ref> Haselager and colleagues highlighted the importance of managing expectations and value.<ref>{{Cite journal |last1=Haselager |first1=Pim |last2=Vlek |first2=Rutger |last3=Hill |first3=Jeremy |last4=Nijboer |first4=Femke |date=2009-11-01 |title=A note on ethical aspects of BCI |url=https://www.sciencedirect.com/science/article/pii/S0893608009001531 |journal=Neural Networks |series=Brain-Machine Interface |volume=22 |issue=9 |pages=1352\u20131357 |doi=10.1016/j.neunet.2009.06.046 |issn=0893-6080 |pmid=19616405 |hdl-access=free |hdl=2066/77533}}</ref> Standard protocols can ensure ethically sound informed-consent procedures for locked-in patients.\n\nThe evolution of BCIs mirrors that of pharmaceutical science, which began as a means to address impairments and now enhances focus and reduces the need for sleep. As BCIs progress from therapies to enhancements, the BCI community is working to create consensus on ethical guidelines for research, development, and dissemination.<ref>{{Cite journal |last1=Attiah |first1=Mark A. |last2=Farah |first2=Martha J. |date=2014-05-15 |title=Minds, motherboards, and money: futurism and realism in the neuroethics of BCI technologies |journal=Frontiers in Systems Neuroscience |volume=8 |pages=86 |doi=10.3389/fnsys.2014.00086 |issn=1662-5137 |pmc=4030132 |pmid=24860445 |doi-access=free}}</ref><ref>{{Cite journal |last1=Nijboer |first1=Femke |last2=Clausen |first2=Jens |last3=Allison |first3=Brendan Z. |last4=Haselager |first4=Pim |date=2013 |title=The Asilomar Survey: Stakeholders' Opinions on Ethical Issues Related to Brain-Computer Interfacing |journal=Neuroethics |volume=6 |issue=3 |pages=541\u2013578 |doi=10.1007/s12152-011-9132-6 |issn=1874-5490 |pmc=3825606 |pmid=24273623}}</ref> Ensuring equitable access to BCIs will be crucial in preventing generational inequalities that could hinder the right to human flourishing.\n\n==Low-cost systems==\n{{main|Consumer brain\u2013computer interfaces}}\nVarious companies are developing inexpensive BCIs for research and entertainment. Toys such as the NeuroSky and Mattel MindFlex have seen some commercial success.\n* In 2006, [[Sony]] patented a neural interface system allowing radio waves to affect signals in the neural cortex.<ref name=\"Sony patent neural interface\">{{cite news|url=http://www.wikipatents.com/US-Patent-6729337/method-and-system-for-generating-sensory-data-onto-the-human-neural |title=Sony patent neural interface |url-status=dead |archive-url=https://web.archive.org/web/20120407071853/http://www.wikipatents.com/US-Patent-6729337/method-and-system-for-generating-sensory-data-onto-the-human-neural |archive-date=7 April 2012 |df=dmy }}</ref>\n* In 2007, [[NeuroSky]] released the first affordable consumer based EEG along with the game NeuroBoy. It was the first large scale EEG device to use dry sensor technology.<ref>{{cite news|url= http://www.economist.com/science/displaystory.cfm?story_id=8847846 |title=Mind Games |date= 23 March 2007 |newspaper=The Economist}}</ref>\n* In 2008, [[OCZ Technology]] developed a device for use in video games relying primarily on [[electromyography]].<ref>{{cite web|url=http://www.ocztechnology.com/nia-game-controller.html |title=nia Game Controller Product Page |publisher=OCZ Technology Group |access-date=30 January 2013}}</ref>\n*In 2008, [[Final Fantasy]] developer [[Square Enix]] announced that it was partnering with NeuroSky to create Judecca, a game.<ref name=\"Mind reading is on the market\">{{cite news|url=https://www.latimes.com/business/la-fi-mind-reader-20100808,0,6235181,full.story|archive-url=https://archive.today/20130104065206/http://www.latimes.com/business/la-fi-mind-reader-20100808,0,6235181,full.story|url-status=dead|archive-date=4 January 2013|title= Mind reading is on the market |date=8 August 2010 |work=[[Los Angeles Times]] | vauthors = Li S }}</ref><ref>{{Cite web |url=https://www.engadget.com/2008/10/09/brains-on-with-neurosky-and-squareenixs-judecca-mind-control-ga |title=Brains-on with NeuroSky and Square Enix's Judecca mind-control game |website=Engadget |date=9 October 2008 |first=Joshua |last=Fruhlinger |accessdate=29 May 2012}}</ref>\n* In 2009, [[Mattel]] partnered with NeuroSky to release [[Mindflex]], a game that used an EEG to steer a ball through an obstacle course. It was by far the best selling consumer based EEG at the time.<ref name=\"Mind reading is on the market\"/><ref>[https://web.archive.org/web/20111108025937/http://www.physorg.com/news150781868.html New games powered by brain waves]. Physorg.com (10 January 2009). Retrieved on 12 September 2010.</ref>\n* In 2009, [[Uncle Milton Industries]] partnered with NeuroSky to release the [[Star Wars]] [[Force Trainer]], a game designed to create the illusion of possessing [[the Force]].<ref name=\"Mind reading is on the market\"/><ref>{{cite news| url=https://www.usatoday.com/life/lifestyle/2009-01-06-force-trainer-toy_N.htm | work=USA Today | title=Toy trains 'Star Wars' fans to use The Force |last=Snider |first=Mike | date=7 January 2009 |\naccess-date=1 May 2010}}</ref>\n* In 2009, [[Emotiv]] released the EPOC, a 14 channel EEG device that can read 4 mental states, 13 conscious states, facial expressions, and head movements. The EPOC was the first commercial BCI to use dry sensor technology, which can be dampened with a saline solution for a better connection.<ref name=\"emotive\">{{cite web|url=http://emotiv.com/|title=Emotiv Homepage|publisher=Emotiv.com|access-date=29 December 2009}}</ref>\n* In November 2011, ''[[Time (magazine)|Time]]'' magazine selected \"necomimi\" produced by [[Neurowear]] as one of the year's best inventions.<ref>{{cite web |url=http://neurowear.com/?p=153 |title='necomimi' selected 'Time Magazine / The 50 best invention of the year' |publisher=Neurowear |date=22 November 2011 |archive-url=https://web.archive.org/web/20120125122705/http://neurowear.com/?p=153 |archive-date=25 January 2012}}</ref>\n* In February 2014, They Shall Walk (a nonprofit organization fixed on constructing exoskeletons, dubbed LIFESUITs, for paraplegics and quadriplegics) began a partnership with James W. Shakarji on the development of a wireless BCI.<ref>{{cite web|url=http://www.theyshallwalk.org/category/lifesuit-updates-and-news/ |title=LIFESUIT Updates & News \u2013 They Shall Walk |publisher=Theyshallwalk.org |access-date=19 December 2016}}</ref>\n* In 2016, a group of hobbyists developed an open-source BCI board that sends neural signals to the audio jack of a smartphone, dropping the cost of entry-level BCI to \u00a320.<ref>{{cite web|url=https://github.com/icibici/smartphone-bci-hardware/ |title=SmartphoneBCI |website=[[GitHub]] |access-date=5 June 2018}}</ref> Basic diagnostic software is available for [[Android (operating system)|Android]] devices, as well as a text entry app for [[Unity (game engine)|Unity]].<ref>{{cite web|url=https://github.com/ryanlintott/SSVEP_keyboard/ |title=SSVEP_keyboard |website=[[GitHub]] |access-date=5 April 2017}}</ref>\n* In 2020, NextMind released a dev kit including an EEG headset with dry electrodes at $399.<ref>{{cite web|date=8 December 2020|title=NextMind ships its real-time brain computer interface Dev Kit for $399|url=https://venturebeat.com/2020/12/07/nextmind-real-time-brain-computer-interface-dev-kit/ |first=Emil |last=Protalinski |access-date=8 September 2021|website=VentureBeat|language=en-US}}</ref><ref>{{cite web|title=NextMind's Dev Kit for mind-controlled computing offers a rare 'wow' factor in tech|url=https://techcrunch.com/2020/12/21/nextminds-dev-kit-for-mind-controlled-computing-offers-a-rare-wow-factor-in-tech/|access-date=1 April 2024|website=TechCrunch|date=21 December 2020|first=Darrell|last=Etherington|language=en-US}}</ref> The device can run various visual-BCI demonstration applications or developers can create their own. It was later acquired by [[Snap Inc.]] in 2022<ref>{{Cite web |title=Welcome Nextmind! |url=https://ar.snap.com/welcome-nextmind |access-date=2024-05-31 |website=ar.snap.com |language=en}}</ref>. \n\n==Future directions==\n[[File:Brain-computer interface.jpeg|thumb|right|Brain-computer interface]]\nA consortium of 12 European partners completed a roadmap to support the European Commission in their funding decisions for the [[Horizon 2020]] framework program. The project was funded by the European Commission. It started in November 2013 and published a roadmap in April 2015.<ref>{{cite web|url=http://bnci-horizon-2020.eu/roadmap|title=Roadmap - BNCI Horizon 2020|website=bnci-horizon-2020.eu|access-date=2019-05-05}}</ref> A 2015 publication describes this project, as well as the Brain-Computer Interface Society.<ref name=\"bncihorizon2020\">{{cite journal|title=BNCI Horizon 2020: towards a roadmap for the BCI community|doi=10.1080/2326263X.2015.1008956 | volume=2 | journal=Brain-Computer Interfaces|pages=1\u201310|year=2015 | vauthors = Brunner C, Birbaumer N, Blankertz B, Guger C, K\u00fcbler A, Mattia D, Mill\u00e1n JD, Miralles F, Nijholt A, Opisso E, Ramsey N | display-authors = 6 |hdl=1874/350349 |s2cid=15822773 |url=http://infoscience.epfl.ch/record/205169 |hdl-access=free }}</ref> It reviewed work within this project that further defined BCIs and applications, explored recent trends, discussed ethical issues, and evaluated directions for new BCIs.\n\nOther recent publications too have explored future BCI directions for new groups of disabled users.<ref name=\"Wolpaw, J.R 2012\"/><ref>{{cite book | vauthors = Allison BZ, Dunne S, Leeb R, Millan J, Nijholt A| date = 2013 | title = Towards Practical Brain-Computer Interfaces: Bridging the Gap from Research to Real-World Applications. | publisher = Springer Verlag | location = Berlin Heidelberg |isbn=978-3-642-29746-5}}</ref>\n\n===Disorders of consciousness (DOC)===\nSome people have a [[disorder of consciousness]] (DOC). This state is defined to include people in a coma and those in a [[vegetative state]] (VS) or [[minimally conscious state]] (MCS). BCI research seeks to address DOC. A key initial goal is to identify patients who can perform basic cognitive tasks, which would change their diagnosis, and allow them to make important decisions (such as whether to seek therapy, where to live, and their views on end-of-life decisions regarding them). Patients incorrectly diagnosed may die as a result of end-of-life decisions made by others. The prospect of using BCI to communicate with such patients is a tantalizing prospect.<ref>{{cite book | vauthors = Edlinger G, Allison BZ, Guger C | chapter = How many people could use a BCI system? | pages = 33\u201366 | veditors = Kansaku K, Cohen L, Birbaumer N |title=Clinical Systems Neuroscience |date=2015 |location=Tokyo  | publisher = pringer Verlag Japan |isbn=978-4-431-55037-2}}</ref><ref>{{cite journal | vauthors = Chatelle C, Chennu S, Noirhomme Q, Cruse D, Owen AM, Laureys S | title = Brain-computer interfacing in disorders of consciousness | journal = Brain Injury | volume = 26 | issue = 12 | pages = 1510\u20131522 | year = 2012 | pmid = 22759199 | doi = 10.3109/02699052.2012.698362 | s2cid = 6498232 | hdl = 2268/162403 | hdl-access = free }}</ref>\n\nMany such patients cannot use BCIs based on vision. Hence, tools must rely on auditory and/or vibrotactile stimuli. Patients may wear headphones and/or vibrotactile stimulators placed on responsive body parts. Another challenge is that patients may be able to communicate only at unpredictable intervals. Home devices can allow communications when the patient is ready. \n\nAutomated tools can ask questions that patients can easily answer, such as \"Is your father named George?\" or \"Were you born in the USA?\" Automated instructions inform patients how to coney yes or no, for example by focusing their attention on stimuli on the right vs. left wrist. This focused attention produces reliable changes in [[electroencephalography|EEG patterns]] that can help determine whether the patient is able to communicate.<ref name=\"BolyMassimini2012\">{{cite journal | vauthors = Boly M, Massimini M, Garrido MI, Gosseries O, Noirhomme Q, Laureys S, Soddu A | title = Brain connectivity in disorders of consciousness | journal = Brain Connectivity | volume = 2 | issue = 1 | pages = 1\u201310 | year = 2012 | pmid = 22512333 | doi = 10.1089/brain.2011.0049 | hdl-access = free | s2cid = 6447538 | hdl = 2268/131984 }}</ref><ref>{{cite journal | vauthors = Gibson RM, Fern\u00e1ndez-Espejo D, Gonzalez-Lara LE, Kwan BY, Lee DH, Owen AM, Cruse D | title = Multiple tasks and neuroimaging modalities increase the likelihood of detecting covert awareness in patients with disorders of consciousness | journal = Frontiers in Human Neuroscience | volume = 8 | pages = 950 | year = 2014 | pmid = 25505400 | pmc = 4244609 | doi = 10.3389/fnhum.2014.00950 | doi-access = free }}</ref><ref>{{cite journal | vauthors = Risetti M, Formisano R, Toppi J, Quitadamo LR, Bianchi L, Astolfi L, Cincotti F, Mattia D | display-authors = 6 | title = On ERPs detection in disorders of consciousness rehabilitation | journal = Frontiers in Human Neuroscience | volume = 7 | pages = 775 | year = 2013 | pmid = 24312041 | pmc = 3834290 | doi = 10.3389/fnhum.2013.00775 | doi-access = free }}</ref>\n\n===Motor recovery===\nPeople may lose some of their ability to move due to many causes, such as stroke or injury. Research in recent years has demonstrated the utility of EEG-based BCI systems in aiding motor recovery and neurorehabilitation in patients who have had a stroke.<ref>{{cite journal | vauthors = Silvoni S, Ramos-Murguialday A, Cavinato M, Volpato C, Cisotto G, Turolla A, Piccione F, Birbaumer N | display-authors = 6 | title = Brain-computer interface in stroke: a review of progress | journal = Clinical EEG and Neuroscience | volume = 42 | issue = 4 | pages = 245\u2013252 | date = October 2011 | pmid = 22208122 | doi = 10.1177/155005941104200410 | s2cid = 37902399 }}</ref><ref>{{cite journal | vauthors = Leamy DJ, Kocijan J, Domijan K, Duffin J, Roche RA, Commins S, Collins R, Ward TE | display-authors = 6 | title = An exploration of EEG features during recovery following stroke - implications for BCI-mediated neurorehabilitation therapy | journal = Journal of Neuroengineering and Rehabilitation | volume = 11 | pages = 9 | date = January 2014 | pmid = 24468185 | pmc = 3996183 | doi = 10.1186/1743-0003-11-9 | first8 = Tomas E | doi-access = free }}</ref><ref>{{cite book | vauthors = Tung SW, Guan C, Ang KK, Phua KS, Wang C, Zhao L, Teo WP, Chew E | title = 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) | chapter = Motor imagery BCI for upper limb stroke rehabilitation: An evaluation of the EEG recordings using coherence analysis | display-authors = 6 | volume = 2013 | pages = 261\u2013264 | date = July 2013 | pmid = 24109674 | doi = 10.1109/EMBC.2013.6609487 | isbn = 978-1-4577-0216-7 | s2cid = 5071115 }}</ref><ref>{{cite journal | vauthors = Bai Z, Fong KN, Zhang JJ, Chan J, Ting KH | title = Immediate and long-term effects of BCI-based rehabilitation of the upper extremity after stroke: a systematic review and meta-analysis | journal = Journal of Neuroengineering and Rehabilitation | volume = 17 | issue = 1 | pages = 57 | date = April 2020 | pmid = 32334608 | pmc = 7183617 | doi = 10.1186/s12984-020-00686-2 | doi-access = free }}</ref> Several groups have explored systems and methods for motor recovery that include BCIs.<ref>{{cite journal | vauthors = Remsik A, Young B, Vermilyea R, Kiekhoefer L, Abrams J, Evander Elmore S, Schultz P, Nair V, Edwards D, Williams J, Prabhakaran V | display-authors = 6 | title = A review of the progression and future implications of brain-computer interface therapies for restoration of distal upper extremity motor function after stroke | journal = Expert Review of Medical Devices | volume = 13 | issue = 5 | pages = 445\u2013454 | date = May 2016 | pmid = 27112213 | pmc = 5131699 | doi = 10.1080/17434440.2016.1174572 }}</ref><ref>{{cite journal | vauthors = Monge-Pereira E, Iba\u00f1ez-Pereda J, Alguacil-Diego IM, Serrano JI, Spottorno-Rubio MP, Molina-Rueda F | title = Use of Electroencephalography Brain-Computer Interface Systems as a Rehabilitative Approach for Upper Limb Function After a Stroke: A Systematic Review | journal = PM&R | volume = 9 | issue = 9 | pages = 918\u2013932 | date = September 2017 | pmid = 28512066 | doi = 10.1016/j.pmrj.2017.04.016 | s2cid = 20808455 | url = https://discovery.ucl.ac.uk/id/eprint/10042536/ }}</ref><ref>{{Cite book| vauthors = Sabathiel N, Irimia DC, Allison BZ, Guger C, Edlinger G |title=Foundations of Augmented Cognition: Neuroergonomics and Operational Neuroscience |date=17 July 2016| chapter = Paired Associative Stimulation with Brain-Computer Interfaces: A New Paradigm for Stroke Rehabilitation|series=Lecture Notes in Computer Science|volume=9743|pages=261\u2013272|doi=10.1007/978-3-319-39955-3_25|isbn=978-3-319-39954-6}}</ref><ref>{{cite book | vauthors = Riccio A, Pichiorri F, Schettini F, Toppi J, Risetti M, Formisano R, Molinari M, Astolfi L, Cincotti F, Mattia D | title = Brain-Computer Interfaces: Lab Experiments to Real-World Applications | display-authors = 6 | chapter = Interfacing brain with computer to improve communication and rehabilitation after brain damage | volume = 228 | pages = 357\u2013387 | year = 2016 | pmid = 27590975 | doi = 10.1016/bs.pbr.2016.04.018 | isbn = 978-0-12-804216-8 | series = Progress in Brain Research }}</ref> In this approach, a BCI measures motor activity while the patient imagines or attempts movements as directed by a therapist. The BCI may provide two benefits: (1) if the BCI indicates that a patient is not imagining a movement correctly (non-compliance), then the BCI could inform the patient and therapist; and (2) rewarding feedback such as functional stimulation or the movement of a virtual avatar also depends on the patient's correct movement imagery.\n\nSo far, BCIs for motor recovery have relied on the EEG to measure the patient's motor imagery. However, studies have also used fMRI to study different changes in the brain as persons undergo BCI-based stroke rehab training.<ref>{{cite journal | vauthors = V\u00e1rkuti B, Guan C, Pan Y, Phua KS, Ang KK, Kuah CW, Chua K, Ang BT, Birbaumer N, Sitaram R | display-authors = 6 | title = Resting state changes in functional connectivity correlate with movement recovery for BCI and robot-assisted upper-extremity training after stroke | journal = Neurorehabilitation and Neural Repair | volume = 27 | issue = 1 | pages = 53\u201362 | date = January 2013 | pmid = 22645108 | doi = 10.1177/1545968312445910 | s2cid = 7120989 }}</ref><ref>{{cite journal | vauthors = Young BM, Nigogosyan Z, Remsik A, Walton LM, Song J, Nair VA, Grogan SW, Tyler ME, Edwards DF, Caldera K, Sattin JA, Williams JC, Prabhakaran V | display-authors = 6 | title = Changes in functional connectivity correlate with behavioral gains in stroke patients after therapy using a brain-computer interface device | journal = Frontiers in Neuroengineering | volume = 7 | pages = 25 | date = 2014 | pmid = 25071547 | pmc = 4086321 | doi = 10.3389/fneng.2014.00025 | doi-access = free }}</ref><ref name=\":6\">{{cite journal | vauthors = Yuan K, Chen C, Wang X, Chu WC, Tong RK | title = BCI Training Effects on Chronic Stroke Correlate with Functional Reorganization in Motor-Related Regions: A Concurrent EEG and fMRI Study | journal = Brain Sciences | volume = 11 | issue = 1 | pages = 56 | date = January 2021 | pmid = 33418846 | doi = 10.3390/brainsci11010056 | pmc = 7824842 | doi-access = free }}</ref> Imaging studies combined with EEG-based BCI systems hold promise for investigating neuroplasticity during motor recovery post-stroke.<ref name=\":6\" /> Future systems might include the fMRI and other measures for real-time control, such as functional near-infrared, probably in tandem with EEGs. Non-invasive brain stimulation has also been explored in combination with BCIs for motor recovery.<ref>{{cite journal | vauthors = Mrachacz-Kersting N, Voigt M, Stevenson AJ, Aliakbaryhosseinabadi S, Jiang N, Dremstrup K, Farina D | title = The effect of type of afferent feedback timed with motor imagery on the induction of cortical plasticity | journal = Brain Research | volume = 1674 | pages = 91\u2013100 | date = November 2017 | pmid = 28859916 | doi = 10.1016/j.brainres.2017.08.025 | hdl-access = free | s2cid = 5866337 | hdl = 10012/12325 }}</ref> In 2016, scientists out of the [[University of Melbourne]] published preclinical proof-of-concept data related to a potential brain-computer interface technology platform being developed for patients with paralysis to facilitate control of external devices such as robotic limbs, computers and exoskeletons by translating brain activity.<ref>{{cite web | vauthors = Opie N |title=Research Overview |url=https://medicine.unimelb.edu.au/research-groups/medicine-and-radiology-research/royal-melbourne-hospital/the-vascular-bionics-laboratory |website=University of Melbourne Medicine |date=2 April 2019 |publisher=University of Melbourne |access-date=5 December 2019}}</ref><ref>{{cite journal | vauthors = Oxley TJ, Opie NL, John SE, Rind GS, Ronayne SM, Wheeler TL, Judy JW, McDonald AJ, Dornom A, Lovell TJ, Steward C, Garrett DJ, Moffat BA, Lui EH, Yassi N, Campbell BC, Wong YT, Fox KE, Nurse ES, Bennett IE, Bauquier SH, Liyanage KA, van der Nagel NR, Perucca P, Ahnood A, Gill KP, Yan B, Churilov L, French CR, Desmond PM, Horne MK, Kiers L, Prawer S, Davis SM, Burkitt AN, Mitchell PJ, Grayden DB, May CN, O'Brien TJ | display-authors = 6 | title = Minimally invasive endovascular stent-electrode array for high-fidelity, chronic recordings of cortical neural activity | journal = Nature Biotechnology | volume = 34 | issue = 3 | pages = 320\u2013327 | date = March 2016 | pmid = 26854476 | doi = 10.1038/nbt.3428 | s2cid = 205282364 }}</ref><ref>{{cite web |title=Synchron begins trialling Stentrode neural interface technology |date=22 September 2019 |url=https://www.medicaldevice-network.com/news/synchron-stentrode-study/ |publisher=Verdict Medical Devices |access-date=5 December 2019}}</ref>\n\n===Functional brain mapping===\nIn 2014, some 400,000 people underwent [[brain mapping]] during neurosurgery. This procedure is often required for people who do not respond to [[medication]].<ref>{{cite journal | vauthors = Radzik I, Miziak B, Dudka J, Chro\u015bci\u0144ska-Krawczyk M, Czuczwar SJ | title = Prospects of epileptogenesis prevention | journal = Pharmacological Reports | volume = 67 | issue = 3 | pages = 663\u2013668 | date = June 2015 | pmid = 25933984 | doi = 10.1016/j.pharep.2015.01.016 | s2cid = 31284248 }}</ref> During this procedure, electrodes are placed on the brain to precisely identify the locations of structures and functional areas. Patients may be awake during neurosurgery and asked to perform tasks, such as moving fingers or repeating words. This is necessary so that surgeons can remove the desired tissue while sparing other regions. Removing too much brain tissue can cause permanent damage, while removing too little can mandate additional neurosurgery.{{citation needed|date=December 2023}} \n\nResearchers explored ways to improve neurosurgical mapping. This work focuses largely on high gamma activity, which is difficult to detect non-invasively. Results improved methods for identifying key functional areas.<ref>{{cite journal | vauthors = Ritaccio A, Brunner P, Gunduz A, Hermes D, Hirsch LJ, Jacobs J, Kamada K, Kastner S, Knight RT, Lesser RP, Miller K, Sejnowski T, Worrell G, Schalk G | display-authors = 6 | title = Proceedings of the Fifth International Workshop on Advances in Electrocorticography | journal = Epilepsy & Behavior | volume = 41 | pages = 183\u2013192 | date = December 2014 | pmid = 25461213 | pmc = 4268064 | doi = 10.1016/j.yebeh.2014.09.015 }}</ref>\n\n===Flexible devices===\n[[Flexible electronics]] are [[polymer]]s or other flexible materials (e.g. [[silk]],<ref name=\"KimSilk\">{{cite journal | vauthors = Kim DH, Viventi J, Amsden JJ, Xiao J, Vigeland L, Kim YS, Blanco JA, Panilaitis B, Frechette ES, Contreras D, Kaplan DL, Omenetto FG, Huang Y, Hwang KC, Zakin MR, Litt B, Rogers JA | display-authors = 6 | title = Dissolvable films of silk fibroin for ultrathin conformal bio-integrated electronics | journal = Nature Materials | volume = 9 | issue = 6 | pages = 511\u2013517 | date = June 2010 | pmid = 20400953 | pmc = 3034223 | doi = 10.1038/nmat2745 | bibcode = 2010NatMa...9..511K }}</ref> [[pentacene]], [[polydimethylsiloxane|PDMS]], [[Parylene]], [[polyimide]]<ref name=\"Boppart\">{{cite journal | vauthors = Boppart SA, Wheeler BC, Wallace CS | title = A flexible perforated microelectrode array for extended neural recordings | journal = IEEE Transactions on Bio-Medical Engineering | volume = 39 | issue = 1 | pages = 37\u201342 | date = January 1992 | pmid = 1572679 | doi = 10.1109/10.108125 | s2cid = 36593459 }}</ref>) printed with [[circuitry]]; the flexibility allows the electronics to bend. The [[semiconductor device fabrication|fabrication techniques]] used to create these devices resembles those used to create [[integrated circuit]]s and [[microelectromechanical systems]] (MEMS).{{Citation needed|date=December 2019|reason=removing citation to predatory publisher content}} \n\nFlexible neural interfaces may minimize brain tissue trauma related to mechanical mismatch between electrode and tissue.<ref>{{cite journal | vauthors = Thompson CH, Zoratti MJ, Langhals NB, Purcell EK | title = Regenerative Electrode Interfaces for Neural Prostheses | journal = Tissue Engineering. Part B, Reviews | volume = 22 | issue = 2 | pages = 125\u2013135 | date = April 2016 | pmid = 26421660 | doi = 10.1089/ten.teb.2015.0279 | doi-access = free }}</ref> \n\n===Neural dust===\n{{main|Neural dust}}\n[[Neural dust]] is millimeter-sized devices operated as [[Wireless power transfer|wirelessly powered]] nerve sensors that were proposed in a 2011 paper from the [[University of California, Berkeley]] Wireless Research Center.<ref name=Rabaey>{{Cite book| vauthors = Rabaey JM |date=September 2011 |doi=10.1109/essderc.2011.6044240|isbn=978-1-4577-0707-0|chapter=Brain-machine interfaces as the new frontier in extreme miniaturization|title=2011 Proceedings of the European Solid-State Device Research Conference (ESSDERC)|pages=19\u201324|s2cid=47542923}}</ref><ref>{{Cite journal| vauthors = Warneke B, Last M, Liebowitz B, Pister KS |s2cid=21557|date=January 2001|title=Smart Dust: communicating with a cubic-millimeter computer|journal=Computer|volume=34|issue=1|pages=44\u201351|doi=10.1109/2.895117|issn=0018-9162}}</ref> In one model, [[local field potential]]s could be distinguished from [[action potential]] \"spikes\", which would offer greatly diversified data vs conventional techniques.<ref name=Rabaey/>\n\n== See also ==\n\n{{div col|colwidth=18em}}\n* [[Informatics]]\n* [[Intendix]] (2009)\n* [[AlterEgo]], a system that reads unspoken verbalizations and responds with bone-conduction headphones\n* [[Augmented learning]]\n* [[Biological machine]]\n* [[Cortical implants]]\n* [[Deep brain stimulation]]\n* [[Human senses]]\n* [[Experience machine]]\n* [[Kernel (neurotechnology company)]]\n* [[Lie detection]]\n* [[Microwave auditory effect]]\n* [[Neural engineering]]\n* [[Neuralink]]\n* [[Neurorobotics]]\n* [[Neurostimulation]]\n* [[Nootropic]]\n* [[Project Cyborg]]\n* [[Simulated reality]]\n* [[Telepresence]]\n* [[Thought identification]]\n* [[Wetware computer]] (Uses similar technology for IO)\n* [[Whole brain emulation]]\n* [[Wirehead (science fiction)]]\n{{div col end}}\n\n== Notes ==\n{{reflist|group=note}}\n\n== References ==\n{{Reflist|30em}}\n\n== Further reading ==\n*Brouse, Andrew. [http://cec.sonus.ca/econtact/14_2/brouse_brainwavemusic.html \"A Young Person's Guide to Brainwave Music: Forty years of audio from the human EEG\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n*Gupta, Cota Navin and Ramaswamy Palanappian. [https://econtact.ca/14_2/gupta-palaniappan_interfacedesign.html \"Using High-Frequency Electroencephalogram in Visual and Auditory-Based Brain-Computer Interface Designs\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n*Ouzounian, Gascia. [https://econtact.ca/14_2/ouzounian_biomuse.html \"The Biomuse Trio in Conversation: An Interview with R. Benjamin Knapp and Eric Lyon\"]. ''eContact! 14.2 \u2013 Biotechnological Performance Practice / Pratiques de performance biotechnologique'' (July 2012). Montr\u00e9al: [[Canadian Electroacoustic Community|CEC]].\n* {{Cite book |url=https://www.researchgate.net/publication/338491730 |title=20 Years of Brain-Machine Interface Research |year=2019 |series=Nicolelis Lab Series |volume=1 |pages=452}}\n* {{Cite book |url=https://www.researchgate.net/publication/338491641 |title=20 Years of Brain-Machine Interface Research |year=2019 |series=Nicolelis Lab Series |volume=2 |pages=436}}\n\n== External links ==\n{{Commons category|Brain-computer interfaces}}\n{{Scholia|topic}}\n\n* {{Cite journal |last=Wandelt |first=Sarah K. |last2=Bj\u00e5nes |first2=David A. |last3=Pejsa |first3=Kelsie |last4=Lee |first4=Brian |last5=Liu |first5=Charles |last6=Andersen |first6=Richard A. |date=2024-05-13 |title=Representation of internal speech by single neurons in human supramarginal gyrus |url=https://www.nature.com/articles/s41562-024-01867-y |journal=Nature Human Behaviour |language=en |pages=1\u201314 |doi=10.1038/s41562-024-01867-y |issn=2397-3374|doi-access=free }}\n\n*[https://web.archive.org/web/20131117040218/http://unlockproject.org/ The Unlock Project]\n*[https://wirelessbci.cloud/ CIA - Wireless BCI]\n\n{{BCI}}\n{{Neuroscience}}\n{{Footer Neuropsychology}}\n{{emerging technologies|topics=yes|neuro=yes|infocom=yes}}\n{{Authority control}}{{DEFAULTSORT:Brain-computer interface}}\n[[Category:Brain\u2013computer interface| ]]\n[[Category:DARPA projects]]\n[[Category:Human\u2013computer interaction]]\n[[Category:Implants (medicine)]]\n[[Category:Neuroprosthetics|*]]\n[[Category:Neural engineering|*]]\n[[Category:User interface techniques]]\n[[Category:Virtual reality]]"}