{"title": "Foundation model", "page_id": 70984276, "revision_id": 1156288818, "revision_timestamp": "2023-05-22T04:29:26Z", "content": "{{Short description|Artificial intelligence model paradigm}}\n{{Use dmy dates|date=May 2023}}\nA '''foundation model''' (also called '''base model''')<ref>{{cite magazine| last=Perrigo | first=Billy | title=The A to Z of Artificial Intelligence |magazine=Time | date=13 April 2023 | url=https://time.com/6271657/a-to-z-of-artificial-intelligence/ | access-date=22 May 2023}}</ref> is a large [[artificial intelligence]] (AI) model trained on a vast quantity of data at scale (often by [[self-supervised learning]] or [[semi-supervised learning]])<ref>{{cite web | last=Goled | first=Shraddha | title=Self-Supervised Learning Vs Semi-Supervised Learning: How They Differ | website=Analytics India Magazine | date=7 May 2021 | url=https://analyticsindiamag.com/self-supervised-learning-vs-semi-supervised-learning-how-they-differ/ | access-date=22 May 2023}}</ref> resulting in a model that can be adapted to a wide range of downstream tasks.<ref name=\"CRFM\">{{Cite web| title = Introducing the Center for Research on Foundation Models (CRFM)| work = Stanford HAI| access-date = 11 June 2022 | url = https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm}}</ref><ref>{{Cite web |last=Goldman |first=Sharon |date=2022-09-13 |title=Foundation models: 2022's AI paradigm shift |url=https://venturebeat.com/ai/foundation-models-2022s-ai-paradigm-shift/ |access-date=2022-10-24 |website=VentureBeat}}</ref> Foundation models have helped bring about a major transformation in how AI systems are built, such as by powering prominent [[chatbot]]s and other user-facing AI. The Stanford Institute for Human-Centered Artificial Intelligence's (HAI) Center for Research on Foundation Models (CRFM) popularized the term.<ref name=\"CRFM\"/>\n\nEarly examples of foundation models were pre-trained [[large language models]] (LLMs) including [[Google]]'s [[BERT (language model)|BERT]]<ref>{{cite arXiv |title=A Primer in BERTology: What we know about how BERT works |first1=Anna |last1=Rogers |first2=Olga |last2=Kovaleva |first3=Anna |last3=Rumshisky |year=2020 |class=cs.CL |eprint=2002.12327 }}</ref> and various early [[Generative_pre-trained_transformer#Foundational models|GPT foundation models]], which notably includes [[OpenAI]]'s '''\"GPT-n\"''' series. Such broad models can in turn be used for task and/or domain specific models using sequences of other kinds of tokens, such as medical codes.<ref>{{Cite journal |last1=Steinberg |first1=Ethan |last2=Jung |first2=Ken |last3=Fries |first3=Jason A. |last4=Corbin |first4=Conor K. |last5=Pfohl |first5=Stephen R. |last6=Shah |first6=Nigam H. |date=January 2021 |title=Language models are an effective representation learning technique for electronic health record data |journal=Journal of Biomedical Informatics |volume=113 |pages=103637 |doi=10.1016/j.jbi.2020.103637 |issn=1532-0480 |pmc=7863633 |pmid=33290879}}</ref> \n\nBeyond text, several visual and multimodal foundation models have been produced{{mdash}}including [[DALL-E]], Flamingo,<ref name=\"deepmind_20220428\">{{citation| title = Tackling multiple tasks with a single visual language model| access-date = 13 June 2022 |date=28 April 2022 | url = https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model}}</ref> Florence <ref>{{cite arXiv |title=Florence: A New Foundation Model for Computer Vision |first1=Lu |last1=Yuan |first2=Dongdong |last2=Chen |first3=Yi-Ling |last3=Chen |first4=Noel |last4=Codella |first5=Xiyang |last5=Dai |first6=Jianfeng |last6=Gao |first7=Houdong |last7=Hu |first8=Xuedong |last8=Huang |first9=Boxin |last9=Li |first10=Chunyuan |last10=Li |first11=Ce |last11=Liu |first12=Mengchen |last12=Liu |first13=Zicheng |last13=Liu |first14=Yumao |last14=Lu |first15=Yu |last15=Shi |first16=Lijuan |last16=Wang |first17=Jianfeng |last17=Wang |first18=Bin |last18=Xiao |first19=Zhen |last19=Xiao |first20=Jianwei |last20=Yang |first21=Michael |last21=Zeng |first22=Luowei |last22=Zhou |first23=Pengchuan |last23=Zhang |year=2022 |class=cs.CV |eprint=2111.11432 }}</ref> and NOOR.<ref>{{Cite web|url=https://finance.yahoo.com/news/technology-innovation-institute-announces-launch-111600479.html|title = Technology Innovation Institute Announces Launch of NOOR, the World's Largest Arabic NLP Model}}</ref> Visual foundation models (VFMs) have been combined with text-based LLMs to develop sophisticated task-specific models.<ref>{{cite web |author=Chenfei Wu |display-authors=et. al. |title=Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models |url=https://arxiv.org/abs/2303.04671 |publisher=Cornell University |access-date=22 May 2023}}</ref>\n\n==Definitions==\nThe Stanford Institute for Human-Centered Artificial Intelligence's (HAI) Center for Research on Foundation Models (CRFM) coined the term \"foundation model\" in August 2021, tentatively referring to \"any model that is trained on broad data (generally using self-supervision at scale) that can be adapted (e.g., fine-tuned) to a wide range of downstream tasks\".<ref name=\"Bommasani_20210818\" /> This was based on their observation that existing overlapping terms were not adequate, submitting that \"'(large) language model' was too narrow given [the] focus is not only language; 'self-supervised model' was too specific to the training objective; and 'pretrained model' suggested that the noteworthy action all happened after 'pretraining.\"<ref>{{cite web | title=Reflections on Foundation Models | website=Stanford HAI | date=18 October 2021 | url=https://hai.stanford.edu/news/reflections-foundation-models | access-date=22 May 2023}}</ref> After considering many terms, they settled on \"foundation model\" to emphasize the intended ''function'' (i.e., amenability to subsequent further development) rather than modality, architecture, or implementation.\n\nThey also note that the concept is not truly new, as it is based on [[deep neural networks]] and [[self-supervised learning]], but asserted that the scale at which the area has developed in recent years, and the increasing potential for any given model to be used for different purposes, warranted a new term.<ref name=\"Bommasani_20210818\" />\n\nA foundation model is a \"paradigm for building AI systems\" in which a model trained on a large amount of unlabeled data can be adapted to many applications.<ref>{{Cite web| title = Stanford CRFM| access-date = 10 June 2022 | url = https://crfm.stanford.edu/}}</ref><ref>{{Cite web| title = What are foundation models? |work=IBM Research Blog|date=9 February 2021 | access-date = 10 June 2022 | url = https://research.ibm.com/blog/what-are-foundation-models}}</ref> Foundation models are \"designed to be adapted (e.g., finetuned) to various downstream cognitive tasks by pre-training on broad data at scale\".<ref>{{Cite journal |last1=Fei |first1=Nanyi |last2=Lu |first2=Zhiwu |last3=Gao |first3=Yizhao |last4=Yang |first4=Guoxing |last5=Huo |first5=Yuqi |last6=Wen |first6=Jingyuan |last7=Lu |first7=Haoyu |last8=Song |first8=Ruihua |last9=Gao |first9=Xin |last10=Xiang |first10=Tao |last11=Sun |first11=Hao |last12=Wen |first12=Ji-Rong |date=December 2022 |title=Towards artificial general intelligence via a multimodal foundation model |journal=Nature Communications |language=en |volume=13 |issue=1 |pages=3094 |doi=10.1038/s41467-022-30761-2 |issn=2041-1723 |pmc=9163040 |pmid=35655064|arxiv=2110.14378 |bibcode=2022NatCo..13.3094F }}</ref>\n\nKey characteristics of foundation models are ''emergence'' and ''homogenization''.<ref name=\"Bommasani_20210818\" /> Because training data is not labelled by humans, the model emerges rather than being explicitly encoded. Properties that were not anticipated can appear. For example, a model trained on a large language dataset might learn to generate stories of its own, or to do arithmetic, without being explicitly programmed to do so.<ref name=\":0\">{{Cite news |title=Huge \"foundation models\" are turbo-charging AI progress |newspaper=The Economist |url=https://www.economist.com/interactive/briefing/2022/06/11/huge-foundation-models-are-turbo-charging-ai-progress |access-date=2022-10-24 |issn=0013-0613}}</ref> Homogenization means that the same method is used in many domains, which allows for powerful advances but also the possibility of \"single points of failure\".<ref name=\"Bommasani_20210818\" />\n\n==Personalizing foundation models==\nSince foundation models are pre-trained on a massive dataset, they are not capable of handling specific \"personal\" concepts that a user may be interested in. A series of methods were designed to augment a foundation model with personal, specific items without retraining the full model. For example, for [[One-shot learning (computer vision)|few-shot]] [[image retrieval]] it was shown how to adapt a vision-language foundation model (CLIP) by adding new concept to its vocabulary.<ref>{{Cite journal |last1=Cohen |first1=Niv |last2=Gal |first2=Rinon |last3=Meirom |first3=Eli A. |last4=Chechik |first4=Gal |last5=Atzmon |first5=Yuval |date=2022-10-23 |title=\"This Is My Unicorn, Fluffy\": Personalizing Frozen Vision-Language Representations |url=https://doi.org/10.1007/978-3-031-20044-1_32 |journal=Computer Vision \u2013 ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XX |series=Lecture Notes in Computer Science |volume=13680 |location=Berlin, Heidelberg |publisher=Springer-Verlag |pages=558\u2013577 |doi=10.1007/978-3-031-20044-1_32 |arxiv=2204.01694 |isbn=978-3-031-20043-4}}</ref>  For [[Text-to-image generation]], an approach called [[textual inversion]]<ref>{{Cite arXiv |last1=Gal |first1=Rinon |last2=Alaluf |first2=Yuval |last3=Atzmon |first3=Yuval |last4=Patashnik |first4=Or |last5=Bermano |first5=Amit H. |last6=Chechik |first6=Gal |last7=Cohen-Or |first7=Daniel |date=2022-08-02 |title=An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion |class=cs.CV |eprint=2208.01618 }}</ref> can be similarly used to teach the system new concept that can later be generated in conjunction with the concepts that the foundation model is already familiar with.\n\n==Opportunities and risks==\nA 2021 arXiv report listed foundation models' capabilities in regards to \"language, vision, robotics, reasoning, and human interaction\", technical principles, such as \"model architectures, training procedures, data, systems, security, evaluation, and theory\", their applications, for example in law, healthcare, and education and their potential impact on society, including \"inequity, misuse, economic and environmental impact, legal and ethical considerations\".<ref name=\"Bommasani_20210818\">{{Cite report| last1 = Bommasani| first1 = Rishi| last2 = Hudson| first2 = Drew A.| last3 = Adeli| first3 = Ehsan| last4 = Altman| first4 = Russ| last5 = Arora| first5 = Simran| last6 = von Arx| first6 = Sydney| last7 = Bernstein| first7 = Michael S.| last8 = Bohg| first8 = Jeannette| last9 = Bosselut| first9 = Antoine| last10 = Brunskill| first10 = Emma| last11 = Brynjolfsson| first11 = Erik| last12 = Buch| first12 = Shyamal| last13 = Card| first13 = Dallas| last14 = Castellon| first14 = Rodrigo| last15 = Chatterji| first15 = Niladri| last16 = Chen| first16 = Annie| last17 = Creel| first17 = Kathleen| last18 = Davis| first18 = Jared Quincy| last19 = Demszky| first19 = Dora| last20 = Donahue| first20 = Chris| last21 = Doumbouya| first21 = Moussa| last22 = Durmus| first22 = Esin| last23 = Ermon| first23 = Stefano| last24 = Etchemendy| first24 = John| last25 = Ethayarajh| first25 = Kawin| last26 = Fei-Fei| first26 = Li| last27 = Finn| first27 = Chelsea| last28 = Gale| first28 = Trevor| last29 = Gillespie| first29 = Lauren| last30 = Goel| first30 = Karan| last31 = Goodman| first31 = Noah| last32 = Grossman| first32 = Shelby| last33 = Guha| first33 = Neel| last34 = Hashimoto| first34 = Tatsunori| last35 = Henderson| first35 = Peter| last36 = Hewitt| first36 = John| last37 = Ho| first37 = Daniel E.| last38 = Hong| first38 = Jenny| last39 = Hsu| first39 = Kyle| last40 = Huang| first40 = Jing| last41 = Icard| first41 = Thomas| last42 = Jain| first42 = Saahil| last43 = Jurafsky| first43 = Dan| last44 = Kalluri| first44 = Pratyusha| last45 = Karamcheti| first45 = Siddharth| last46 = Keeling| first46 = Geoff| last47 = Khani| first47 = Fereshte| last48 = Khattab| first48 = Omar| last49 = Koh| first49 = Pang Wei| last50 = Krass| first50 = Mark| last51 = Krishna| first51 = Ranjay| last52 = Kuditipudi| first52 = Rohith| last53 = Kumar| first53 = Ananya| last54 = Ladhak| first54 = Faisal| last55 = Lee| first55 = Mina| last56 = Lee| first56 = Tony| last57 = Leskovec| first57 = Jure| last58 = Levent| first58 = Isabelle| last59 = Li| first59 = Xiang Lisa| last60 = Li| first60 = Xuechen| last61 = Ma| first61 = Tengyu| last62 = Malik| first62 = Ali| last63 = Manning| first63 = Christopher D.| last64 = Mirchandani| first64 = Suvir| last65 = Mitchell| first65 = Eric| last66 = Munyikwa| first66 = Zanele| last67 = Nair| first67 = Suraj| last68 = Narayan| first68 = Avanika| last69 = Narayanan| first69 = Deepak| last70 = Newman| first70 = Ben| last71 = Nie| first71 = Allen| last72 = Niebles| first72 = Juan Carlos| last73 = Nilforoshan| first73 = Hamed| last74 = Nyarko| first74 = Julian| last75 = Ogut| first75 = Giray| last76 = Orr| first76 = Laurel| last77 = Papadimitriou| first77 = Isabel| last78 = Park| first78 = Joon Sung| last79 = Piech| first79 = Chris| last80 = Portelance| first80 = Eva| last81 = Potts| first81 = Christopher| last82 = Raghunathan| first82 = Aditi| last83 = Reich| first83 = Rob| last84 = Ren| first84 = Hongyu| last85 = Rong| first85 = Frieda| last86 = Roohani| first86 = Yusuf| last87 = Ruiz| first87 = Camilo| last88 = Ryan| first88 = Jack| last89 = R\u00e9| first89 = Christopher| last90 = Sadigh| first90 = Dorsa| last91 = Sagawa| first91 = Shiori| last92 = Santhanam| first92 = Keshav| last93 = Shih| first93 = Andy| last94 = Srinivasan| first94 = Krishnan| last95 = Tamkin| first95 = Alex| last96 = Taori| first96 = Rohan| last97 = Thomas| first97 = Armin W.| last98 = Tram\u00e8r| first98 = Florian| last99 = Wang| first99 = Rose E.| last100 = Wang| first100 = William| last101 = Wu| first101 = Bohan| last102 = Wu| first102 = Jiajun| last103 = Wu| first103 = Yuhuai| last104 = Xie| first104 = Sang Michael| last105 = Yasunaga| first105 = Michihiro| last106 = You| first106 = Jiaxuan| last107 = Zaharia| first107 = Matei| last108 = Zhang| first108 = Michael| last109 = Zhang| first109 = Tianyi| last110 = Zhang| first110 = Xikun| last111 = Zhang| first111 = Yuhui| last112 = Zheng| first112 = Lucia| last113 = Zhou| first113 = Kaitlyn| last114 = Liang| first114 = Percy| title = On the Opportunities and Risks of Foundation Models| date = 18 August 2021 | arxiv = 2108.07258}}</ref>\n\nAn article about foundation models in ''The Economist'' notes that \"some worry that the technology's heedless spread will further concentrate economic and political power\".<ref name=\":0\" />\n\n==References==\n{{reflist}}\n\n{{Natural Language Processing}}\n{{Differentiable computing}}\n{{Existential risk from artificial intelligence}}\n\n[[Category:Natural language processing]]\n[[Category:Computational linguistics]]\n[[Category:Computational fields of study]]\n[[Category:Language modeling]]\n[[Category:Unsupervised learning]]\n[[Category:Deep learning]]"}