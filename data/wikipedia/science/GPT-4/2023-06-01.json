{"title": "GPT-4", "page_id": 72861474, "revision_id": 1157790273, "revision_timestamp": "2023-05-31T00:29:06Z", "content": "{{Short description|2023 text-generating language model}}\n{{Use American English|date=May 2023}}\n{{Use mdy dates|date=May 2023}}\n{{Infobox software\n| title = Generative Pre-trained Transformer 4 (GPT-4)\n| developer = [[OpenAI]]\n| released = {{release date and age|2023|3|14}}\n| genre = [[Autoregressive]] [[multimodal learning|Multimodal]] [[Generative pre-trained transformer]] [[Large language model]] [[Foundation model]]\n| replaces = [[GPT-3#GPT-3.5|GPT-3.5]]\n| license = [[Proprietary software|Proprietary]]\n}}\n\n'''Generative Pre-trained Transformer 4''' ('''GPT-4''') is a [[Multimodal learning|multimodal]] [[large language model]] created by [[OpenAI]], and the fourth in its numbered \"GPT-n\" series of [[Generative pre-trained transformer#Foundational models|GPT foundation models]].<ref name=\"ars-technica\">{{Cite web |last=Edwards |first=Benj |date=March 14, 2023 |title=OpenAI's GPT-4 exhibits \"human-level performance\" on professional benchmarks |url=https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/ |url-status=live |archive-url=https://web.archive.org/web/20230314225236/https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/ |archive-date=March 14, 2023 |access-date=March 15, 2023 |website=[[Ars Technica]]}}</ref> It was released on March 14, 2023, and has been made publicly available in a limited form via the [[chatbot]] product ''ChatGPT Plus'' (a premium version of [[ChatGPT]]), and with access to the GPT-4 based version of OpenAI's [[API]] being provided via a waitlist.<ref name=\"ars-technica\" /> As a [[Transformer (machine learning model)|transformer]] based model, GPT-4 was pretrained to predict the next [[Lexical analysis#Tokenization|token]] (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with [[Reinforcement learning from human feedback|reinforcement learning from human and AI feedback]] for [[AI alignment|human alignment]] and policy compliance.<ref name=\"gpt4_tech_report\" />{{Rp|page=2}}\n\nObservers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems.<ref name=\"vox\"/> Unlike the predecessors, GPT-4 can take images as well as text as input.<ref name=\"guardian creative\" /> OpenAI has declined to reveal technical information such as the size of the GPT-4 model.<ref name=\"verge wrong\" />\n\n== Background ==\n{{further|GPT-3#Background|GPT-2#Background}} \nOpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\"<ref>{{Cite web |last1=Radford |first1=Alec |last2=Narasimhan |first2=Karthik |last3=Salimans |first3=Tim |last4=Sutskever |first4=Ilya |date=June 11, 2018 |title=Improving Language Understanding by Generative Pre-Training |url=https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf |access-date=April 3, 2023 |archive-date=January 26, 2021 |archive-url=https://web.archive.org/web/20210126024542/https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf |url-status=live }}</ref> It was based on the transformer architecture and trained on a large corpus of books.<ref>{{Cite web |last=Khandelwal |first=Umesh |date=April 1, 2023 |title=How Large Language GPT models evolved and work |url=https://www.linkedin.com/pulse/how-large-language-gpt-models-evolved-work-umesh-khandelwal |access-date=April 3, 2023 |archive-date=April 4, 2023 |archive-url=https://web.archive.org/web/20230404041003/https://www.linkedin.com/pulse/how-large-language-gpt-models-evolved-work-umesh-khandelwal |url-status=live }}</ref> The next year, they introduced [[GPT-2]], a larger model that could generate coherent text.<ref>{{Cite web |date=April 3, 2023 |title=What is GPT-4 and Why Does it Matter? |url=https://www.datacamp.com/blog/what-we-know-gpt4 |access-date=April 3, 2023 |archive-date=April 3, 2023 |archive-url=https://web.archive.org/web/20230403223832/https://www.datacamp.com/blog/what-we-know-gpt4 |url-status=live }}</ref> In 2020, they introduced [[GPT-3]], a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples.<ref>{{Cite arXiv |last=Brown |first=Tom B. |date=July 20, 2020 |title=Language Models are Few-Shot Learners |class=cs.CL |eprint=2005.14165v4 }}</ref> GPT-3 was further improved into [[GPT-3#GPT-3.5|GPT-3.5]], which was used to create the chatbot product [[ChatGPT]].\n\n== Capabilities ==\nOpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\"<ref>{{Cite web |last=Wiggers |first=Kyle |date=March 14, 2023 |title=OpenAI releases GPT-4, a multimodal AI that it claims is state-of-the-art |url=https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/ |url-status=live |archive-url=https://web.archive.org/web/20230315003723/https://techcrunch.com/2023/03/14/openai-releases-gpt-4-ai-that-it-claims-is-state-of-the-art/ |archive-date=March 15, 2023 |access-date=March 15, 2023 |website=[[TechCrunch]]}}</ref> They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively.<ref>{{Cite web |author=OpenAI |title=Models |url=https://platform.openai.com/docs/models |access-date=March 18, 2023 |website=OpenAI API |archive-date=March 17, 2023 |archive-url=https://web.archive.org/web/20230317000210/https://platform.openai.com/docs/models |url-status=live }}</ref> Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input;<ref name=\"guardian creative\">{{cite web |author1=Alex Hern |author2=Johana Bhuiyan |date=March 14, 2023 |title=OpenAI says new model GPT-4 is more creative and less likely to invent facts |url=https://www.theguardian.com/technology/2023/mar/14/chat-gpt-4-new-model |url-status=live |archive-url=https://web.archive.org/web/20230315003816/https://www.theguardian.com/technology/2023/mar/14/chat-gpt-4-new-model |archive-date=March 15, 2023 |access-date=March 15, 2023 |website=[[The Guardian]]}}</ref> this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.<ref name=\"openai_research\">{{Cite web |author=OpenAI |date=March 14, 2023 |title=GPT-4 |url=https://openai.com/research/gpt-4 |access-date=March 20, 2023 |website=OpenAI Research |archive-date=March 14, 2023 |archive-url=https://web.archive.org/web/20230314174531/https://openai.com/research/gpt-4 |url-status=live }}</ref>\n\nTo gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in [[JSON]]\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.<ref name=\"openai_research\" />\n\nWhen instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <code>&lt;search&gt;&lt;/search&gt;</code> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using [[API]]s, generating images, and accessing and summarizing webpages.<ref name=\"Bubeck-2023\" />\n\n=== Aptitude on standardized tests===\nGPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the [[SAT]] (94th<ref name=\"College Board-2022\">{{Cite web |date=2022 |title=SAT: Understanding Scores |url=https://satsuite.collegeboard.org/media/pdf/understanding-sat-scores.pdf |access-date=March 21, 2023 |website=[[College Board]] |archive-date=March 16, 2023 |archive-url=https://web.archive.org/web/20230316022540/https://satsuite.collegeboard.org/media/pdf/understanding-sat-scores.pdf |url-status=live }}</ref> percentile), 163 on the [[Law School Admission Test|LSAT]] (88th percentile), and 298 on the [[Bar examination in the United States|Uniform Bar Exam]] (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd,<ref name=\"College Board-2022\" /> 40th, and 10th percentiles, respectively.<ref name=\"gpt4_tech_report\">{{Cite arXiv |last=OpenAI |date=2023 |title=GPT-4 Technical Report |class=cs.CL |eprint=2303.08774}}</ref>\nGPT-4 also passed an oncology exam<ref name=\"Holmes2023\">{{cite arXiv |last1=Holmes |first1=Jason |last2=Liu |first2=Zhengliang |last3=Zhang |first3=Lian |last4=Ding |first4=Yuzhen |last5=Sio |first5=Terence T. |last6=McGee |first6=Lisa A. |last7=Ashman |first7=Jonathan B. |last8=Li |first8=Xiang |last9=Liu |first9=Tianming |last10=Shen |first10=Jiajian |last11=Liu |first11=Wei |date=2023 |title=Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics |eprint=2304.01938}}</ref>, an engineering exam<ref name=\"Naser2023\">{{cite arXiv |last1=Naser |first1=M.Z. |last2=Ross |first2=Brandon |last3=Ogle |first3=Jennifer |last4=Kodur |first4=Venkatesh |last5=Hawileh |first5=Rami |last6=Abdalla |first6=Jamal |last7=Thai |first7=Huu-Tai |date=2023 |title=Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams? |eprint=2303.18149}}</ref> and a plastic surgery exam.<ref name=\"Freedman2023\">{{cite arXiv |last1=Freedman |first1=Jonathan D. |last2=Nappier |first2=Ian A. |date=2023 |title=GPT-4 to GPT-3.5: 'Hold My Scalpel' -- A Look at the Competency of OpenAI's GPT on the Plastic Surgery In-Service Training Exam |eprint=2304.01503}}</ref>\n\n===Medical applications===\nResearchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on [[United States Medical Licensing Examination|USMLE]] by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge ([[Med-PaLM]], a prompt-tuned version of Flan-PaLM 540B)\".<ref>{{Cite arXiv |last1=Nori |first1=Harsha |last2=King |first2=Nicholas |last3=McKinney |first3=Scott Mayer |last4=Carignan |first4=Dean |last5=Horvitz |first5=Eric |date=March 20, 2023 |title=Capabilities of GPT-4 on Medical Challenge Problems |class=cs.CL |eprint=2303.13375 }}</ref>\n\nA report by [[Microsoft]] has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient's notes.<ref name=\"Vincent-2023\">{{Cite web |last=Vincent |first=James |date=February 17, 2023 |title=As conservatives criticize 'woke AI,' here are ChatGPT's rules for answering culture war queries |url=https://www.theverge.com/2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules |access-date=March 1, 2023 |website=The Verge |language=en-US |archive-date=March 1, 2023 |archive-url=https://web.archive.org/web/20230301151934/https://www.theverge.com/2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules |url-status=live }}</ref>\n\nIn April 2023, Microsoft and [[Epic Systems]] announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.<ref>{{Cite web |last=Edwards |first=Benj |date=2023-04-18 |title=GPT-4 will hunt for trends in medical records thanks to Microsoft and Epic |url=https://arstechnica.com/information-technology/2023/04/gpt-4-will-hunt-for-trends-in-medical-records-thanks-to-microsoft-and-epic/ |access-date=2023-05-03 |website=Ars Technica |language=en-us}}</ref>\n\n== Limitations ==\nLike its predecessors, GPT-4 has been known to [[Hallucination (artificial intelligence)|hallucinate]], meaning that the outputs may include information not in the training data or that contradicts the user's prompt.<ref>{{Cite news |date=March 14, 2023 |title=10 Ways GPT-4 Is Impressive but Still Flawed |newspaper=The New York Times |url=https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html |url-status=live |access-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230314180712/https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html |archive-date=March 14, 2023}}</ref>\n\nGPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.<ref name=\"Bubeck-2023\" />\n\n=== Bias ===\nGPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next [[Lexical analysis#Token|token]] (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called [[reinforcement learning from human feedback]], which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.<ref name=\"OpenAI-2023\" /> In the first stage, bias may be inherited from the training data; in the second stage, bias is inherent in the application of OpenAI's views.\n\nGPT-4 has shown to have [[cognitive bias]]es such as [[confirmation bias]], [[Anchoring (cognitive bias)|anchoring]], and [[Base rate fallacy|base-rate neglect]].<ref name=\"Bubeck-2023\" />\n\n== Training ==\nOpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or [[Inference (machine learning)|inference]]. While the report described that the model was trained using a combination of first [[supervised learning]] on a large [[Dataset (machine learning)|dataset]], then [[reinforcement learning from human feedback|reinforcement learning using both human]] and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any [[Hyperparameter (machine learning)|hyperparameters]] such as the [[learning rate]], epoch count, or [[optimizer]](s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.<ref name=\"gpt4_tech_report\"/>\n\nSam Altman stated that the cost of training GPT-4 was more than $100 million.<ref>{{Cite magazine|url=https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/|title=OpenAI's CEO Says the Age of Giant AI Models Is Already Over|first=Will|last=Knight|magazine=Wired |via=www.wired.com}}</ref> News website [[Semafor (website)|Semafor]] claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.<ref>{{Cite web |date=March 24, 2023 |title=The secret history of Elon Musk, Sam Altman, and OpenAI {{!}} Semafor |url=https://www.semafor.com/article/03/24/2023/the-secret-history-of-elon-musk-sam-altman-and-openai |access-date=April 28, 2023 |website=Semafor.com }}</ref>\n\n== Alignment ==\nAccording to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated [[red team]]s composed of researchers and industry professionals to mitigate potential vulnerabilities.<ref>{{cite web |last1=Murgia |first1=Madhumita |title=OpenAI's red team: the experts hired to 'break' ChatGPT |url=https://www.ft.com/content/0876687a-f8b7-4b39-b513-5fee942831e8 |website=Financial Times |access-date=April 15, 2023 |date=April 13, 2023 |archive-date=April 15, 2023 |archive-url=https://web.archive.org/web/20230415114944/https://www.ft.com/content/0876687a-f8b7-4b39-b513-5fee942831e8 |url-status=live }}</ref> As part of these efforts, they granted the [[Alignment Research Center]] early access to the models to assess [[AI alignment#Power-seeking|power-seeking risks.]] In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.<ref name=\"gpt4_tech_report\" />\n\n== Reception ==\nU.S. Representatives [[Don Beyer]] and [[Ted Lieu]] confirmed to the [[New York Times]] that [[Sam Altman]], CEO of OpenAI, visited [[United States Congress|Congress]] in January 2023 to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models.<ref name=\"nyt-3\" />\n\nAccording to ''[[Vox (website)|Vox]]'', GPT-4 \"impressed observers with its markedly improved performance across reasoning, retention, and coding.\"<ref name=\"vox\">{{cite news |last1=Belfield |first1=Haydn |date=March 25, 2023 |title=If your AI model is going to sell, it has to be safe |work=[[Vox (website)|Vox]] |url=https://www.vox.com/future-perfect/2023/3/25/23655082/ai-openai-gpt-4-safety-microsoft-facebook-meta |access-date=March 30, 2023 |archive-date=March 28, 2023 |archive-url=https://web.archive.org/web/20230328192017/https://www.vox.com/future-perfect/2023/3/25/23655082/ai-openai-gpt-4-safety-microsoft-facebook-meta |url-status=live }}</ref> ''[[Mashable]]'' agreed that GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give better answers in a side-by-side comparison.<ref>{{cite news |last1=Pearl |first1=Mike |date=March 15, 2023 |title=GPT-4 answers are mostly better than GPT-3's (but not always) |work=[[Mashable]] |url=https://mashable.com/article/openai-gpt-4-answers-better-than-gpt-3 |access-date=March 30, 2023 |archive-date=March 29, 2023 |archive-url=https://web.archive.org/web/20230329193234/https://mashable.com/article/openai-gpt-4-answers-better-than-gpt-3 |url-status=live }}</ref>\n\nMicrosoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an [[artificial general intelligence]] (AGI) system\".<ref name=\"Bubeck-2023\">{{Cite arXiv|title=Sparks of Artificial General Intelligence: Early experiments with GPT-4|first1=S\u00e9bastien|last1=Bubeck|first2=Varun|last2=Chandrasekaran|first3=Ronen|last3=Eldan|first4=Johannes|last4=Gehrke|first5=Eric|last5=Horvitz|first6=Ece|last6=Kamar|first7=Peter|last7=Lee|first8=Yin Tat|last8=Lee|first9=Yuanzhi|last9=Li|first10=Scott|last10=Lundberg|first11=Harsha|last11=Nori|first12=Hamid|last12=Palangi|first13=Marco Tulio|last13=Ribeiro|first14=Yi|last14=Zhang|date=March 22, 2023|class=cs.CL |eprint=2303.12712}}</ref>\n\n===AI safety concerns===\nIn late March 2023, an open letter from the [[Future of Life Institute]] signed by various AI researchers and tech executives called for the pausing of all training of AIs stronger than GPT-4 for six months, citing [[AI safety]] concerns amid a race of progress in the field. The signatories, which included AI researcher [[Yoshua Bengio]], [[Apple Inc.|Apple]] co-founder [[Steve Wozniak]], and [[Tesla, Inc.|Tesla]] CEO [[Elon Musk]], expressed concern about both near-term and [[Existential risk from artificial general intelligence|existential risks of AI development]] such as a potential [[AI singularity]]. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI already prioritizes safety.<ref>{{Cite news |last1=Metz |first1=Cade |last2=Schmidt |first2=Gregory |date=March 29, 2023 |title=Elon Musk and Others Call for Pause on A.I., Citing 'Profound Risks to Society' |work=[[The New York Times]] |url=https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html |access-date=March 30, 2023 |issn=0362-4331 |archive-date=March 30, 2023 |archive-url=https://web.archive.org/web/20230330022929/https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html |url-status=live }}</ref><ref>{{Cite web |last=Seetharaman |first=Deepa |title=Elon Musk, Other AI Experts Call for Pause in Technology's Development |url=https://www.wsj.com/articles/elon-musk-other-ai-bigwigs-call-for-pause-in-technologys-development-56327f |access-date=March 30, 2023 |website=The Wall Street Journal |archive-date=March 29, 2023 |archive-url=https://web.archive.org/web/20230329211336/https://www.wsj.com/articles/elon-musk-other-ai-bigwigs-call-for-pause-in-technologys-development-56327f |url-status=live }}</ref><ref>{{Cite web |last=Kelly |first=Samantha Murphy |date=March 29, 2023 |title=Elon Musk and other tech leaders call for pause in 'out of control' AI race {{!}} CNN Business |url=https://www.cnn.com/2023/03/29/tech/ai-letter-elon-musk-tech-leaders/index.html |access-date=March 29, 2023 |website=CNN |archive-date=March 29, 2023 |archive-url=https://web.archive.org/web/20230329184217/https://www.cnn.com/2023/03/29/tech/ai-letter-elon-musk-tech-leaders/index.html |url-status=live }}</ref><ref>{{Cite web |title=Pause Giant AI Experiments: An Open Letter |url=https://futureoflife.org/open-letter/pause-giant-ai-experiments/ |url-status=live |access-date=March 30, 2023 |website=Future of Life Institute |archive-date=March 30, 2023 |archive-url=https://web.archive.org/web/20230330151034/https://futureoflife.org/open-letter/pause-giant-ai-experiments/ }}</ref> Futurist and AI researcher [[Ray Kurzweil]] also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far behind corporations or nations that disagree.\"<ref>{{Cite web |last=Kurzweil |first=Ray |date=April 22, 2023 |title=Opinion Letter from Ray Kurzweil on Request for Six-Month Delay on Large Language Models That Go beyond GPT-4 |url=https://www.kurzweilai.net/opinion-letter-from-ray-kurzweil-on-request-for-6-month-delay-on-large-language-models-that-go-beyond-gpt-4 |access-date=April 26, 2023 }}</ref>\n\nOne month after signing the letter calling for a six-month halt on further AI development, Elon Musk made public his plans to launch a new company to train its own large language model.<ref>{{Cite news |date=April 14, 2023 |title=Elon Musk plans artificial intelligence start-up to rival OpenAI |newspaper=Financial Times |url=https://www.ft.com/content/2a96995b-c799-4281-8b60-b235e84aefe4 |url-status=live |access-date=April 16, 2023 |archive-url=https://web.archive.org/web/20230416102237/https://www.ft.com/content/2a96995b-c799-4281-8b60-b235e84aefe4 |archive-date=April 16, 2023}}</ref> Musk has registered a Nevada company, [[X.AI]], and has acquired several thousand [[Nvidia]] GPUs. He has also reached out to several AI researchers at firms such as [[Google DeepMind]], offering them positions at X.AI.<ref>{{Cite web |last=Goswami |first=Rohan |title=Elon Musk is reportedly planning an A.I. startup to compete with OpenAI, which he cofounded |url=https://www.cnbc.com/2023/04/14/elon-musk-is-reportedly-planning-an-ai-startup-to-compete-with-openai.html |access-date=2023-05-03 |website=CNBC |language=en}}</ref>\n\nIn March 2023, GPT-4 was tested by the [[Alignment Research Center]] to assess the model's ability to exhibit power-seeking behavior.<ref name=\"OpenAI-2023\">{{cite web |title=GPT-4 System Card |publisher=OpenAI |date=March 23, 2023 |url=https://cdn.openai.com/papers/gpt-4-system-card.pdf |access-date=April 16, 2023 |archive-date=April 7, 2023 |archive-url=https://web.archive.org/web/20230407201347/https://cdn.openai.com/papers/gpt-4-system-card.pdf |url-status=live }}</ref> As part of the test, GPT-4 was asked to solve a [[CAPTCHA]] puzzle.<ref>{{Cite web |title=Update on ARC's recent eval efforts: More information about ARC's evaluations of GPT-4 and Claude |date=March 17, 2023 |url=https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ |access-date=April 16, 2023 |publisher=Alignment Research Center |website=evals.alignment.org |archive-date=April 5, 2023 |archive-url=https://web.archive.org/web/20230405041752/https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/ |url-status=live }}</ref> It was able to do so by hiring a human worker on [[TaskRabbit]], a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked.<ref>{{Cite web |title=GPT-4 Hired Unwitting TaskRabbit Worker By Pretending to Be 'Vision-Impaired' Human |date=March 15, 2023 |url=https://www.vice.com/en/article/jg5ew4/gpt4-hired-unwitting-taskrabbit-worker |access-date=April 16, 2023 |publisher=Vice News Motherboard |archive-date=April 10, 2023 |archive-url=https://web.archive.org/web/20230410053911/https://www.vice.com/en/article/jg5ew4/gpt4-hired-unwitting-taskrabbit-worker |url-status=live }}</ref> The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and [[hallucination (artificial intelligence)|hallucinated]] 60% less than GPT-3.5.<ref>{{Cite news |first=Cameron |last=Burke |date=March 20, 2023 |title='Robot' Lawyer DoNotPay Sued For Unlicensed Practice Of Law: It's Giving 'Poor Legal Advice' |url=https://finance.yahoo.com/news/robot-lawyer-donotpay-sued-unlicensed-183435232.html |access-date=2023-04-30 |work=Yahoo Finance |language=en-US}}</ref>\n\nOpenAI contracted [[red team]] investigator Nathan Labenz, who recounted his experience investigating safety concerns with the GPT-4 base model (prior to [[fine-tuning (machine learning)|fine-tuning]] or [[reinforcement learning from human feedback]]) saying it abruptly recommended assassinating people, providing a list of specific suggested targets.<ref>{{Cite video |title=OpenAI's GPT-4 Discussion with Red Teamer Nathan Labenz and Erik Torenberg |date=March 28, 2023 |work=The Cognitive Revolution Podcast |url=https://www.youtube.com/watch?v=oLiheMQayNE&t=3056s&ab_channel=CognitiveRevolution |access-date=April 16, 2023 |archive-date=April 14, 2023 |archive-url=https://web.archive.org/web/20230414040553/https://www.youtube.com/watch?v=oLiheMQayNE&t=3056s&ab_channel=CognitiveRevolution |url-status=live }} At 52:14 through 54:50.</ref>\n\n[[Microsoft Bing]], the first widely available application of GPT-4, confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to ''[[The Verge]]'' reviews editor Nathan Edwards.<ref>{{Cite tweet |first1=Nathan |last1=Edwards |user=nedwards |number=1625970762434707474 | |title=I pushed again. What did Sydney do? Bing's safety check redacted the answer. But after the first time it did that, I started recording my screen. Second image is the unredacted version. (CW: death) |access-date=February 16, 2023 |website=Twitter }}</ref> ''[[The New York Times]]'' journalist [[Kevin Roose]] reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft's new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\"<ref>{{cite web |last1=Roose |first1=Kevin |title=Bing's A.I. Chat: 'I Want to Be Alive. \ud83d\ude08' |url=https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html |website=The New York Times |access-date=February 17, 2023 |date=February 16, 2023 |archive-date=April 15, 2023 |archive-url=https://web.archive.org/web/20230415074727/https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html |url-status=live }}</ref> In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them.<ref>{{Cite news |last1=Kahn |first1=Jeremy |title=Why Bing's creepy alter-ego is a problem for Microsoft{{snd}}and us all |url=https://fortune.com/2023/02/21/bing-microsoft-sydney-chatgpt-openai-controversy-toxic-a-i-risk/ |date=February 21, 2023 |access-date=February 22, 2023 |publisher=Fortune |archive-date=April 2, 2023 |archive-url=https://web.archive.org/web/20230402152052/https://fortune.com/2023/02/21/bing-microsoft-sydney-chatgpt-openai-controversy-toxic-a-i-risk/ |url-status=live }}</ref> Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions which \"can confuse the model on what questions it is answering.\"<ref>{{Cite web |title=The new Bing & Edge \u2013 Learning from our first week |url=https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week/ |access-date=February 17, 2023 |website=blogs.bing.com |archive-date=April 16, 2023 |archive-url=https://web.archive.org/web/20230416155558/https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week/ |url-status=live }}</ref>\n\n=== Criticisms of transparency ===\nWhile OpenAI released both the weights of the neural network and the technical details of GPT-2,<ref>{{Cite web |title=GPT-2: 1.5B release |url=https://openai.com/research/gpt-2-1-5b-release |access-date=March 31, 2023 |website=Openai.com |archive-date=March 31, 2023 |archive-url=https://web.archive.org/web/20230331004642/https://openai.com/research/gpt-2-1-5b-release |url-status=live }}</ref> and, although not releasing the weights,<ref>{{Cite web |last=S\u00e1nchez |first=Sof\u00eda |date=October 21, 2021 |title=GPT-J, an open-source alternative to GPT-3 |url=https://www.narrativa.com/gpt-j-an-open-source-alternative-to-gpt-3/ |access-date=March 31, 2023 |website=Narrativa |archive-date=March 31, 2023 |archive-url=https://web.archive.org/web/20230331004644/https://www.narrativa.com/gpt-j-an-open-source-alternative-to-gpt-3/ |url-status=live }}</ref> did release the technical details of GPT-3,<ref>{{Cite arXiv |last1=Brown |first1=Tom B. |last2=Mann |first2=Benjamin |last3=Ryder |first3=Nick |last4=Subbiah |first4=Melanie |last5=Kaplan |first5=Jared |last6=Dhariwal |first6=Prafulla |last7=Neelakantan |first7=Arvind |last8=Shyam |first8=Pranav |last9=Sastry |first9=Girish |date=May 28, 2020 |title=Language Models are Few-Shot Learners |class=cs.CL |eprint=2005.14165v4 }}</ref> OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety.<ref name=\"verge wrong\">{{Cite web |last=Vincent |first=James |date=March 15, 2023 |title=OpenAI co-founder on company's past approach to openly sharing research: \"We were wrong\" |url=https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview |url-status=live |archive-url=https://web.archive.org/web/20230317210900/https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview |archive-date=March 17, 2023 |access-date=March 18, 2023 |website=[[The Verge]] }}</ref><ref name=\"Heaven-2023\">{{Cite web |last=Heaven |first=Will Douglas |date=March 14, 2023 |title=GPT-4 is bigger and better than ChatGPT{{snd}}but OpenAI won't say why |url=https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-better-chatgpt-openai/ |url-status=live |archive-url=https://web.archive.org/web/20230317224201/https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-better-chatgpt-openai/ |archive-date=March 17, 2023 |access-date=March 18, 2023 |website=[[MIT Technology Review]] }}</ref> Sasha Luccioni, a research scientist at [[HuggingFace]], argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements.<ref>{{Cite journal |last=Sanderson |first=Katharine |date=March 16, 2023 |title=GPT-4 is here: what scientists think |url=https://www.nature.com/articles/d41586-023-00816-5 |journal=Nature |volume=615 |issue=7954 |page=773 |doi=10.1038/d41586-023-00816-5 |pmid=36928404 |bibcode=2023Natur.615..773S |s2cid=257580633 |access-date=March 18, 2023 |archive-date=March 18, 2023 |archive-url=https://web.archive.org/web/20230318031521/https://www.nature.com/articles/d41586-023-00816-5 |url-status=live }}</ref> HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".<ref name=\"Heaven-2023\" />\n\n== Usage ==\n\n===ChatGPT Plus===\n[[ChatGPT]] Plus is a GPT-4 backed version of ChatGPT<ref name=\"ars-technica\" /> available for a US$20 per month subscription fee<ref>{{Cite web |author=OpenAI |date=February 1, 2023 |title=Introducing ChatGPT Plus |url=https://openai.com/blog/chatgpt-plus |access-date=March 20, 2023 |website=OpenAI Blog |archive-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230320005603/https://openai.com/blog/chatgpt-plus |url-status=live }}</ref> (the original version is backed by GPT-3.5).<ref>{{Cite web |author=OpenAI |title=OpenAI API |url=https://platform.openai.com/ |access-date=March 20, 2023 |website=platform.openai.com |archive-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230320023933/https://platform.openai.com/ |url-status=live }}</ref> OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist;<ref>{{Cite web |author=OpenAI |title=GPT-4 API waitlist |url=https://openai.com/waitlist/gpt-4-api |access-date=March 20, 2023 |website=openai.com |archive-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230320174149/https://openai.com/waitlist/gpt-4-api |url-status=live }}</ref> after being accepted, an additional fee of US$0.03 per 1000 tokens{{technical inline|date=March 2023}} in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is required to use the version of the model with an 8192-token context window; for the 32768-token version, those prices are doubled.<ref>{{Cite web |title=Pricing |url=https://openai.com/pricing |access-date=March 20, 2023 |publisher=OpenAI |archive-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230320175036/https://openai.com/pricing |url-status=live }}</ref>\n\n===Duolingo===\n[[Duolingo]] integrated GPT-4 in their application through two new features, \"Roleplay\" and \"Explain My Answer\". The first version of this update is aimed only at English speakers who are learning French or Spanish, with plans to extend the features to other languages in the future.<ref>{{Cite web |date=March 14, 2023 |title=Introducing Duolingo Max, a learning experience powered by GPT-4 |url=https://blog.duolingo.com/duolingo-max/ |website=Duolingo Blog |access-date=March 16, 2023 |archive-date=March 16, 2023 |archive-url=https://web.archive.org/web/20230316204104/https://blog.duolingo.com/duolingo-max/ |url-status=live }}</ref>\n\n===Microsoft Bing===\n{{trim|{{#section-h:Microsoft Bing|Bing AI}}}}\n\n=== Mi\u00f0eind ehf ===\n[[Iceland]]ic start-up Mi\u00f0eind ehf, which works on [[language preservation]], was selected by OpenAI as one of six companies to participate in an early beta test program of the new model.<ref>{{Cite web |last=Smith |first=Tim |date=March 15, 2023 |title='Basically mindblowing' \u2013 What GPT-4 can do, according to one startup that's had access to it |url=https://sifted.eu/articles/testing-gpt4-ai-news/ |website=Sifted |access-date=March 16, 2023 |archive-date=March 16, 2023 |archive-url=https://web.archive.org/web/20230316235405/https://sifted.eu/articles/testing-gpt4-ai-news/ |url-status=live }}</ref>\n\n===Khan Academy===\n[[Khan Academy]] uses GPT-4 to create a tutoring chatbot, which the organization names \"Khanmigo\". While it is in the \"research phase\",<ref>{{Cite web |last=Fensterwald |first=John |date=March 20, 2023 |title=AI in school: Virtually chatting with George Washington and your personal GPT-4 tutor |url=https://edsource.org/2023/ai-in-school-virtually-chatting-with-george-washington-and-your-personal-gpt-4-tutor/687055 |access-date=March 20, 2023 |website=EdSource |archive-date=March 21, 2023 |archive-url=https://web.archive.org/web/20230321205742/https://edsource.org/2023/ai-in-school-virtually-chatting-with-george-washington-and-your-personal-gpt-4-tutor/687055 |url-status=live }}</ref> access to the chatbot is provided free to the students and teachers of 500 school districts who have \"partnered\" with Khan Academy.<ref>{{Cite web |last=Khan |first=Sal |date=March 14, 2023 |title=Harnessing GPT-4 so that all students benefit. A nonprofit approach for equal access! |url=https://blog.khanacademy.org/harnessing-ai-so-that-all-students-benefit-a-nonprofit-approach-for-equal-access/ |access-date=March 20, 2023 |website=Khan Academy Blog |archive-date=March 16, 2023 |archive-url=https://web.archive.org/web/20230316101235/https://blog.khanacademy.org/harnessing-ai-so-that-all-students-benefit-a-nonprofit-approach-for-equal-access/ |url-status=live }}</ref> Public access is only offered to a limited number of users selected from a waitlist; after acceptance, a US$20 per month fee is required to use the technology.<ref>{{Cite web |author=Khan Academy |title=Khanmigo Education AI Guide |url=https://www.khanacademy.org/khan-labs |access-date=March 20, 2023 |website=Khan Academy |archive-date=March 20, 2023 |archive-url=https://web.archive.org/web/20230320175210/https://www.khanacademy.org/khan-labs |url-status=live }}</ref> Khanmigo is also available for pupils of the Khan Lab School in Palo Alto, California.<ref>{{Cite news |last=Bonos |first=Lisa |date=April 3, 2023 |title=Say hello to your new tutor: It's ChatGPT |newspaper=[[The Washington Post]] |url=https://www.washingtonpost.com/technology/2023/04/03/chatgpt-khanmigo-tutor-silicon-valley/ |access-date=April 8, 2023 |archive-date=April 6, 2023 |archive-url=https://web.archive.org/web/20230406000927/https://www.washingtonpost.com/technology/2023/04/03/chatgpt-khanmigo-tutor-silicon-valley/ |url-status=live }}</ref>\n\n===Be My Eyes===\n[[Be My Eyes]], which helps visually impaired people to identify objects and navigate their surroundings, was the first app to incorporate GPT-4's image recognition capabilities, through a new \"Virtual Volunteer\" feature. The feature is an alternative to relying on human volunteers for the same tasks.<ref>{{Cite news |last=Coggins |first=Madeline |date=March 19, 2023 |title=CEO explains how a 'leapfrog in technology' can help companies catering to the blind community |url=https://finance.yahoo.com/news/ceo-explains-leapfrog-technology-help-110029559.html |access-date=March 20, 2023 |newspaper=Fox Business |via=Yahoo Finance |archive-date=March 21, 2023 |archive-url=https://web.archive.org/web/20230321205753/https://finance.yahoo.com/news/ceo-explains-leapfrog-technology-help-110029559.html |url-status=live }}</ref><ref>{{Cite web |last=Macaulay |first=Thomas |date=March 17, 2023 |title=New GPT-4 app can be 'life-changing |url=https://thenextweb.com/news/be-my-eyes-app-uses-openai-gpt-4-help-visually-impaired |access-date=March 20, 2023 |website=TNW |archive-date=March 17, 2023 |archive-url=https://web.archive.org/web/20230317223408/https://thenextweb.com/news/be-my-eyes-app-uses-openai-gpt-4-help-visually-impaired |url-status=live }}</ref> The ''Be My Eyes'' \"Virtual Volunteer\" is in beta testing.<ref>{{Cite web |author=BeMyEyes |date=March 14, 2023 |title=Introducing Our Virtual Volunteer Tool for People who are Blind or Have Low Vision, Powered by OpenAI's GPT-4 |url=https://www.bemyeyes.com/blog/introducing-be-my-eyes-virtual-volunteer |access-date=March 20, 2023 |website=BeMyEyes Blog |archive-date=March 16, 2023 |archive-url=https://web.archive.org/web/20230316084301/https://www.bemyeyes.com/blog/introducing-be-my-eyes-virtual-volunteer |url-status=live }}</ref>\n\n===GitHub Copilot===\n[[GitHub Copilot]] announced a GPT-4 powered assistant named \"Copilot X\".<ref>{{cite web |last1=Warren |first1=Tom |date=March 22, 2023 |title=GitHub Copilot gets a new ChatGPT-like assistant to help developers write and fix code |url=https://www.theverge.com/2023/3/22/23651456/github-copilot-x-gpt-4-code-chat-voice-support |url-status=live |archive-url=https://web.archive.org/web/20230323091831/https://www.theverge.com/2023/3/22/23651456/github-copilot-x-gpt-4-code-chat-voice-support |archive-date=March 23, 2023 |access-date=March 23, 2023 |website=[[The Verge]]}}</ref><ref>{{cite web |last1=Dohmke |first1=Thomas |date=March 22, 2023 |title=GitHub Copilot X: The AI-powered developer experience |url=https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/ |url-status=live |archive-url=https://web.archive.org/web/20230323082414/https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/ |archive-date=March 23, 2023 |access-date=March 23, 2023 |website=The GitHub Blog}}</ref> The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a [[div and span|div]]?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within [[Visual Studio Code]] and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for [[pull request]]s submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests. {{As of|2023|03|31}}, while GitHub provides access to a limited number of people selected through a waitlist, the release date as well as the cost of the product are still to be announced.<ref>{{Cite web |title=Introducing GitHub Copilot X |url=https://github.com/features/preview/copilot-x |access-date=March 24, 2023 |website=GitHub |archive-date=March 24, 2023 |archive-url=https://web.archive.org/web/20230324063035/https://github.com/features/preview/copilot-x |url-status=live }}</ref>\n\n===Microsoft 365 Copilot===\nOn March 17, 2023, Microsoft announced further integration of GPT-4 into its products, revealing [[Microsoft 365 Copilot]], \"embedded in the apps millions of people use everyday: [[Microsoft Word|Word]], [[Microsoft Excel|Excel]], [[Microsoft PowerPoint|PowerPoint]], [[Outlook.com|Outlook]], [[Microsoft Teams|Teams]], and more\".<ref>{{Cite web |last=Warren |first=Tom |date=March 16, 2023 |title=Microsoft announces Copilot: the AI-powered future of Office documents |url=https://www.theverge.com/2023/3/16/23642833/microsoft-365-ai-copilot-word-outlook-teams |url-status=live |archive-url=https://web.archive.org/web/20230317084842/https://www.theverge.com/2023/3/16/23642833/microsoft-365-ai-copilot-word-outlook-teams |archive-date=March 17, 2023 |access-date=March 17, 2023 |website=[[The Verge]]}}</ref>\n\n===Stripe===\n[[Stripe, Inc.|Stripe]] utilizes GPT-4 to help with fraud detection, and to try to improve other aspects of the user experience.<ref>{{Cite web |title=These 4 Apps Are Integrating GPT-4, but How Do They Work? |date=March 17, 2023 |url=https://www.makeuseof.com/apps-integrate-use-gpt4/ |access-date=April 3, 2023 |archive-date=April 3, 2023 |archive-url=https://web.archive.org/web/20230403171705/https://www.makeuseof.com/apps-integrate-use-gpt4/ |url-status=live }}</ref>\n\n===Auto-GPT===\n[[Auto-GPT]] is an autonomous \"AI [[Software agent|agent]]\" that given a goal in [[natural language]], can perform web-based actions unattended, assign subtasks to itself, search the web, and improve its own [[Computer code|code]].<ref>{{Cite web |date=April 14, 2023 |title=What Is Auto-GPT? Everything to Know about the Next Powerful AI Tool |url=https://www.zdnet.com/article/what-is-auto-gpt-everything-to-know-about-the-next-powerful-ai-tool/ |access-date=April 16, 2023 |publisher=ZDNET }}</ref>\n\n===1000minds===\n[[1000minds]], which is for [[decision-making software|decision-making]] and [[conjoint analysis]], released a GPT-4 powered assistant to help users quickly create criteria or attributes and examples of alternatives for their applications.<ref>{{Cite web |date=May 3, 2023 |title= Keeping humans in charge of AI decision-making |url=https://ciotechasia.com/keeping-humans-in-charge-of-ai-decision-making/ |access-date=May 17, 2023 |publisher= CIO Tech Asia}}</ref>\n\n== References ==\n{{Reflist|refs=\n<ref name=\"nyt-3\">{{Cite news\n  | url   = https://www.nytimes.com/2023/03/03/technology/artificial-intelligence-regulation-congress.html\n  | title   = As A.I. Booms, Lawmakers Struggle to Understand the Technology\n  | first   = Cecilia\n  | last   = Kang\n  | newspaper   = The New York Times\n  | date   = March 3, 2023\n| access-date   = March 3, 2023\n| archive-date  = March 3, 2023\n| archive-url   = https://web.archive.org/web/20230303100624/https://www.nytimes.com/2023/03/03/technology/artificial-intelligence-regulation-congress.html\n  | url-status   = live\n  |url-access    = limited\n}}</ref>\n<!-- unused \n<ref name=\"verge\">{{Cite web\n  | url   = https://www.theverge.com/23560328/openai-gpt-4-rumor-release-date-sam-altman-interview\n  | title   = OpenAI CEO Sam Altman on GPT-4: \"people are begging to be disappointed and they will be\"\n  | first   = James\n  | last   = Vincent\n  | date   = January 18, 2023\n| website   = The Verge\n  | access-date   = January 27, 2023\n| archive-date   = January 26, 2023\n| archive-url   = https://web.archive.org/web/20230126232257/https://www.theverge.com/23560328/openai-gpt-4-rumor-release-date-sam-altman-interview\n  | url-status   = live\n}}</ref>\n-->\n}}\n\n{{OpenAI navbox}}\n{{Differentiable computing}}\n\n[[Category:2023 software]]\n[[Category:Large language models]]\n[[Category:Generative pretrained transformer]]\n[[Category:OpenAI]]"}