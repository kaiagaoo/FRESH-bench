{"title": "Generative artificial intelligence", "page_id": 73291755, "revision_id": 1157776431, "revision_timestamp": "2023-05-30T22:03:35Z", "content": "{{short description|AI system capable of generating content in response to prompts}}\n{{distinguish|Artificial general intelligence}}\n\n'''Generative artificial intelligence''' or '''generative AI''' is a type of [[artificial intelligence]] (AI) system capable of generating text, images, or other media in response to [[Prompt engineering|prompts]].<ref name=\"nytimes\">{{Cite web|url=https://www.nytimes.com/2023/01/27/technology/anthropic-ai-funding.html|title=Anthropic Said to Be Closing In on $300 Million in New A.I. Funding|last1=Griffith|first1=Erin|last2=Metz|first2=Cade|date=2023-01-27|work=[[The New York Times]]|accessdate=2023-03-14}}</ref><ref name=\"bloomberg\">{{cite news |last1=Lanxon |first1=Nate |last2=Bass |first2=Dina |last3=Davalos |first3=Jackie |title=A Cheat Sheet to AI Buzzwords and Their Meanings |url=https://news.bloomberglaw.com/tech-and-telecom-law/a-cheat-sheet-to-ai-buzzwords-and-their-meanings-quicktake |access-date=March 14, 2023 |newspaper=Bloomberg News |date=March 10, 2023 |location=}}</ref> Generative AI models learn the patterns and structure of their input [[training data set|training data]], and then generate new data that has similar characteristics.<ref>{{Cite news |last=Pasick |first=Adam |date=2023-03-27 |title=Artificial Intelligence Glossary: Neural Networks and Other Terms Explained |language=en-US |work=The New York Times |url=https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html |access-date=2023-04-22 |issn=0362-4331}}</ref><ref>{{cite web | url=https://openai.com/research/generative-models | title=Generative models | author1=Andrej Karpathy | author2=Pieter Abbeel | author3=Greg Brockman | author4=Peter Chen | author5=Vicki Cheung | author6=Yan Duan | author7=Ian Goodfellow | author8=Durk Kingma | author9=Jonathan Ho | author10=Rein Houthooft | author11=Tim Salimans | author12=John Schulman | author13=Ilya Sutskever | author14=Wojciech Zaremba | date=2016-06-16 | website=OpenAI}}</ref>\n\nNotable generative AI systems include [[ChatGPT]] (and its variant [[Bing Chat]]), a [[chatbot]] built by [[OpenAI]] using their [[GPT-3]] and [[GPT-4]] [[foundation models|foundational]] [[large language models]],<ref name=\"nytimes-gpt4\">{{Cite news |last=Metz |first=Cade |date=2023-03-14 |title=OpenAI Plans to Up the Ante in Tech's A.I. Race |language=en-US |work=The New York Times |url=https://www.nytimes.com/2023/03/14/technology/openai-gpt4-chatgpt.html |access-date=2023-03-31 |issn=0362-4331}}</ref> and [[Bard (chatbot)|Bard]], a chatbot built by [[Google]] using their [[LaMDA]] foundation model.<ref>{{Cite arXiv |last1=Thoppilan |first1=Romal |last2=De Freitas |first2=Daniel |last3=Hall |first3=Jamie |last4=Shazeer |first4=Noam |last5=Kulshreshtha |first5=Apoorv |last6=Cheng |first6=Heng-Tze |last7=Jin |first7=Alicia |last8=Bos |first8=Taylor |last9=Baker |first9=Leslie |last10=Du |first10=Yu |last11=Li |first11=YaGuang |last12=Lee |first12=Hongrae |last13=Zheng |first13=Huaixiu Steven |last14=Ghafouri |first14=Amin |last15=Menegali |first15=Marcelo |last16=Huang |first16=Yanping |last17=Krikun |first17=Maxim |last18=Lepikhin |first18=Dmitry |last19=Qin |first19=James |last20=Chen |first20=Dehao |last21=Xu |first21=Yuanzhong |last22=Chen |first22=Zhifeng |last23=Roberts |first23=Adam |last24=Bosma |first24=Maarten |last25=Zhao |first25=Vincent |last26=Zhou |first26=Yanqi |last27=Chang |first27=Chung-Ching |last28=Krivokon |first28=Igor |last29=Rusch |first29=Will |last30=Pickett |first30=Marc |last31=Srinivasan |first31=Pranesh |last32=Man |first32=Laichee |last33=Meier-Hellstern |first33=Kathleen |last34=Ringel Morris |first34=Meredith |last35=Doshi |first35=Tulsee |last36=Delos Santos |first36=Renelito |last37=Duke |first37=Toju |last38=Soraker |first38=Johnny |last39=Zevenbergen |first39=Ben |last40=Prabhakaran |first40=Vinodkumar |last41=Diaz |first41=Mark |last42=Hutchinson |first42=Ben |last43=Olson |first43=Kristen |last44=Molina |first44=Alejandra |last45=Hoffman-John |first45=Erin |last46=Lee |first46=Josh |last47=Aroyo |first47=Lora |last48=Rajakumar |first48=Ravi |last49=Butryna |first49=Alena |last50=Lamm |first50=Matthew |last51=Kuzmina |first51=Viktoriya |last52=Fenton |first52=Joe |last53=Cohen |last54=Aaron |last55=Bernstein |first55=Rachel |last56=Kurzweil |first56=Ray |last57=Aguera-Arcas |first57=Blaise |last58=Cui |first58=Claire |last59=Croak |first59=Marian |last60=Chi |first60=Ed |last61=Le |first61=Quoc |date=January 20, 2022 |title=LaMDA: Language Models for Dialog Applications |class=cs.CL |eprint=2201.08239 <!--|url-status=live |archive-url=https://web.archive.org/web/20220121025747/https://arxiv.org/abs/2201.08239 |archive-date=January 21, 2022 |access-date=June 12, 2022-->}}</ref>\nOther generative AI models include [[artificial intelligence art]] systems such as [[Stable Diffusion]], [[Midjourney]], and [[DALL-E]].<ref>{{Cite web|last=Roose|first=Kevin|date=2022-10-21|title=A Coming-Out Party for Generative A.I., Silicon Valley's New Craze|url=https://www.nytimes.com/2022/10/21/technology/generative-ai.html|access-date=2023-03-14|website=[[The New York Times]]}}</ref>\n\nGenerative AI has potential applications across a wide range of industries, including art, writing, software development, healthcare, finance, gaming, marketing, and fashion.<ref name=\"economist2\">{{Cite web|url=https://www.economist.com/business/2023/03/06/dont-fear-an-ai-induced-jobs-apocalypse-just-yet|title=Don't fear an AI-induced jobs apocalypse just yet|date=2023-03-06|publisher=The Economist|accessdate=2023-03-14}}</ref><ref name=\"mckinsey\">{{Cite web|url=https://www.mckinsey.com/industries/retail/our-insights/generative-ai-unlocking-the-future-of-fashion|title=Generative AI: Unlocking the future of fashion|last1=Harreis|first1=H.|last2=Koullias|first2=T.|last3=Roberts|first3=Roger}}</ref>\nInvestment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models.<ref name=\"nytimes\"/><ref name=\"economist1\">{{Cite web|url=https://www.economist.com/business/2023/01/30/the-race-of-the-ai-labs-heats-up|title=The race of the AI labs heats up|date=2023-01-30|publisher=The Economist|accessdate=2023-03-14}}</ref><ref>{{Cite web|url=https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-for-businesses-and-governments|title=Google Cloud brings generative AI to developers, businesses, and governments|last1=Yang|first1=June|last2=Gokturk|first2=Burak|date=2023-03-14}}</ref> However, there are also concerns about the potential misuse of generative AI, such as in creating [[fake news]] or [[deepfake]]s, which can be used to deceive or manipulate people.<ref>{{cite web |title=Transcript: Senate Judiciary Subcommittee Hearing on Oversight of AI |url=https://techpolicy.press/transcript-senate-judiciary-subcommittee-hearing-on-oversight-of-ai/ |website=techpolicy.press |author=Justin Hendrix |date=May 16, 2023 |access-date=May 19, 2023}}</ref>\n\n==History==\n{{main|History of artificial intelligence}}\n\nSince its founding, the field of [[machine learning]] has used [[statistical models]], including [[Generative_model|generative models]], to model and predict data. Beginning in the late 2000s, the emergence of [[deep learning]] drove progress and research in image and video processing, text analysis, speech recognition, and other tasks. However, most deep neural networks were trained as [[Discriminative_model|discriminative]] models performing classification tasks such as [[Convolutional_neural_network|convolutional neural network]]-based [[Image_classification|image classification]].\n\nIn 2014, advancements such as the [[variational autoencoder]] and [[generative adversarial network]] produced the first practical deep neural networks capable of learning generative, rather than discriminative, models of complex data such as images. These deep generative models were the first able to output not only class labels for images, but to output entire images.\n\nIn 2017, the [[Transformer_(machine_learning_model)|Transformer]] network enabled advancements in generative models, leading to the first [[Generative pre-trained transformer]] in 2018.<ref>{{cite web|url=https://github.com/openai/finetune-transformer-lm|title=finetune-transformer-lm|website=GitHub|access-date=2023-05-19}}</ref> This was followed in 2019 by [[GPT-2]] which demonstrated the ability to generalize unsupervised to many different tasks as a [[Foundation models|Foundation model]].<ref>{{Cite journal|author=Radford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David; Amodei, Dario; Sutskever, Ilya; others|title=Language models are unsupervised multitask learners|journal=OpenAI blog|volume=1|issue=8|pages=9|year=2019}}</ref>\n\nIn 2021, the release of [[DALL-E]], a transformer-based pixel generative model, followed by [[Midjourney]] and [[Stable Diffusion]] marked the emergence of practical high quality [[artificial intelligence art]] from natural language prompts.\n\nIn 2023, [[GPT-4]] was released. A team from Microsoft Research concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an [[artificial general intelligence]] (AGI) system\".<ref name=\"Bubeck-2023\">{{Cite arXiv|title=Sparks of Artificial General Intelligence: Early experiments with GPT-4|first1=S\u00e9bastien|last1=Bubeck|first2=Varun|last2=Chandrasekaran|first3=Ronen|last3=Eldan|first4=Johannes|last4=Gehrke|first5=Eric|last5=Horvitz|first6=Ece|last6=Kamar|first7=Peter|last7=Lee|first8=Yin Tat|last8=Lee|first9=Yuanzhi|last9=Li|first10=Scott|last10=Lundberg|first11=Harsha|last11=Nori|first12=Hamid|last12=Palangi|first13=Marco Tulio|last13=Ribeiro|first14=Yi|last14=Zhang|date=March 22, 2023|class=cs.CL |eprint=2303.12712}}</ref>\n\n==Modalities==\n[[File:Th\u00e9\u00e2tre d'Op\u00e9ra Spatial.webp|thumb|[[Th\u00e9\u00e2tre d'Op\u00e9ra Spatial]], an image generated by [[Midjourney]]|alt=A detailed oil painting of figures in a futuristic opera scene]]\nA generative AI system is constructed by applying [[Unsupervised learning|unsupervised]] or [[Self-supervised learning|self-supervised]] [[machine learning]] to a data set. The capabilities of a generative AI system depend on the [[List of datasets for machine-learning research|modality or type]] of the data set used.\n\nGenerative AI can be either ''unimodal'' or [[Multimodal_learning|''multimodal'']]; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.<ref>https://www.marktechpost.com/2023/03/21/a-history-of-generative-ai-from-gan-to-gpt-4/</ref> For example, one version of [[OpenAI]]'s [[GPT-4]] accepts both text and image inputs.<ref>{{cite news |title=Explainer: What is Generative AI, the technology behind OpenAI's ChatGPT? |url=https://www.reuters.com/technology/what-is-generative-ai-technology-behind-openais-chatgpt-2023-03-17/ |work=Reuters |date=March 17, 2023 |access-date=March 17, 2023}}</ref>\n\n* '''Text''': Generative AI systems trained on words or [[Lexical analysis#Tokenization|word tokens]] include [[GPT-3]], [[LaMDA]], [[LLaMA]], [[BLOOM (language model)|BLOOM]], [[GPT-4]], and others (see [[Large language model#List of large language models|List of large language models]]). They are capable of [[natural language processing]], [[machine translation]], and [[natural language generation]] and can be used as [[foundation models]] for other tasks.<ref name=\"FoundationModels\">{{Cite arXiv |last1=Bommasani |first1=R |last2=Hudson |first2=DA |last3=Adeli |first3=E |last4=Altman |first4=R |last5=Arora |first5=S |last6=von Arx |first6=S |last7=Bernstein |first7=MS |last8=Bohg |first8=J |last9=Bosselut |first9=A |last10=Brunskill |first10=E |last11=Brynjolfsson |first11=E |title=On the opportunities and risks of foundation models |year=2021 |date=2021-08-16 |class=cs.LG |eprint=2108.07258 }}</ref> Data sets include [[BookCorpus]], [[Wikipedia]], and others (see [[List of text corpora]]).\n* '''Code''': In addition to [[natural language]] text, large language models can be trained on [[programming language]] text, allowing them to generate [[source code]] for new [[computer programs]].<ref>{{cite arXiv | last1=Chen | first1=Ming | last2=Tworek | first2=Jakub | last3=Jun | first3=Hongyu | last4=Yuan | first4=Qinyuan | last5=Pinto | first5=Hanyu Philippe De Oliveira | last6=Kaplan | first6=Jerry | last7=Edwards | first7=Haley | last8=Burda | first8=Yannick | last9=Joseph | first9=Nicholas | last10=Brockman | first10=Greg | last11=Ray | first11=Alvin | title=Evaluating Large Language Models Trained on Code | date=2021-07-06 | class=cs.LG | eprint=2107.03374}}</ref> Examples include [[OpenAI Codex]].\n* '''Images''': Generative AI systems trained on sets of images with [[Caption (text)|text captions]] include [[Google Brain|Imagen]], [[DALL-E]], [[Midjourney]], [[Stable Diffusion]] and others (see [[Artificial intelligence art]], [[Generative art]], [[Synthetic media]]). They are commonly used for [[Text-to-image model|text-to-image]] generation and [[neural style transfer]].<ref name=\"ZeroShotTextToImage\">{{Cite conference |last1=Ramesh |first1=Aditya |last2=Pavlov |first2=Mikhail |last3=Goh |first3=Gabriel |last4=Gray |first4=Scott |last5=Voss |first5=Chelsea |last6=Radford |first6=Alec |last7=Chen |first7=Mark |last8=Sutskever |first8=Ilya |title=Zero-shot text-to-image generation |book-title=International Conference on Machine Learning |pages=8821\u20138831 |year=2021 |publisher=PMLR }}</ref> Datasets include [[LAION|LAION-5B]] and others (See [[:Category:Datasets in computer vision|Datasets in computer vision]]).\n* '''Molecules''': Generative AI systems can be trained on sequences of [[amino acids]] or molecular representations such as [[Simplified molecular-input line-entry system|SMILES]] representing DNA or proteins. These systems, such as [[AlphaFold]], are used for [[protein structure prediction]] and [[drug discovery]].<ref name=\"MITTechReview-AI-Automation\">{{Cite web |last=Heaven |first=Will Douglas |title=AI is dreaming up drugs that no one has ever seen. Now we've got to see if they work |url=https://www.technologyreview.com/2023/02/15/1067904/ai-automation-drug-development/ |website=MIT Technology Review |publisher=Massachusetts Institute of Technology |date=2023-02-15 |access-date=2023-03-15 }}</ref> Datasets include [[List of biological databases|various biological datasets]].\n* '''Music''': Generative AI systems such as MusicLM can be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as ''a calming violin melody backed by a distorted guitar riff''.<ref>{{cite arXiv|last1=Agostinelli|first1=Andrea|last2=Denk|first2=Timo I.|last3=Borsos|first3=Zal\u00e1n|last4=Engel|first4=Jesse|last5=Verzetti|first5=Mauro|last6=Caillon|first6=Antoine|last7=Huang|first7=Qingqing|last8=Jansen|first8=Aren|last9=Roberts|first9=Adam|last10=Tagliasacchi|first10=Marco|last11=Sharifi|first11=Matt|last12=Zeghidour|first12=Neil|last13=Frank|first13=Christian|title=MusicLM: Generating Music From Text|eprint=2301.11325|date=26 January 2023|class=cs.SD }}</ref>\n* '''Video''': Generative AI trained on annotated video can generate temporally-coherent video clips. Examples include Gen1 by RunwayML<ref>{{cite web|last=Metz|first=Cade|title=Instant Videos Could Represent the Next Leap in A.I. Technology|url=https://www.nytimes.com/2023/04/04/technology/runway-ai-videos.html|website=The New York Times|date=April 4, 2023|language=en}}</ref> and Make-A-Video by [[Meta Platforms]].<ref>{{cite web|url=https://www.cnet.com/news/social-media/facebook-parent-metas-ai-tool-can-create-artsy-videos-from-text/|title=Facebook Parent Meta's AI Tool Can Create Artsy Videos From Text|author=Queenie Wong|date=Sep 29, 2022|publisher=cnet.com|accessdate=Apr 4, 2023}}</ref>\n* '''Robot Actions''': Generative AI trained on the motions of a robotic system can generate new trajectories for [[motion planning]]. For example, UniPi from Google Research uses prompts like ''pick up blue bowl'' or ''wipe plate with yellow sponge'' to control movements of a robot arm.<ref>{{cite web|url=https://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html|title=UniPi: Learning universal policies via text-guided video generation|date=2023-04-12|author=Sherry Yang, Yilun Du|work=Google Research, Brain Team|publisher=Google AI Blog|access-date=}}</ref>\n\n==See also==\n* {{annotated link|Computational creativity}}\n* {{annotated link|Artificial general intelligence}}\n* {{annotated link|Artificial imagination}}\n* {{annotated link|Artificial intelligence art}}\n* {{annotated link|Music and artificial intelligence}}\n* {{annotated link|Generative adversarial network}}\n* {{annotated link|Generative pre-trained transformer}}\n* {{annotated link|Large language model}}\n\n==References==\n{{Reflist}}\n\n[[Category:Artificial intelligence]]\n[[Category:Artificial neural networks]]\n[[Category:Deep learning]]\n[[Category:Emerging technologies]]\n[[Category:Machine learning]]"}