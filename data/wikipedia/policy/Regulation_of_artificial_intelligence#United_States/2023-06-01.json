{"title": "Regulation of artificial intelligence", "page_id": 63451675, "revision_id": 1156047250, "revision_timestamp": "2023-05-20T23:30:17Z", "content": "{{Short description|none}} <!-- This short description is INTENTIONALLY \"none\" - please see WP:SDNONE before you consider changing it! -->\n{{Computing law}}\nThe '''regulation of artificial intelligence''' is the development of public sector [[Policy|policies]] and laws for promoting and regulating [[artificial intelligence]] (AI); it is therefore related to the broader [[regulation of algorithms]].<ref>{{cite journal |last1=Nemitz |first1=Paul |title=Constitutional democracy and technology in the age of artificial intelligence |journal=[[Philosophical Transactions of the Royal Society A|Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences]] |date=2018 |volume=376 |issue=2133 |pages=20180089 |doi=10.1098/rsta.2018.0089 |pmid=30323003 |bibcode=2018RSPTA.37680089N |doi-access=free}}</ref><ref>{{cite journal |last1=Cath |first1=Corinne |title=Governing artificial intelligence: ethical, legal and technical opportunities and challenges |journal=[[Philosophical Transactions of the Royal Society A|Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences]] |date=2018 |volume=376 |issue=2133 |pages=20180080 |doi=10.1098/rsta.2018.0080 |pmid=30322996 |pmc=6191666 |bibcode=2018RSPTA.37680080C |doi-access=free}}</ref><ref>{{cite journal |last1=Buiten |first1=Miriam C. |title=Towards Intelligent Regulation of Artificial Intelligence |journal=European Journal of Risk Regulation |date=2019 |volume=10 |issue=1 |pages=41\u201359 |doi=10.1017/err.2019.8 |doi-access=free}}</ref><ref>{{cite arXiv |eprint=2005.11072 |first1=Olivia J. |last1=Erd\u00e9lyi |first2=Judy |last2=Goldsmith |title=Regulating Artificial Intelligence: Proposal for a Global Solution |date=2020|class=cs.CY }}</ref>  The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally, including in the [[European Union]] and in supra-national bodies like the [[IEEE]], [[OECD]] and others. Since 2016, a wave of AI ethics guidelines have been published in order to maintain social control over the technology.<ref>{{cite journal |last1=H\u00e9der |first1=M |title=A criticism of AI ethics guidelines |journal=Inform\u00e1ci\u00f3s T\u00e1rsadalom |date=2020 |volume=20 |issue=4 |pages=57\u201373 |doi=10.22503/inftars.XX.2020.4.5|s2cid=233252939 }}</ref> Regulation is considered necessary to both encourage AI and manage associated risks. In addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI,<ref>{{cite web |date=2019 |title=European Commission.: Ethics guidelines for trustworthy AI. EC HLEG |url=https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai}}</ref> and take accountability to mitigate the risks.<ref>{{Cite journal |last1=Curtis |first1=Caitlin |last2=Gillespie |first2=Nicole |last3=Lockey |first3=Steven |date=2022-05-24 |title=AI-deploying organizations are key to addressing 'perfect storm' of AI risks |url=https://doi.org/10.1007/s43681-022-00163-7 |journal=AI and Ethics |volume=3 |issue=1 |pages=145\u2013153 |language=en |doi=10.1007/s43681-022-00163-7 |pmid=35634256 |issn=2730-5961 |pmc=9127285}}</ref> Regulation of AI through mechanisms such as review boards can also be seen as social means to approach the [[AI control problem]].<ref>{{cite news|title=An Ethical Approach to AI is an Absolute Imperative, Andreas Kaplan|language=en|url=https://olbios.org/an-ethical-approach-to-ai-is-an-absolute-imperative/|access-date=26 April 2021}}</ref><ref>{{Cite journal |last1=Sotala|first1=Kaj|last2=Yampolskiy|first2=Roman V |date=2014-12-19|title=Responses to catastrophic AGI risk: a survey|journal=Physica Scripta |volume=90|issue=1|page=018001|doi=10.1088/0031-8949/90/1/018001 |issn=0031-8949|doi-access=free}}</ref>\n\n== Background ==\nIn 2017 [[Elon Musk]] called for regulation of AI development.<ref name=\":0\">{{cite news|title=Elon Musk Warns Governors: Artificial Intelligence Poses 'Existential Risk'|language=en|work=NPR.org|url=https://www.npr.org/sections/thetwo-way/2017/07/17/537686649/elon-musk-warns-governors-artificial-intelligence-poses-existential-risk|access-date=27 November 2017}}</ref> According to [[National Public Radio|NPR]], the [[Tesla, Inc.|Tesla]] CEO was \"clearly not thrilled\" to be advocating for government scrutiny that could impact his own industry, but believed the risks of going completely without oversight are too high: \"Normally the way regulations are set up is when a bunch of bad things happen, there's a public outcry, and after many years a regulatory agency is set up to regulate that industry. It takes forever. That, in the past, has been bad but not something which represented a fundamental risk to the existence of civilization.\"<ref name=\":0\" /> In response, some politicians expressed skepticism about the wisdom of regulating a technology that is still in development.<ref>{{cite news|last1=Gibbs|first1=Samuel|date=17 July 2017|title=Elon Musk: regulate AI to combat 'existential threat' before it's too late|work=The Guardian|url=https://www.theguardian.com/technology/2017/jul/17/elon-musk-regulation-ai-combat-existential-threat-tesla-spacex-ceo|access-date=27 November 2017}}</ref> Responding both to Musk and to February 2017 proposals by European Union lawmakers to regulate AI and robotics, Intel CEO [[Brian Krzanich]] has argued that AI is in its infancy and that it is too early to regulate the technology.<ref name=\"cnbc\">{{cite news|last1=Kharpal|first1=Arjun|date=7 November 2017|title=A.I. is in its 'infancy' and it's too early to regulate it, Intel CEO Brian Krzanich says|work=CNBC|url=https://www.cnbc.com/2017/11/07/ai-infancy-and-too-early-to-regulate-intel-ceo-brian-krzanich-says.html|access-date=27 November 2017}}</ref> Instead of trying to regulate the technology itself, some scholars suggested developing common norms including requirements for the testing and transparency of algorithms, possibly in combination with some form of warranty.<ref>{{cite journal|last1=Kaplan|first1=Andreas|last2=Haenlein|first2=Michael|year=2019|title=Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence|journal=Business Horizons|volume=62|pages=15\u201325|doi=10.1016/j.bushor.2018.08.004|s2cid=158433736 }}</ref>\n\n== Perspectives ==\nThe regulation of artificial intelligences is the development of public sector policies and laws for promoting and regulating AI.<ref>{{Cite book|title=Research handbook on the law of artificial intelligence|last1=Barfield|first1= Woodrow|last2= Pagallo|first2= Ugo|year = 2018|isbn=978-1-78643-904-8|location=Cheltenham, UK|oclc=1039480085}}</ref> Regulation is now generally considered necessary to both encourage AI and manage associated risks.<ref name=\"zenodo.org\">{{Cite journal|last1=Wirtz|first1=Bernd W.|last2=Weyerer|first2=Jan C.|last3=Geyer|first3=Carolin|s2cid=158829602|date=2018-07-24|title=Artificial Intelligence and the Public Sector\u2014Applications and Challenges|journal=International Journal of Public Administration|volume=42|issue=7|pages=596\u2013615|doi=10.1080/01900692.2018.1498103|issn=0190-0692|url=https://zenodo.org/record/3569435}}</ref><ref>{{Cite journal|last=Buiten|first=Miriam C|date=2019|title=Towards Intelligent Regulation of Artificial Intelligence|journal=European Journal of Risk Regulation|volume=10|issue=1|pages=41\u201359|doi=10.1017/err.2019.8|issn=1867-299X|doi-access=free}}</ref><ref>{{Cite journal|last1=Mantelero|first1=Alessandro|last2=Esposito|first2=Maria Samantha|date=2021|title=An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems|url=https://linkinghub.elsevier.com/retrieve/pii/S0267364921000340|journal=Computer Law & Security Review|language=en|volume=41|page=105561|doi=10.1016/j.clsr.2021.105561| issn=0267-3649|s2cid=237588123}}</ref> Public administration and policy considerations generally focus on the technical and economic implications and on trustworthy and human-centered AI systems,<ref name=\"aiis\">{{Cite book|title=Artificial intelligence in society.|publisher=Organisation for Economic Co-operation and Development.|date = 11 June 2019|isbn=978-92-64-54519-9|location=Paris|oclc=1105926611}}</ref> although regulation of artificial [[superintelligence]]s is also considered.<ref>{{Citation|last1=Kamyshansky|first1=Vladimir P.|title=Revisiting the Place of Artificial Intelligence in Society and the State|date=2020|work=Artificial Intelligence: Anthropogenic Nature vs. Social Origin|pages=359\u2013364|place=Cham|publisher=Springer International Publishing|isbn=978-3-030-39318-2|last2=Rudenko|first2=Evgenia Y.|last3=Kolomiets|first3=Evgeniy A.|last4=Kripakova|first4=Dina R.|doi=10.1007/978-3-030-39319-9_41|s2cid=213070224}}</ref> The basic approach to regulation focuses on the risks and biases of AI's underlying technology, i.e., machine-learning algorithms, at the level of the input data, algorithm testing, and the decision model, as well as whether explanations of biases in the code can be understandable for prospective recipients of the technology, and technically feasible for producers to convey.<ref>{{Cite journal|last=BUITEN|first=Miriam C|date=2019|title=Towards Intelligent Regulation of Artificial Intelligence|url=http://dx.doi.org/10.1017/err.2019.8|journal=European Journal of Risk Regulation|volume=10|issue=1|pages=41\u201359|doi=10.1017/err.2019.8|s2cid=155138874|issn=1867-299X}}</ref>\n\nThere have been both [[hard law]] and [[soft law]] proposals to regulate AI.<ref>{{cite journal |title=Special Issue on Soft Law Governance of Artificial Intelligence: IEEE Technology and Society Magazine publication information |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=C2 |doi=10.1109/MTS.2021.3126194 |url=https://doi.org/10.1109/MTS.2021.3126194}}</ref> Some legal scholars have noted that hard law approaches to AI regulation have substantial challenges.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref><ref>{{cite journal |last1=Johnson |first1=Walter G. |last2=Bowman |first2=Diana M. |title=A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=68\u201376 |doi=10.1109/MTS.2021.3123745|s2cid=245053179 }}</ref> Among the challenges, AI technology is rapidly evolving leading to a \"pacing problem\" where traditional laws and regulations often cannot keep up with emerging applications and their associated risks and benefits.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref><ref>{{cite journal |last1=Johnson |first1=Walter G. |last2=Bowman |first2=Diana M. |title=A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=68\u201376 |doi=10.1109/MTS.2021.3123745|s2cid=245053179 }}</ref> Some legal scholars have noted that hard law approaches to AI regulation have substantial challenges.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref><ref>{{cite journal |last1=Johnson |first1=Walter G. |last2=Bowman |first2=Diana M. |title=A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=68\u201376 |doi=10.1109/MTS.2021.3123745|s2cid=245053179 }}</ref> Similarly, the diversity of AI applications challenges existing regulatory agencies, which often have limited jurisdictional scope.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref> As an alternative, some legal scholars argue that soft law approaches to AI regulation are promising because soft laws can be adapted more flexibly to meet the needs of emerging and evolving AI technology and nascent applications.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref><ref>{{cite journal |last1=Johnson |first1=Walter G. |last2=Bowman |first2=Diana M. |title=A Survey of Instruments and Institutions Available for the Global Governance of Artificial Intelligence |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=68\u201376 |doi=10.1109/MTS.2021.3123745|s2cid=245053179 }}</ref> However, soft law approaches often lack substantial enforcement potential.<ref>{{cite web |last1=Marchant |first1=Gary |title=\"Soft Law\" Governance of AI |url=https://escholarship.org/content/qt0jq252ks/qt0jq252ks.pdf |website=AI Pulse |publisher=AI PULSE Papers |access-date=28 February 2023}}</ref><ref>{{cite journal |last1=Sutcliffe |first1=Hillary R. |last2=Brown |first2=Samantha |title=Trust and Soft Law for AI |journal=IEEE Technology and Society Magazine |date=December 2021 |volume=40 |issue=4 |pages=14\u201324 |doi=10.1109/MTS.2021.3123741|s2cid=244955938 }}</ref>\n\nCason Schmit, Megan Doerr, and Jennifer Wagner proposed the creation of a quasi-governmental regulator by leveraging intellectual property rights (i.e., [[copyleft]] licensing) in certain AI objects (i.e., AI models and training datasets) and delegating enforcement rights to a designated enforcement entity.<ref>{{cite journal |last1=Schmit |first1=C. D. |last2=Doerr |first2=M. J. |last3=Wagner |first3=J. K. |title=Leveraging IP for AI governance |journal=Science |date=17 February 2023 |volume=379 |issue=6633 |pages=646\u2013648 |doi=10.1126/science.add2202|pmid=36795826 |bibcode=2023Sci...379..646S |s2cid=256901479 }}</ref>  They argue that AI can be licensed under terms that require adherence to specified ethical practices and codes of conduct. (e.g., soft law principles).<ref>{{cite journal |last1=Schmit |first1=C. D. |last2=Doerr |first2=M. J. |last3=Wagner |first3=J. K. |title=Leveraging IP for AI governance |journal=Science |date=17 February 2023 |volume=379 |issue=6633 |pages=646\u2013648 |doi=10.1126/science.add2202|pmid=36795826 |bibcode=2023Sci...379..646S |s2cid=256901479 }}</ref>\n\nAI regulation could derive from basic principles. A 2020 Berkman Klein Center for Internet & Society meta-review of existing sets of principles, such as the Asilomar Principles and the Beijing Principles, identified eight such basic principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and respect for human values.<ref>{{Cite document|publisher=Berkman Klein Center for Internet & Society|last1=Fjeld|first1=Jessica|last2=Achten|first2=Nele|last3=Hilligoss|first3=Hannah|last4=Nagy|first4=Adam|last5=Srikumar|first5=Madhu|date=2020-01-15|title=Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-based Approaches to Principles for AI|url=https://dash.harvard.edu/handle/1/42160420|language=en-US}}</ref> AI law and regulations have been divided into three main topics, namely governance of autonomous intelligence systems, responsibility and accountability for the systems, and privacy and safety issues.<ref name=\"zenodo.org\" /> A public administration approach sees a relationship between AI law and regulation, the [[Ethics of artificial intelligence|ethics of AI]], and 'AI society', defined as workforce substitution and transformation, social acceptance and trust in AI, and the transformation of human to machine interaction.<ref>{{Cite journal|last1=Wirtz|first1=Bernd W.|last2=Weyerer|first2=Jan C.|last3=Sturm|first3=Benjamin J.|s2cid=218807452|date=2020-04-15|title=The Dark Sides of Artificial Intelligence: An Integrated AI Governance Framework for Public Administration|journal=International Journal of Public Administration|volume=43|issue=9|pages=818\u2013829|doi=10.1080/01900692.2020.1749851|issn=0190-0692}}</ref> The development of public sector strategies for management and regulation of AI is deemed necessary at the local, national,<ref name=\"aifs\">{{Cite journal|last=Bredt|first=Stephan|date=2019-10-04|title=Artificial Intelligence (AI) in the Financial Sector\u2014Potential and Public Strategies|journal=Frontiers in Artificial Intelligence|volume=2|page=16|doi=10.3389/frai.2019.00016|pmid=33733105|pmc=7861258|issn=2624-8212|doi-access=free}}</ref> and international levels<ref name=\":12\">{{Cite book|url=https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf|title=White Paper: On Artificial Intelligence \u2013 A European approach to excellence and trust|publisher=European Commission|year=2020|location=Brussels|page=1}}</ref> and in a variety of fields, from public service management<ref>{{Cite journal|last1=Wirtz|first1=Bernd W.|last2=M\u00fcller|first2=Wilhelm M.|s2cid=158267709|date=2018-12-03|title=An integrated artificial intelligence framework for public management|journal=Public Management Review|volume=21|issue=7|pages=1076\u20131100|doi=10.1080/14719037.2018.1549268|issn=1471-9037}}</ref> and accountability<ref>{{Cite book|last1=Reisman|first1=Dillon|url=https://ainowinstitute.org/aiareport2018.pdf|title=Algorithmic impact assessments: A practical framework for public agency accountability|last2=Schultz|first2=Jason|last3=Crawford|first3=Kate|last4=Whittaker|first4=Meredith|publisher=AI Now Institute|year=2018|location=New York}}</ref> to law enforcement,<ref name=\":12\" /><ref>{{cite web|date=2020|title=Towards Responsible Artificial Intelligence Innovation|url=http://www.unicri.it/sites/default/files/2020-07/UNICRI-INTERPOL_Report_Towards_Responsible_AI_Innovation_0.pdf|access-date=2020-08-09|website=UNICRI}}</ref> healthcare (especially the concept of a Human Guarantee),<ref name=\":14\">{{Cite journal|last1=Kohli|first1=Ajay|last2=Mahajan|first2=Vidur|last3=Seals|first3=Kevin|last4=Kohli|first4=Ajit|last5=Jha|first5=Saurabh|date=2019|title=Concepts in U.S. Food and Drug Administration Regulation of Artificial Intelligence for Medical Imaging|url=http://dx.doi.org/10.2214/ajr.18.20410|journal=American Journal of Roentgenology|volume=213|issue=4|pages=886\u2013888|doi=10.2214/ajr.18.20410|pmid=31166758|s2cid=174813195|issn=0361-803X}}</ref><ref>{{Cite journal|last1=Hwang|first1=Thomas J.|last2=Kesselheim|first2=Aaron S.|last3=Vokinger|first3=Kerstin N.|date=2019-12-17|title=Lifecycle Regulation of Artificial Intelligence\u2013 and Machine Learning\u2013Based Software Devices in Medicine|url=http://dx.doi.org/10.1001/jama.2019.16842|journal=JAMA|volume=322|issue=23|pages=2285\u20132286|doi=10.1001/jama.2019.16842|pmid=31755907|s2cid=208230202|issn=0098-7484}}</ref><ref>{{Cite journal|last1=Sharma|first1=Kavita|last2=Manchikanti|first2=Padmavati|date=2020-10-01|title=Regulation of Artificial Intelligence in Drug Discovery and Health Care|url=http://dx.doi.org/10.1089/blr.2020.29183.ks|journal=Biotechnology Law Report|volume=39|issue=5|pages=371\u2013380|doi=10.1089/blr.2020.29183.ks|s2cid=225540889|issn=0730-031X}}</ref><ref>{{Cite journal|last1=Petkus|first1=Haroldas|last2=Hoogewerf|first2=Jan|last3=Wyatt|first3=Jeremy C|date=2020|title=What do senior physicians think about AI and clinical decision support systems: Quantitative and qualitative analysis of data from specialty societies|url= |journal=Clinical Medicine|volume=20|issue=3|pages=324\u2013328|doi=10.7861/clinmed.2019-0317|pmid=32414724|pmc=7354034|issn=1470-2118}}</ref><ref>{{Cite journal |last1=Cheng |first1=Jerome Y. |last2=Abel |first2=Jacob T. |last3=Balis |first3=Ulysses G.J. |last4=McClintock |first4=David S. |last5=Pantanowitz |first5=Liron |date=2021 |title=Challenges in the Development, Deployment, and Regulation of Artificial Intelligence in Anatomic Pathology |url=http://dx.doi.org/10.1016/j.ajpath.2020.10.018 |journal=The American Journal of Pathology |volume=191 |issue=10 |pages=1684\u20131692 |doi=10.1016/j.ajpath.2020.10.018 |pmid=33245914 |s2cid=227191875 |issn=0002-9440}}</ref> the financial sector,<ref name=\"aifs\" /> robotics,<ref name=\":13\">{{Cite journal|last1=Gurkaynak|first1=Gonenc|last2=Yilmaz|first2=Ilay|last3=Haksever|first3=Gunes|date=2016|title=Stifling artificial intelligence: Human perils|journal=Computer Law & Security Review|volume=32|issue=5|pages=749\u2013758|doi=10.1016/j.clsr.2016.05.003|issn=0267-3649}}</ref><ref>{{Cite journal|last1=Iphofen|first1=Ron|last2=Kritikos|first2=Mihalis|date=2019-01-03|title=Regulating artificial intelligence and robotics: ethics by design in a digital society|journal=Contemporary Social Science|volume=16|issue=2|pages=170\u2013184|doi=10.1080/21582041.2018.1563803|s2cid=59298502|issn=2158-2041}}</ref> autonomous vehicles,<ref name=\":13\" /> the military<ref>{{Cite book|url=https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB_AI_PRINCIPLES_PRIMARY_DOCUMENT.PDF|title=AI principles: Recommendations on the ethical use of artificial intelligence by the Department of Defense|publisher=United States Defense Innovation Board|year=2019|location=Washington, DC|oclc=1126650738}}</ref> and national security,<ref name=\"babupol\">{{Cite book|last1=Babuta|first1=Alexander|url=https://rusi.org/sites/default/files/ai_national_security_final_web_version.pdf|title=Artificial Intelligence and UK National Security: Policy Considerations|last2=Oswald|first2=Marion|last3=Janjeva|first3=Ardi|publisher=Royal United Services Institute|year=2020|location=London|access-date=2020-04-28|archive-date=2020-05-02|archive-url=https://web.archive.org/web/20200502044604/https://rusi.org/sites/default/files/ai_national_security_final_web_version.pdf|url-status=dead}}</ref> and international law.<ref name=\"rwg\">{{cite news|url=https://www.snopes.com/2017/04/21/robots-with-guns/|title=Robots with Guns: The Rise of Autonomous Weapons Systems|date=21 April 2017|work=Snopes.com|access-date=24 December 2017}}</ref><ref>{{Cite journal|url=https://dash.harvard.edu/handle/1/33813394|title=No Mere Deodands: Human Responsibilities in the Use of Violent Intelligent Systems Under Public International Law|last=Bento|first=Lucas|date=2017|website=Harvard Scholarship Depository|access-date=2019-09-14}}</ref>\n\n[[Henry Kissinger]], [[Eric Schmidt]], and [[Daniel P. Huttenlocher|Daniel Huttenlocher]] published an joint statement in November 2021 entitled \"Being Human in an Age of AI\", calling for a government commission to regulate AI.<ref>{{Cite news|last=Kissinger|first=Henry|author-link=Henry Kissinger|date=1 November 2021|title=The Challenge of Being Human in the Age of AI|work=[[The Wall Street Journal]]|url=https://www.wsj.com/articles/being-human-artifical-intelligence-ai-chess-antibiotic-philosophy-ethics-bill-of-rights-11635795271}}</ref>\n\n=== As a response to the AI control problem ===\n{{main article|AI control problem}}\nRegulation of AI can be seen as positive social means to manage the [[AI control problem]], i.e., the need to insure long-term beneficial AI, with other social responses such as doing nothing or banning being seen as impractical, and approaches such as enhancing human capabilities through [[transhumanism]] techniques like [[Brain\u2013computer interface|brain-computer interfaces]] being seen as potentially complementary.<ref name=\"ragi\">{{Cite journal|last1=Sotala|first1=Kaj|last2=Yampolskiy|first2=Roman V|date=2014-12-19|title=Responses to catastrophic AGI risk: a survey|journal=Physica Scripta|volume=90|issue=1|page=018001|doi=10.1088/0031-8949/90/1/018001|issn=0031-8949|doi-access=free}}</ref><ref name=\"mpat\">{{Cite journal|last1=Barrett|first1=Anthony M.|last2=Baum|first2=Seth D.|date=2016-05-23|title=A model of pathways to artificial superintelligence catastrophe for risk and decision analysis|journal=Journal of Experimental & Theoretical Artificial Intelligence|volume=29|issue=2|pages=397\u2013414|arxiv=1607.07730|doi=10.1080/0952813x.2016.1186228|issn=0952-813X|s2cid=928824}}</ref> Regulation of research into [[artificial general intelligence]] (AGI) focuses on the role of review boards, from university or corporation to international levels, and on encouraging research into safe AI,<ref name=\"mpat\" /> together with the possibility of differential intellectual progress (prioritizing risk-reducing strategies over risk-taking strategies in AI development) or conducting international mass surveillance to perform AGI arms control.<ref name=\"ragi\" /> For instance, the 'AGI Nanny' is a proposed strategy, potentially under the control of humanity, for preventing the creation of a dangerous [[superintelligence]] as well as for addressing other major threats to human well-being, such as subversion of the global financial system, until a true superintelligence can be safely created. It entails the creation of a smarter-than-human, but not superintelligent, AGI system connected to a large surveillance network, with the goal of monitoring humanity and protecting it from danger.\"<ref name=\"ragi\" /> Regulation of conscious, ethically aware AGIs focuses on integrating them with existing human society and can be divided into considerations of their legal standing and of their moral rights.<ref name=\"ragi\" /> Regulation of AI has been seen as restrictive, with a risk of preventing the development of AGI.<ref name=\":13\" />\n\n== Global guidance ==\nThe development of a global governance board to regulate AI development was suggested at least as early as 2017.<ref>{{Cite journal|last1=Boyd|first1=Matthew|last2=Wilson|first2=Nick|date=2017-11-01|title=Rapid developments in Artificial Intelligence: how might the New Zealand government respond?|journal=Policy Quarterly|volume=13|issue=4|doi=10.26686/pq.v13i4.4619|issn=2324-1101|doi-access=free}}</ref> In December 2018, Canada and France announced plans for a G7-backed International Panel on Artificial Intelligence, modeled on the [[Intergovernmental Panel on Climate Change|International Panel on Climate Change]], to study the global effects of AI on people and economies and to steer AI development.<ref>{{cite web|url=https://www.canada.ca/en/innovation-science-economic-development/news/2019/05/declaration-of-the-international-panel-on-artificial-intelligence.html|title=Declaration of the International Panel on Artificial Intelligence|last=Innovation|first=Science and Economic Development Canada|date=2019-05-16|website=gcnws|access-date=2020-03-29}}</ref> In 2019, the Panel was renamed the Global Partnership on AI.<ref>{{Cite magazine|url=https://www.wired.com/story/world-plan-rein-ai-us-doesnt-like/|title=The world has a plan to rein in AI\u2014but the US doesn't like it|date=2020-01-08|magazine=Wired|language=en-GB|access-date=2020-03-29|last1=Simonite|first1=Tom}}</ref><ref name=\"timear\">{{cite web|url=https://www.informationweek.com/big-data/ai-machine-learning/ai-regulation-has-the-time-arrived/a/d-id/1337099|title=AI Regulation: Has the Time Arrived?|website=InformationWeek|date=24 February 2020|language=en|access-date=2020-03-29}}</ref>\n\nThe [[Global Partnership on Artificial Intelligence]] was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology, as outlined in the [[OECD]] ''Principles on Artificial Intelligence'' (2019).<ref name=\"UNESCO Science Report 2021\"/> The founding members of the Global Partnership on Artificial Intelligence are Australia, Canada, the European Union, France, Germany, India, Italy, Japan, Rep. Korea, Mexico, New Zealand, Singapore, Slovenia, the USA and the UK. The GPAI Secretariat is hosted by the OECD in Paris, France. GPAI's mandate covers four themes, two of which are supported by the International Centre of Expertise in Montr\u00e9al for the Advancement of Artificial Intelligence, namely, responsible AI and data governance. A corresponding centre of excellence in Paris, yet to be identified, will support the other two themes on the future of work and innovation, and commercialization. GPAI will also investigate how AI can be leveraged to respond to the Covid-19 pandemic.<ref name=\"UNESCO Science Report 2021\"/>\n\nThe OECD Recommendations on AI<ref>{{cite web|url=https://www.oecd.org/going-digital/ai/principles/|title=OECD Principles on Artificial Intelligence - Organisation for Economic Co-operation and Development|website=www.oecd.org|language=en|access-date=2020-03-29}}</ref> were adopted in May 2019, and the G20 AI Principles in June 2019.<ref name=\"timear\" /><ref>{{Cite book|url=https://www.mofa.go.jp/mofaj/files/000486596.pdf|title=G20 Ministerial Statement on Trade and Digital Economy|publisher=G20|year=2019|location=Tsukuba City, Japan}}</ref><ref>{{Cite journal|date=2019-08-21|title=International AI ethics panel must be independent|journal=Nature|language=en|volume=572|issue=7770|page=415|doi=10.1038/d41586-019-02491-x|pmid=31435065|bibcode=2019Natur.572R.415.|doi-access=free}}</ref> In September 2019 the [[World Economic Forum]] issued ten 'AI Government Procurement Guidelines'.<ref>{{Cite book|url=http://www3.weforum.org/docs/WEF_Guidelines_for_AI_Procurement.pdf|title=Guidelines for AI Procurement|publisher=World Economic Forum|year=2019|location=Cologny/Geneva}}</ref> In February 2020, the European Union published its draft strategy paper for promoting and regulating AI.<ref name=\":12\" />\n\nAt the United Nations (UN), several entities have begun to promote and discuss aspects of AI regulation and policy, including the [[UNICRI Centre for AI and Robotics]].<ref name=\"babupol\" /> In partnership with INTERPOL, UNICRI's Centre issued the report ''AI and Robotics for Law Enforcement'' in April 2019<ref>{{Cite web |title=UNICRI :: United Nations Interregional Crime and Justice Research Institute |url=https://unicri.it/news/article/AI_Robotics_Crime_Terrorism_Security |access-date=2022-07-18 |website=unicri.it}}</ref> and the follow-up report ''Towards Responsible AI Innovation'' in May 2020.<ref>{{Cite web |last=UNICRI: United Nations Interregional Crime and Justice Research Institute |date=July 2020 |title=Towards Responsible Artificial Intelligence Innovation |url=https://unicri.it/towards-responsible-artificial-intelligence-innovation |access-date=2022-07-18 |website=unicri.it}}</ref> At [[UNESCO]]'s Scientific 40th session in November 2019, the organization commenced a two-year process to achieve a \"global standard-setting instrument on ethics of artificial intelligence\". In pursuit of this goal, UNESCO forums and conferences on AI were held to gather stakeholder views. A draft text of a ''Recommendation on the Ethics of AI'' of the UNESCO Ad Hoc Expert Group was issued in September 2020 and included a call for legislative gaps to be filled.<ref name=\":15\">{{Cite book|last1=N\u00edFhaol\u00e1in|first1=Labhaoise|url=http://ceur-ws.org/Vol-2771/AICS2020_paper_53.pdf|title=Assessing the Appetite for Trustworthiness and the Regulation of Artificial Intelligence in Europe|last2=Hines|first2=Andrew|last3=Nallur|first3=Vivek|publisher=Technological University Dublin, School of Computer Science, Dublin|year=2020|location=Dublin|pages=1\u201312}}{{CC-notice|cc=by4}} (The CC BY 4.0 licence means that everyone have the right to reuse the text that is quoted here, or other parts of the original article itself, if they credit the authors. More info: [[Creative Commons license]]) Changes were made as follows: citations removed and minor grammatical amendments.</ref> UNESCO tabled the international instrument on the ethics of AI for adoption at its General Conference in November 2021;<ref name=\"UNESCO Science Report 2021\">{{cite book |title=UNESCO Science Report: the Race Against Time for Smarter Development. |date=11 June 2021 |publisher=UNESCO |location=Paris |isbn=978-92-3-100450-6 |url=https://unesdoc.unesco.org/ark:/48223/pf0000377433/PDF/377433eng.pdf.multi}}</ref> this was subsequently adopted.<ref>{{Cite web |last= |date=2020-02-27 |title=Recommendation on the ethics of artificial intelligence |url=https://en.unesco.org/artificial-intelligence/ethics |access-date=2022-07-18 |website=UNESCO |language=en}}</ref> While the UN is making progress with the global management of AI, its institutional and legal capability to manage the AGI existential risk is more limited.<ref>{{Cite journal |last=Nindler |first=Reinmar |date=2019-03-11 |title=The United Nation's Capability to Manage Existential Risks with a Focus on Artificial Intelligence |url=https://brill.com/view/journals/iclr/21/1/article-p5_3.xml |journal=International Community Law Review |volume=21 |issue=1 |pages=5\u201334 |doi=10.1163/18719732-12341388 |s2cid=150911357 |issn=1871-9740}}</ref>\n\nAn initiative of [[International Telecommunication Union]] (ITU) in partnership with 40 UN sister agencies, [[AI for Good]] is a global platform which aims to identify practical applications of AI to advance the United Nations Sustainable Development Goals and scale those solutions for global impact. It is an action-oriented, global & inclusive United Nations platform fostering development of AI to positively impact health, climate, gender, inclusive prosperity, sustainable infrastructure, and other global development priorities.<ref>{{Cite web |title=About |url=https://aiforgood.itu.int/about-ai-for-good/ |access-date=2023-04-06 |website=AI for Good |language=en-US}}</ref>\n\n== Regional and national regulation ==\n[[File:AI Strategic Documents Timeline UNICRI.jpg|thumb|Timeline of strategies, action plans and policy papers setting defining national, regional and international approaches to AI<ref>{{cite web|title=UNICRI :: United Nations Interregional Crime and Justice Research Institute|url=http://www.unicri.it/index.php/topics/ai_robotics|access-date=2020-08-08|website=www.unicri.it}}</ref>]]\nThe regulatory and policy landscape for AI is an emerging issue in regional and national jurisdictions globally, for example in the European Union<ref>{{Cite book|last=Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body.|title=Regulation of artificial intelligence in selected jurisdictions.|lccn=2019668143|oclc=1110727808}}</ref> and Russia.<ref>{{Citation|last1=Popova|first1=Anna V.|title=The System of Law and Artificial Intelligence in Modern Russia: Goals and Instruments of Digital Modernization|date=2021|url=http://dx.doi.org/10.1007/978-3-030-56433-9_11|work=Studies in Systems, Decision and Control|pages=89\u201396|place=Cham|publisher=Springer International Publishing|isbn=978-3-030-56432-2|access-date=2021-03-27|last2=Gorokhova|first2=Svetlana S.|last3=Abramova|first3=Marianna G.|last4=Balashkina|first4=Irina V.|doi=10.1007/978-3-030-56433-9_11|s2cid=234309883}}</ref> Since early 2016, many national, regional and international authorities have begun adopting strategies, actions plans and policy papers on AI.<ref>{{cite web|url=https://oecd-opsi.org/projects/ai/strategies/|title=OECD Observatory of Public Sector Innovation - Ai Strategies and Public Sector Components|access-date=2020-05-04}}</ref><ref>{{Cite book|last1=Berryhill|first1=Jamie|url=https://oecd-opsi.org/wp-content/uploads/2019/11/AI-Report-Online.pdf|title=Hello, World: Artificial Intelligence and its Use in the Public Sector|last2=Heang|first2=K\u00e9vin Kok|last3=Clogher|first3=Rob|last4=McBride|first4=Keegan|publisher=OECD Observatory of Public Sector Innovation|year=2019|location=Paris}}</ref> These documents cover a wide range of topics such as regulation and governance, as well as industrial strategy, research, talent and infrastructure.<ref name=\"aiis\" /><ref>{{Cite book|last=Campbell|first=Thomas A.|url=http://www.unicri.it/in_focus/files/Report_AI-An_Overview_of_State_Initiatives_FutureGrasp_7-23-19.pdf|title=Artificial Intelligence: An Overview of State Initiatives|publisher=FutureGrasp, LLC|year=2019|location=Evergreen, CO}}</ref>\n\n===Canada===\nThe ''Pan-Canadian Artificial Intelligence Strategy'' (2017) is supported by federal funding of Can $125 million with the objectives of increasing the number of outstanding AI researchers and skilled graduates in Canada, establishing nodes of scientific excellence at the three major AI centres, developing 'global thought leadership' on the economic, ethical, policy and legal implications of AI advances and supporting a national research community working on AI.<ref name=\"UNESCO Science Report 2021\" /> The Canada CIFAR AI Chairs Program is the cornerstone of the strategy. It benefits from funding of Can$86.5 million over five years to attract and retain world-renowned AI researchers.<ref name=\"UNESCO Science Report 2021\" />\nThe federal government appointed an Advisory Council on AI in May 2019 with a focus on examining how to build on Canada's strengths to ensure that AI advancements reflect Canadian values, such as human rights, transparency and openness. The Advisory Council on AI has established a working group on extracting commercial value from Canadian-owned AI and data analytics.<ref name=\"UNESCO Science Report 2021\" /> In 2020, the federal government and Government of Quebec announced the opening of the International Centre of Expertise in Montr\u00e9al for the Advancement of Artificial Intelligence, which will advance the cause of responsible development of AI.<ref name=\"UNESCO Science Report 2021\" /> In 2022, the Canadian Federal Government tabled a bill for the Artificial Intelligence and Data Act.<ref>{{Cite web |title=Government Bill (House of Commons) C-27 (44-1) - First Reading - Digital Charter Implementation Act, 2022 - Parliament of Canada |url=https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading |access-date=2022-07-12 |website=www.parl.ca |language=en-ca}}</ref> In November 2022, Canada has introduced the Digital Charter Implementation Act (Bill C-27), which proposes three acts that have been described as a holistic package of legislation for trust and privacy: the Consumer Privacy Protection Act, the Personal Information and Data Protection Tribunal Act, and the [[Artificial intelligence|Artificial Intelligence]] & Data Act (AIDA).\n\n=== China ===\n{{Further|Artificial intelligence industry in China}}\nThe regulation of AI in China is mainly governed by the [[State Council of the People's Republic of China]]'s July 8, 2017 \"A Next Generation Artificial Intelligence Development Plan\" (State Council Document No. 35), in which the [[Central Committee of the Chinese Communist Party]] and the State Council of the PRC urged the governing bodies of China to promote the development of AI up to 2030. Regulation of the issues of ethical and legal support for the development of AI is accelerating, and policy ensures state control of Chinese companies and over valuable data, including storage of data on Chinese users within the country and the mandatory use of People's Republic of China's national standards for AI, including over big data, cloud computing, and industrial software.<ref>{{Cite web |last=State Council China |title=New Generation of Artificial Intelligence Development Plan |url=https://www.unodc.org/ji/en/resdb/data/chn/2017/new_generation_of_artificial_intelligence_development_plan.html |access-date=2022-07-18 |website=www.unodc.org |language=en}}</ref><ref>{{Cite journal |last=Department of International Cooperation Ministry of Science and Technology |date=September 2017 |title=Next Generation Artificial Intelligence Development Plan Issued by State Council |url=https://www.mfa.gov.cn/ce/cefi/eng/kxjs/P020171025789108009001.pdf |journal=China Science & Technology Newsletter |issue=17 |pages=2\u201312 |via=[[Ministry of Foreign Affairs of China]]}}</ref><ref>{{Cite journal |last1=Wu |first1=Fei |last2=Lu |first2=Cewu |last3=Zhu |first3=Mingjie |last4=Chen |first4=Hao |last5=Zhu |first5=Jun |last6=Yu |first6=Kai |last7=Li |first7=Lei |last8=Li |first8=Ming |last9=Chen |first9=Qianfeng |last10=Li |first10=Xi |last11=Cao |first11=Xudong |date=2020 |title=Towards a new generation of artificial intelligence in China |url=https://www.nature.com/articles/s42256-020-0183-4 |journal=[[Nature Machine Intelligence]] |language=en |volume=2 |issue=6 |pages=312\u2013316 |doi=10.1038/s42256-020-0183-4 |issn=2522-5839 |s2cid=220507829}}</ref> In 2021, China published ethical guidelines for the use of AI in China which state that researchers must ensure that AI abides by shared human values, is always under human control, and is not endangering public safety.<ref>{{Cite web |title=Ethical Norms for New Generation Artificial Intelligence Released |url=https://cset.georgetown.edu/publication/ethical-norms-for-new-generation-artificial-intelligence-released/ |access-date=2022-07-18 |website=[[Center for Security and Emerging Technology]] |language=en-US}}</ref>\n\n=== Council of Europe ===\nThe [[Council of Europe]] (CoE) is an international organization which promotes human rights democracy and the rule of law and comprises 47 member states, including all 29 Signatories of the European Union's 2018 Declaration of Cooperation on Artificial Intelligence. The CoE has created a common legal space in which the members have a legal obligation to guarantee rights as set out in the [[European Convention on Human Rights]]. Specifically in relation to AI, \"The Council of Europe's aim is to identify intersecting areas between AI and our standards on human rights, democracy and rule of law, and to develop relevant standard setting or capacity-building solutions\". The large number of relevant documents identified by the CoE include guidelines, charters, papers, reports and strategies.<ref>{{cite web|title=Council of Europe and Artificial Intelligence|url=https://www.coe.int/en/web/artificial-intelligence/home|access-date=2021-07-29|website=Artificial Intelligence|language=en-GB}}</ref> The authoring bodies of these AI regulation documents are not confined to one sector of society and include organizations, companies, bodies and nation-states.<ref name=\":15\" />\n\n=== European Union ===\nMost European Union (EU) countries have their own national strategies towards regulating AI, but these are largely convergent.<ref name=\":15\" /> The European Union is guided by a European Strategy on Artificial Intelligence,<ref>{{cite web|title=Communication Artificial Intelligence for Europe|url=https://ec.europa.eu/digital-single-market/en/news/communication-artificial-intelligence-europe|last=Anonymous|date=2018-04-25|website=Shaping Europe's digital future - European Commission|language=en|access-date=2020-05-05}}</ref> supported by a High-Level Expert Group on Artificial Intelligence.<ref>{{cite web|title=High-Level Expert Group on Artificial Intelligence|url=https://ec.europa.eu/digital-single-market/en/high-level-expert-group-artificial-intelligence|last=smuhana|date=2018-06-14|website=Shaping Europe's digital future - European Commission|language=en|access-date=2020-05-05}}</ref><ref>{{Cite journal|last1=Andra\u0161ko|first1=Jozef|last2=Mesar\u010d\u00edk|first2=Mat\u00fa\u0161|last3=Hamu\u013e\u00e1k|first3=Ondrej|date=2021-01-02|title=The regulatory intersections between artificial intelligence, data protection and cyber security: challenges and opportunities for the EU legal framework|url=http://dx.doi.org/10.1007/s00146-020-01125-5|journal=AI & Society|volume=36|issue=2|pages=623\u2013636|doi=10.1007/s00146-020-01125-5|s2cid=230109912|issn=0951-5666}}</ref> In April 2019, the European Commission published its ''Ethics Guidelines for Trustworthy Artificial Intelligence (AI)'',<ref>{{cite web|title=Ethics Guidelines For Trustworthy AI|url=https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf}}</ref><ref>{{cite web|title=Building trust in human-centric AI|url=https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines|last=Weiser|first=Stephanie|date=2019-04-03|website=FUTURIUM - European Commission|language=en|access-date=2020-05-05}}</ref> following this with its ''Policy and investment recommendations for trustworthy Artificial Intelligence'' in June 2019.<ref>{{cite web|title=Policy and investment recommendations for trustworthy Artificial Intelligence|url=https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence|last=Anonymous|date=2019-06-26|website=Shaping Europe's digital future - European Commission|language=en|access-date=2020-05-05}}</ref> The EU Commission's High Level Expert Group on Artificial Intelligence carries out work on Trustworthy AI, and the Commission has issued reports on the Safety and Liability Aspects of AI and on the Ethics of Automated Vehicles. In 2020 the EU Commission sought views on a proposal for AI specific legislation, and that process is ongoing.<ref name=\":15\" />\n\nOn February 2, 2020, the European Commission published its ''White Paper on Artificial Intelligence - A European approach to excellence and trust''.<ref name=\"extr\">{{Cite book|last=European Commission.|title=White paper on artificial intelligence: a European approach to excellence and trust.|year=2020|oclc=1141850140}}</ref><ref>{{cite web|title=Does This Change Everything? Coronavirus and your private data|url=https://www.eib.org/en/stories/coronavirus-impact-data-privacy|access-date=2021-06-07|website=European Investment Bank|language=en|archive-date=7 June 2021|archive-url=https://web.archive.org/web/20210607142044/https://www.eib.org/en/stories/coronavirus-impact-data-privacy|url-status=live}}</ref><ref>{{cite web|title=White Paper on Artificial Intelligence \u2013 a European approach to excellence and trust {{!}} Shaping Europe's digital future|url=https://digital-strategy.ec.europa.eu/en/consultations/white-paper-artificial-intelligence-european-approach-excellence-and-trust|access-date=2021-06-07|website=digital-strategy.ec.europa.eu|date=19 February 2020 }}</ref><ref>{{cite journal|title=What's Ahead for a Cooperative Regulatory Agenda on Artificial Intelligence?|url=https://www.csis.org/analysis/whats-ahead-cooperative-regulatory-agenda-artificial-intelligence|access-date=2021-06-07|website=www.csis.org|date=17 March 2021 |language=en|archive-date=7 June 2021|archive-url=https://web.archive.org/web/20210607144154/https://www.csis.org/analysis/whats-ahead-cooperative-regulatory-agenda-artificial-intelligence|url-status=live|last1=Broadbent |first1=Meredith }}</ref>\nThe White Paper consists of two main building blocks, an 'ecosystem of excellence' and a 'ecosystem of trust'. The latter outlines the EU's approach for a regulatory framework for AI. In its proposed approach, the Commission differentiates between 'high-risk' and 'non-high-risk' AI applications. Only the former should be in the scope of a future EU regulatory framework. Whether this would be the case could in principle be determined by two cumulative criteria, concerning critical sectors and critical use. Following key requirements are considered for high-risk AI applications: requirements for training data; data and record-keeping; informational duties; requirements for robustness and accuracy; human oversight; and specific requirements for specific AI applications, such as those used for purposes of remote biometric identification. AI applications that do not qualify as 'high-risk' could be governed by a voluntary labeling scheme. As regards compliance and enforcement, the Commission considers prior conformity assessments which could include 'procedures for testing, inspection or certification' and/or 'checks of the algorithms and of the data sets used in the development phase'. A European governance structure on AI in the form of a framework for cooperation of national competent authoritieus could facilitate the implementation of the regulatory framework.<ref name=\"extr\" /><ref>{{cite news |title=Regulating AI in the EU |url=https://www.mhc.ie/latest/insights/regulating-ai-in-the-eu |accessdate=30 March 2023 |work=Mason Hayes & Curran |language=en}}</ref> A January 2021 draft was leaked online on April 14, 2021,<ref>Heikkil\u00e4, Melissa (2021-04-14). [https://www.politico.eu/newsletter/ai-decoded/politico-ai-decoded-transatlantic-schisms-finland-talks-to-machines-facebooks-fairness-project/ \"POLITICO AI: Decoded: The EU's AI rules \u2014 Finland talks to machines \u2014 Facebook's fairness project\"] (newsletter). ''POLITICO''. Retrieved 2021-05-14.</ref> before the Commission ultimately presented their official \"Proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)\" a week later.<ref>European Commission (2021-04-21). ''[https://ec.europa.eu/commission/presscorner/detail/en/ip_21_1682 Europe fit for the Digital Age: Commission proposes new rules and actions for excellence and trust in Artificial Intelligence]'' (press release). Retrieved 2021-05-14.</ref> Shortly after, the [[Artificial Intelligence Act]] was formally proposed.<ref>{{cite web |last=Pery |first=Andrew |date=2021-10-06 |title=Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities |url=https://deepai.org/publication/trustworthy-artificial-intelligence-and-process-mining-challenges-and-opportunities |access-date=2022-02-27 |website=DeepAI}}</ref> This includes a fine-tune of the 2020 risk-based approach. The proposal has been severely critiqued in the  public debate. Academics are concerned about the various unclear elements in the proposal - such as the broad definition of what constitutes AI - and fear unintended legal implications, especially for vulnerable groups such as patients and migrants.<ref>{{Cite journal |last1=Veale |first1=Michael |last2=Borgesius |first2=Frederik Zuiderveen |date=2021-08-01 |title=Demystifying the Draft EU Artificial Intelligence Act \u2014 Analysing the good, the bad, and the unclear elements of the proposed approach |url=https://www.degruyter.com/document/doi/10.9785/cri-2021-220402/html |journal=Computer Law Review International |language=en |volume=22 |issue=4 |pages=97\u2013112 |doi=10.9785/cri-2021-220402 |arxiv=2107.03721 |s2cid=235765823 |issn=2194-4164}}</ref> <ref>{{Cite journal |last=van Kolfschooten |first=Hannah |date=January 2022 |title=EU regulation of artificial intelligence: Challenges for patients' rights |url=https://kluwerlawonline.com/journalarticle/Common+Market+Law+Review/59.1/COLA202200 |journal=Common Market Law Review |volume=59 |issue=1 |pages=81\u2013112|doi=10.54648/COLA2022005 |s2cid=248591427 }}</ref>  \n\nObservers have expressed concerns about the multiplication of legislative proposals under the [[von der Leyen Commission]]. The speed of the legislative initiatives is partially led by political ambitions of the [[EU]] and could put at risk the digital rights of the European citizens, including rights to privacy,<ref>{{cite web |url=https://encompass-europe.com/comment/eus-digital-ambitions-beset-with-strategic-dissonance |title= EU's digital ambitions beset with strategic dissonance |last=Natale |first= Lara|date= February 2022 |website= Encompass|publisher= |access-date= 25 February 2022|quote=}}</ref> especially in the face of uncertain guarantees of data protection through cyber security.<ref>{{Cite journal |last1=Andra\u0161ko |first1=Jozef |last2=Mesar\u010d\u00edk |first2=Mat\u00fa\u0161 |last3=Hamu\u013e\u00e1k |first3=Ondrej |date=2021-01-02 |title=The regulatory intersections between artificial intelligence, data protection and cyber security: challenges and opportunities for the EU legal framework |url=http://dx.doi.org/10.1007/s00146-020-01125-5 |journal=AI & Society |volume=36 |issue=2 |pages=623\u2013636 |doi=10.1007/s00146-020-01125-5 |s2cid=253686398 |issn=0951-5666}}</ref> Among the stated guiding principles in the variety of legislative proposals in the area of AI under the von der Leyen Commission are the objectives of [[strategic autonomy]]<ref>{{cite news |last1= Bertuzzi |first1= Luca|last2= Killeen|first2= Molly|date= 17 September 2021|title=Digital Brief powered by Google: make it or break it, Chips Act, showing the path |url=https://www.euractiv.com/section/digital/news/digital-brief-powered-by-google-make-it-or-break-it-showing-the-path/ |work=Euractiv |location= |access-date=25 February 2022}}</ref> and the concept of digital sovereignty.<ref>{{cite web |url=https://www.atlanticcouncil.org/blogs/new-atlanticist/frances-new-mantra-liberty-equality-digital-sovereignty/ |title= France's new mantra: liberty, equality, digital sovereignty|last= Propp|first= Kenneth|date= 7 February 2022|website= Atlantic Council |publisher= |access-date= 25 February 2022|quote=}}</ref>\n\n=== United Kingdom ===\nThe UK supported the application and development of AI in business via the [https://www.gov.uk/government/publications/digital-economy-strategy-2015-2018 ''Digital Economy Strategy 2015-2018,''] introduced at the beginning of 2015 by [[Innovate UK]] as part of the UK Digital Strategy.<ref>{{Cite web |title=Digital economy strategy 2015 to 2018 |url=https://www.ukri.org/publications/digital-economy-strategy-2015-to-2018/ |access-date=2022-07-18 |website=www.ukri.org |date=16 February 2015 |language=en-US}}</ref> In the public sector, guidance has been provided by the Department for Digital, Culture, Media and Sport, on data ethics<ref>{{Cite book|url=https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/737137/Data_Ethics_Framework.pdf|title=Data Ethics Framework|publisher=Department for Digital, Culture, Media and Sport|year=2018|location=London}}</ref> and the [[Alan Turing Institute]], on responsible design and implementation of AI systems.<ref>{{Cite journal|journal=Zenodo|last=Leslie|first=David|s2cid=189762499|date=2019-06-11|title=Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector|url=https://zenodo.org/record/3240529|doi=10.5281/zenodo.3240529| arxiv=1906.05684}}</ref> In terms of cyber security, in 2020 the [[National Cyber Security Centre (United Kingdom)|National Cyber Security Centre]] has issued guidance on 'Intelligent Security Tools'.<ref name=\"babupol\" /><ref>{{cite web|title=Intelligent security tools|url=https://www.ncsc.gov.uk/collection/intelligent-security-tools|access-date=2020-04-28|website=www.ncsc.gov.uk|language=en}}</ref> The following year, the [[UK]] published its 10-year National AI Strategy,<ref>{{Cite web|url=https://www.theregister.com/2021/09/22/uk_10_year_national_ai_strategy/|title=UK publishes National Artificial Intelligence Strategy|first=Tim|last=Richardson|website=www.theregister.com}}</ref> which describes actions to assess long-term AI risks, including AGI-related catastrophic risks.<ref>[https://www.gov.uk/government/publications/national-ai-strategy/national-ai-strategy-html-version The National AI Strategy of the UK], 2021 (actions 9 and 10 of the section \"Pillar 3 - Governing AI Effectively\")</ref>\n\n=== United States ===\nDiscussions on regulation of AI in the United States have included topics such as the timeliness of regulating AI, the nature of the federal regulatory framework to govern and promote AI, including what agency should lead, the regulatory and governing powers of that agency, and how to update regulations in the face of rapidly changing technology, as well as the roles of state governments and courts.<ref>{{Cite journal|last=Weaver|first=John Frank|date=2018-12-28|title=Regulation of artificial intelligence in the United States|url=https://www.elgaronline.com/view/edcoll/9781786439048/9781786439048.00018.xml|journal=Research Handbook on the Law of Artificial Intelligence|pages=155\u2013212|language=en-US|doi=10.4337/9781786439055.00018|isbn=9781786439055}}</ref>\n\nAs early as 2016, the Obama administration had begun to focus on the risks and regulations for artificial intelligence. In a report titled ''[https://obamawhitehouse.archives.gov/blog/2016/10/12/administrations-report-future-artificial-intelligence Preparing For the Future of Artificial Intelligence],'' the National Science and Technology Council set a precedent to allow researchers to continue to develop new AI technologies with few restrictions. It is stated within the report that \"the approach to regulation of AI-enabled products to protect public safety should be informed by assessment of the aspects of risk....\".<ref>{{cite web|last=National Science and Technology Council Committee on Technology|date=October 2016|work=[[whitehouse.gov]]|title=Preparing for the Future of Artificial Intelligence|via=[[NARA|National Archives]]|url=https://obamawhitehouse.archives.gov/blog/2016/10/12/administrations-report-future-artificial-intelligence}}</ref> These risks would be the principal reason to create any form of regulation, granted that any existing regulation would not apply to AI technology.\n\nThe first main report was the [https://www.nitrd.gov/news/national_ai_rd_strategic_plan.aspx National Strategic Research and Development Plan for Artificial Intelligence.] On August 13, 2018, Section 1051 of the Fiscal Year 2019 [[John S. McCain National Defense Authorization Act for Fiscal Year 2019|John S. McCain National Defense Authorization Act]] (P.L. 115-232) established the [https://www.nscai.gov National Security Commission on Artificial Intelligence] \"to consider the methods and means necessary to advance the development of artificial intelligence, machine learning, and associated technologies to comprehensively address the national security and defense needs of the United States.\"<ref>{{cite web|title=About|url=https://sites.google.com/nscai.gov/home/about|access-date=2020-06-29|website=National Security Commission on Artificial Intelligence|language=en-US}}</ref> Steering on regulating security-related AI is provided by the National Security Commission on Artificial Intelligence.<ref>{{cite web|url=https://www.congress.gov/bill/115th-congress/house-bill/5356|title=H.R.5356 \u2013 115th Congress (2017\u20132018): National Security Commission Artificial Intelligence Act of 2018|last=Stefanik|first=Elise M.|date=2018-05-22|website=www.congress.gov|access-date=2020-03-13}}</ref> The Artificial Intelligence Initiative Act (S.1558) is a proposed bill that would establish a federal initiative designed to accelerate research and development on AI for, ''inter alia'', the economic and national security of the United States.<ref>{{cite web|url=https://www.congress.gov/bill/116th-congress/senate-bill/1558/text|title=Text - S.1558 - 116th Congress (2019-2020): Artificial Intelligence Initiative Act|last=Heinrich|first=Martin|date=2019-05-21|website=www.congress.gov|access-date=2020-03-29}}</ref><ref>{{Cite journal|last=Scherer|first=Matthew U.|date=2015|title=Regulating Artificial Intelligence Systems: Risks, Challenges, Competencies, and Strategies|journal=SSRN Working Paper Series|doi=10.2139/ssrn.2609777|issn=1556-5068}}</ref>\n\nOn January 7, 2019, following an [https://trumpwhitehouse.archives.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/ Executive Order on Maintaining American Leadership in Artificial Intelligence], the White House's Office of Science and Technology Policy released a draft ''[https://www.whitehouse.gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI-1-7-19.pdf Guidance for Regulation of Artificial Intelligence Applications]'', which includes ten principles for United States agencies when deciding whether and how to regulate AI.<ref>{{cite web|url=https://www.insidetechmedia.com/2020/01/14/ai-update-white-house-issues-10-principles-for-artificial-intelligence-regulation/|title=AI Update: White House Issues 10 Principles for Artificial Intelligence Regulation|date=2020-01-14|website=Inside Tech Media|language=en-US|access-date=2020-03-25}}</ref> In response, the National Institute of Standards and Technology has released a position paper,<ref>{{Cite book|url=https://www.nist.gov/system/files/documents/2019/08/10/ai_standards_fedengagement_plan_9aug2019.pdf|title=U.S. Leadership in AI: A Plan for Federal Engagement in Developing Technical Standards and Related Tools|publisher=National Institute of Science and Technology|year=2019}}</ref> and the Defense Innovation Board has issued recommendations on the ethical use of AI.<ref>{{Cite book|url=https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB_AI_PRINCIPLES_PRIMARY_DOCUMENT.PDF|title=AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the Department of Defense|publisher=Defense Innovation Board|year=2020|location=Washington, DC}}</ref> A year later, the administration called for comments on regulation in another draft of its Guidance for Regulation of Artificial Intelligence Applications.<ref>{{cite web|date=2020-01-13|title=Request for Comments on a Draft Memorandum to the Heads of Executive Departments and Agencies, \"Guidance for Regulation of Artificial Intelligence Applications\"|url=https://www.federalregister.gov/documents/2020/01/13/2020-00261/request-for-comments-on-a-draft-memorandum-to-the-heads-of-executive-departments-and-agencies|access-date=2020-11-28|website=Federal Register}}</ref>\n\nOther specific agencies working on the regulation of AI include the Food and Drug Administration,<ref>{{Cite journal|last1=Hwang|first1=Thomas J.|last2=Kesselheim|first2=Aaron S.|last3=Vokinger|first3=Kerstin N.|date=2019-12-17|title=Lifecycle Regulation of Artificial Intelligence\u2013 and Machine Learning\u2013Based Software Devices in Medicine|url=https://jamanetwork.com/journals/jama/fullarticle/2756194|journal=JAMA|language=en|volume=322|issue=23|pages=2285\u20132286|doi=10.1001/jama.2019.16842|pmid=31755907 |s2cid=208230202 |issn=0098-7484}}</ref> which has created pathways to regulate the incorporation of AI in medical imaging.<ref name=\":14\" />\n\nIn March 2021, the National Security Commission on Artificial Intelligence released their final report.<ref>{{Cite book|url=https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf|title=NSCAI Final Report|publisher=The National Security Commission on Artificial Intelligence|year=2021|location=Washington, DC}}</ref>  In the report, they stated that \"Advances in AI, including the mastery of more general AI capabilities along one or more dimensions, will likely provide new capabilities and applications. Some of these advances could lead to inflection points or leaps in capabilities. Such advances may also introduce new concerns and risks and the need for new policies, recommendations, and technical advances to assure that systems are aligned with goals and values, including safety, robustness and trustworthiness. The US should monitor advances in AI and make necessary investments in technology and give attention to policy so as to ensure that AI systems and their uses align with our goals and values.\"\n\nIn June 2022, Senators [[Rob Portman]] and [[Gary Peters]] introduced the Global Catastrophic Risk Mitigation Act. The bipartisan bill \"would also help counter the risk of artificial intelligence... from being abused in ways that may pose a catastrophic risk\".<ref>{{cite web|author=Homeland Newswire |url=https://homelandnewswire.com/stories/627890045-portman-peters-introduce-bipartisan-bill-to-ensure-federal-government-is-prepared-for-catastrophic-risks-to-national-security |title=Portman, Peters Introduce Bipartisan Bill to Ensure Federal Government is Prepared for Catastrophic Risks to National Security |publisher=HomelandNewswire |date=2022-06-25 |accessdate=2022-07-04}}</ref><ref>{{cite web|url=https://www.congress.gov/bill/117th-congress/senate-bill/4488/text |title=Text - S.4488 - 117th Congress (2021-2022): A bill to establish an interagency committee on global catastrophic risk, and for other purposes. {{pipe}} Congress.gov {{pipe}} Library of Congress |publisher=Congress.gov |date=2022-06-23 |accessdate=2022-07-04}}</ref> On October 4, 2022, President Joe Biden unveiled a new [https://www.whitehouse.gov/ostp/ai-bill-of-rights/ AI Bill of Rights] , which outlines five protections Americans should have in the AI age:  1. Safe and Effective Systems, 2. Algorithmic Discrimination Protection, 3.Data Privacy, 4. Notice and Explanation, and 5. Human Alternatives, Consideration, and Fallback. The Bill was introduced in October 2021 by the Office of Science and Technology Policy (OSTP), a US government department that advises the president on science and technology.<ref>{{cite web | url=https://www.technologyreview.com/2022/10/04/1060600/white-house-ai-bill-of-rights | title=The White House just unveiled a new AI Bill of Rights }}</ref>\n\nIn January 2023, the New York City Bias Audit Law ([https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=B051915D-A9AC-451E-81F8-6596032FA3F9 Local Law 144]) was enacted by the NYC Council in November 2021. Originally due to come into effect on 1st January 2023, the enforcement date for Local Law 144 has now been pushed back to 15th April 2023 due to the high volume of comments received during the public hearing on the Department of Consumer and Worker Protection's (DCWP) proposed rules to clarify the requirements of the legislation. From 15th April 2023, companies are prohibited from using automated tools to hire candidates or promote employees, unless the tools have been independently audited for bias. These regulations are likely to affect hundreds of organisations within the city and may include your own.\n\n=== Brazil ===\nOn September 30, 2021, the Brazilian Chamber of Deputies approved the Brazilian Legal Framework for Artificial Intelligence, Marco Legal da Intelig\u00eancia Artificial, in regulatory efforts for the development and usage of AI technologies and to further stimulate research and innovation in AI solutions aimed at ethics, culture, justice, fairness, and accountability. This 10 article bill outlines objectives including missions to contribute to the elaboration of ethical principles, promote sustained investments in research, and remove barriers to innovation.  Specifically, in article 4, the bill emphasizes the avoidance of discriminatory AI solutions, plurality, and respect for human rights. Furthermore, this act emphasizes the importance of the equality principle in deliberate decision-making algorithms, especially for highly diverse and multiethnic societies like that of Brazil. \n\nWhen the bill was first released to the public, it faced substantial criticism, alarming the government for critical provisions. The underlying issue is that this bill fails to thoroughly and carefully address accountability, transparency, and inclusivity principles. Article VI establishes subjective liability, meaning any individual that is damaged by an AI system and is wishing to receive compensation must specify the stakeholder and prove that there was a mistake in the machine's life cycle. Scholars emphasize that it is out of legal order to assign an individual responsible for proving algorithmic errors given the high degree of autonomy, unpredictability, and complexity of AI systems. This also drew attention to the currently occurring issues with face recognition systems in Brazil leading to unjust arrests by the police, which would then imply that when this bill is adopted, individuals would have to prove and justify these machine errors. \n\nThe main controversy of this draft bill was directed to three proposed principles. First, the non-discrimination principle, suggests that AI must be developed and used in a way that merely mitigates the possibility of abusive and discriminatory practices. Secondly, the pursuit of neutrality principle lists recommendations for stakeholders to mitigate biases; however, with no obligation to achieve this goal. Lastly, the transparency principle states that a system's transparency is only necessary when there is a high risk of violating fundamental rights. As easily observed, the Brazilian Legal Framework for Artificial Intelligence lacks binding and obligatory clauses and is rather filled with relaxed guidelines. In fact, experts emphasize that this bill may even make accountability for AI discriminatory biases even harder to achieve. Compared to the EU's proposal of extensive risk-based regulations, the Brazilian Bill has 10 articles proposing vague and generic recommendations.\n\nCompared to the multistakeholder participation approach taken previously in the 2000s when drafting the Brazilian Internet Bill of Rights, Marco Civil da Internet, the Brazilian Bill is assessed to significantly lack perspective. Multistakeholderism, more commonly referred to as Multistakeholder Governance, is defined as the practice of bringing multiple stakeholders to participate in dialogue, decision-making, and implementation of responses to jointly perceived problems. In the context of regulatory AI, this multistakeholder perspective captures the trade-offs and varying perspectives of different stakeholders with specific interests, which helps maintain transparency and broader efficacy. On the contrary, the legislative proposal for AI regulation did not follow a similar multistakeholder approach. \n\nFuture steps may include, expanding upon the multistakeholder perspective. There has been a growing concern about the inapplicability of the framework of the bill, which highlights that the one-shoe-fits-all solution may not be suitable for the regulation of AI and calls for subjective and adaptive provisions.\n\n== Regulation of fully autonomous weapons ==\n{{main|Lethal autonomous weapon|}}\nLegal questions related to [[Lethal autonomous weapon|lethal autonomous weapons systems]] (LAWS), in particular compliance with [[International Humanitarian Law|the laws of armed conflict]], have been under discussion at the United Nations since 2013, within the context of the [[Convention on Certain Conventional Weapons]].<ref>{{cite web|url=https://unog.ch/80256EE600585943/(httpPages)/8FA3C2562A60FF81C1257CE600393DF6?OpenDocument|title=Background on Lethal Autonomous Weapons Systems in the CCW|publisher=United Nations Geneva}}</ref> Notably, informal meetings of experts took place in 2014, 2015 and 2016 and a Group of Governmental Experts (GGE) was appointed to further deliberate on the issue in 2016. A set of guiding principles on LAWS affirmed by the GGE on LAWS were adopted in 2018.<ref>{{cite web|url=https://www.unog.ch/80256EDD006B8954/(httpAssets)/815F8EE33B64DADDC12584B7004CF3A4/$file/CCW+MSP+2019+CRP.2+Rev+1.pdf|title=Guiding Principles affirmed by the Group of Governmental Experts on Emerging Technologies in the Area of Lethal Autonomous Weapons System|publisher=United Nations Geneva}}</ref>\n\nIn 2016, China published a position paper questioning the adequacy of existing international law to address the eventuality of fully autonomous weapons, becoming the first permanent member of the U.N. [[Security Council]] to broach the issue,<ref name=\"rwg\" /> and leading to proposals for global regulation.<ref>{{Cite journal|last=Baum|first=Seth|date=2018-09-30|title=Countering Superintelligence Misinformation|journal=Information|volume=9|issue=10|page=244|doi=10.3390/info9100244|issn=2078-2489|doi-access=free}}</ref> The possibility of a moratorium or preemptive ban of the development and use of LAWS has also been raised on several occasions by other national delegations to the Convention on Certain Conventional Weapons and is strongly advocated for by the [[Campaign to Stop Killer Robots]] \u2013 a coalition of non-governmental organizations.<ref>{{cite web|url=https://www.stopkillerrobots.org/wp-content/uploads/2019/10/KRC_CountryViews_25Oct2019rev.pdf|title=Country Views on Killer Robots|publisher=The Campaign to Stop Killer Robots}}</ref> The US government maintains that current international humanitarian law is capable of regulating the development or use of LAWS, and the US military does not have LAWS in its inventory.<ref>{{Cite book|last=Sayler|first=Kelley|url=https://fas.org/sgp/crs/natsec/R45178.pdf|title=Artificial Intelligence and National Security: Updated November 10, 2020|publisher=Congressional Research Service|year=2020|location=Washington, DC}}</ref>\n\n== See also ==\n* [[Artificial intelligence]]\n* [[Artificial intelligence arms race]]\n* [[AI alignment]]\n* [[Algorithmic accountability]]\n* [[Artificial intelligence in government]]\n* [[Ethics of artificial intelligence]]\n* [[Government by algorithm]]\n* [[Legal informatics]]\n* [[Regulation of algorithms]]\n* {{section link|Self-driving car liability|Artificial intelligence and liability}}\n\n== References ==\n{{reflist}}\n\n[[Category:Existential risk from artificial general intelligence]]\n[[Category:Computer law]]"}