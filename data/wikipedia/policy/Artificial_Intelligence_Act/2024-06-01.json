{"title": "Artificial Intelligence Act", "page_id": 68665578, "revision_id": 1226529489, "revision_timestamp": "2024-05-31T06:36:05Z", "content": "{{Short description|2024 European Union regulation on artificial intelligence}}\n{{Use dmy dates|date=May 2023}}\n\n{{Infobox EU legislation\n| number              = \n| type                = Regulation\n| EEA                 = \n| title               = Artificial Intelligence Act{{efn|name=longtitle}}\n| madeby              = [[European Parliament]] and [[European Council|Council]]\n| madeunder           = \n| OJrefurl            = \n| OJref               = \n| made                = \n| CouncilVote         = 21 May 2024\n| EPVote              = 13 March 2024\n| commenced           = <!-- Twentieth day following that of its publication in the Official Journal of the European Union -->\n| implementation      = \n| application         = \n| CommProp            = {{CELEX|52021PC0206|text=2021/206}}\n| ESCOpin             = \n| CROpin              = \n| ParlOpin            = \n| Reports             = \n| replaces            = \n| amends              = \n| amendedby           = \n| replacedby          = \n| status              = current\n}}\n\nThe '''Artificial Intelligence Act''' ('''AI Act'''){{efn|Officially the '''Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828'''|name=longtitle}} is a [[Regulation (European Union)|European Union regulation]] concerning [[artificial intelligence]] (AI).\n\nIt establishes a common regulatory and [[legal framework]] for AI within the [[European Union]] (EU).<ref>{{cite web |title=Proposal for a Regulation laying down harmonised rules on artificial intelligence: Shaping Europe's digital future |url=https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence |website=digital-strategy.ec.europa.eu |date=21 April 2021 |access-date=2023-01-09 |language=en |archive-date=4 January 2023 |archive-url=https://web.archive.org/web/20230104120436/https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence |url-status=live }}</ref> Proposed by the [[European Commission]] on 21 April 2021,<ref>{{Cite web |title=EUR-Lex \u2013 52021PC0206 \u2013 EN \u2013 EUR-Lex |url=https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206 |url-status=live |archive-url=https://web.archive.org/web/20210823212239/https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206 |archive-date=23 August 2021 |access-date=2021-09-07 |website=eur-lex.europa.eu}}</ref> it passed the [[European Parliament]] on 13 March 2024,<ref name=\"CNBC\">{{cite web |title=World's first major act to regulate AI passed by European lawmakers |url=https://www.cnbc.com/2024/03/13/european-lawmakers-endorse-worlds-first-major-act-to-regulate-ai.html |access-date=13 March 2024 |date=14 March 2024 |work=CNBC |archive-date=13 March 2024 |archive-url=https://web.archive.org/web/20240313120308/https://www.cnbc.com/2024/03/13/european-lawmakers-endorse-worlds-first-major-act-to-regulate-ai.html |url-status=live }}</ref> and was unanimously approved by the [[Council of the European Union|EU Council]] on 21 May 2024.<ref name=\"auto\">{{Cite web |last=Browne |first=Ryan |date=2024-05-21 |title=World's first major law for artificial intelligence gets final EU green light |url=https://www.cnbc.com/2024/05/21/worlds-first-major-law-for-artificial-intelligence-gets-final-eu-green-light.html |access-date=2024-05-22 |website=CNBC |language=en |archive-date=21 May 2024 |archive-url=https://web.archive.org/web/20240521235907/https://www.cnbc.com/2024/05/21/worlds-first-major-law-for-artificial-intelligence-gets-final-eu-green-light.html |url-status=live }}</ref> The Act also creates a European Artificial Intelligence Board to promote national cooperation and ensure compliance with the regulation.<ref>{{Cite web|last1=MacCarthy|first1=Mark|last2=Propp |first2=Kenneth |date=2021-05-04 |title=Machines learn that Brussels writes the rules: The EU's new AI regulation |url=https://www.brookings.edu/blog/techtank/2021/05/04/machines-learn-that-brussels-writes-the-rules-the-eus-new-ai-regulation/ |url-status=live |archive-url=https://web.archive.org/web/20221027115538/https://www.brookings.edu/blog/techtank/2021/05/04/machines-learn-that-brussels-writes-the-rules-the-eus-new-ai-regulation/ |archive-date=27 October 2022 |access-date=2021-09-07 |website=Brookings |language=en-US}}</ref> Like the EU's [[General Data Protection Regulation]], the Act can apply [[Extraterritoriality|extraterritorially]] to providers from outside the EU if they have users within the EU.<ref name=\":4\" />\n\nIt covers all types of AI across a broad range of sectors, with exceptions for AI systems used solely for military, national security, research and non-professional purposes.<ref>{{Cite news |date=9 December 2023 |title=Artificial intelligence act: Council and Parliament strike a deal on the first rules for AI in the world |url=https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/ |access-date=January 6, 2024 |work=Council of the EU |archive-date=10 January 2024 |archive-url=https://web.archive.org/web/20240110092304/https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/ |url-status=live }}</ref> As a piece of product regulation, it does not confer rights on individuals, but regulates the providers of AI systems and entities using AI in a professional context.<ref name=\":4\">{{Cite web |last=Mueller |first=Benjamin |date=2021-05-04 |title=The Artificial Intelligence Act: A Quick Explainer |url=https://datainnovation.org/2021/05/the-artificial-intelligence-act-a-quick-explainer/ |access-date=2024-01-06 |website=Center for Data Innovation |language=en-US |archive-date=14 October 2022 |archive-url=https://web.archive.org/web/20221014172842/http://datainnovation.org/2021/05/the-artificial-intelligence-act-a-quick-explainer/ |url-status=live }}</ref> The draft Act was revised to address the rise in popularity of [[generative artificial intelligence]] systems, such as [[ChatGPT]], whose general-purpose capabilities did not fit the main framework.<ref>{{Cite news |last=Coulter |first=Martin |date=December 7, 2023 |title=What is the EU AI Act and when will regulation come into effect? |url=https://www.reuters.com/technology/what-are-eus-landmark-ai-rules-2023-12-06/ |work=Reuters |access-date=11 January 2024 |archive-date=10 December 2023 |archive-url=https://web.archive.org/web/20231210214020/https://www.reuters.com/technology/what-are-eus-landmark-ai-rules-2023-12-06/ |url-status=live }}</ref> More restrictive regulations are planned for powerful generative AI systems with systemic impact.<ref name=\":1\">{{Cite web |last=Espinoza |first=Javier |date=December 9, 2023 |title=EU agrees landmark rules on artificial intelligence |url=https://www.ft.com/content/d5bec462-d948-4437-aab1-e6505031a303 |access-date=2024-01-06 |website=Financial Times |archive-date=29 December 2023 |archive-url=https://web.archive.org/web/20231229130308/https://www.ft.com/content/d5bec462-d948-4437-aab1-e6505031a303 |url-status=live }}</ref>\n\nThe Act classifies [[#Exemptions|non-exempted]] AI applications by their risk of causing harm. There are four levels\u2014unacceptable, high, limited, minimal\u2014plus an additional category for general-purpose AI. Applications with unacceptable risks are banned. High-risk applications must comply with security, [[transparency (behavior)|transparency]] and quality obligations, and undergo [[Conformity assessment|conformity assessments]]. Limited-risk applications only have transparency obligations, while minimal-risk applications are not regulated. For general-purpose AI, transparency requirements are imposed, with additional evaluations for high-capability models.<ref name=\":1\" /><ref name=\":2\">{{Cite news |title=EU AI Act: first regulation on artificial intelligence |url=https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence |access-date=2024-01-06 |work=European Parliament News |language=en |archive-date=10 January 2024 |archive-url=https://web.archive.org/web/20240110162551/https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence |url-status=live }}</ref>\n\n==Provisions==\n=== Risk categories ===\nThere are different risk categories depending on the type of application, with a specific category dedicated to general-purpose generative AI:\n\n* Unacceptable risk \u2013 AI applications in this category are banned, except for [[#Exemptions|specific exemptions]].<ref name=\"LQDN_technosolutionist_goldrush\" /> When no exemption applies, this includes AI applications that [[Manipulation (psychology)|manipulate human behaviour]], those that use real-time remote [[Biometrics|biometric]] identification (such as [[Facial recognition system|facial recognition]]) in public spaces, and those used for [[Social Credit System|social scoring]] (ranking individuals based on their personal characteristics, socio-economic status or behaviour).<ref name=\":2\" /> \n* High-risk \u2013 AI applications that are expected to pose significant threats to health, safety, or the [[fundamental rights]] of persons. Notably, AI systems used in health, education, recruitment, critical infrastructure management, law enforcement or justice. They are subject to quality, transparency, human oversight and safety obligations, and in some cases require a \"Fundamental Rights Impact Assessment\" before deployment.<ref>{{Citation |last=Mantelero |first=Alessandro |year=2022 |title=Beyond Data. Human Rights, Ethical and Social Impact Assessment in AI |series=Information Technology and Law Series |volume=36 |publisher= Springer-T.M.C. Asser Press |publication-place= The Hague |doi-access=free |doi=10.1007/978-94-6265-531-7 |isbn=978-94-6265-533-1 }}</ref> They must be evaluated both before they are placed on the market and throughout their life cycle. The list of high-risk applications can be expanded over time, without the need to modify the AI Act itself.<ref name=\":4\" />\n* General-purpose AI \u2013 Added in 2023, this category includes in particular [[foundation model]]s like ChatGPT. They are subject to transparency requirements. High-impact general-purpose AI systems which could pose systemic risks (notably those trained using a computational capability exceeding 10<sup>25</sup> [[FLOPS]])<ref name=\":3\">{{Cite web |last=Bertuzzi |first=Luca |date=2023-12-07 |title=AI Act: EU policymakers nail down rules on AI models, butt heads on law enforcement |url=https://www.euractiv.com/section/artificial-intelligence/news/ai-act-eu-policymakers-nail-down-rules-on-ai-models-butt-heads-on-law-enforcement/ |access-date=2024-01-06 |website=Euractiv |language=en-GB |archive-date=8 January 2024 |archive-url=https://web.archive.org/web/20240108215257/https://www.euractiv.com/section/artificial-intelligence/news/ai-act-eu-policymakers-nail-down-rules-on-ai-models-butt-heads-on-law-enforcement/ |url-status=live }}</ref> must also undergo a thorough evaluation process.<ref name=\":2\" />\n* Limited risk \u2013 AI systems in this category have transparency obligations, ensuring users are informed that they are interacting with an AI system and allowing them to make informed choices. This category includes, for example, AI applications that make it possible to generate or manipulate images, sound, or videos (like [[deepfake]]s).<ref name=\":2\" /> In this category, free models that are [[open source]] (''i.e.'', whose parameters are publicly available) are not regulated, with some exceptions.<ref name=\":3\" /><ref>{{cite web |title=Regulating Chatbots and Deepfakes |url=https://www.mhc.ie/hubs/the-eu-artificial-intelligence-act/regulating-chatbots-and-deepfakes-under-the-eu-ai-act |website=mhc.ie |publisher=Mason Hayes & Curran |language=en |access-date=11 January 2024 |archive-date=9 January 2024 |archive-url=https://web.archive.org/web/20240109141128/https://www.mhc.ie/hubs/the-eu-artificial-intelligence-act/regulating-chatbots-and-deepfakes-under-the-eu-ai-act |url-status=live }}</ref>\n* Minimal risk \u2013 This category includes, for example, AI systems used for video games or [[spam filters]]. Most AI applications are expected to fall into this category.<ref>{{Cite web |last=Liboreiro |first=Jorge |date=2021-04-21 |title='Higher risk, stricter rules': EU's new artificial intelligence rules |url=https://www.euronews.com/my-europe/2021/04/21/the-higher-the-risk-the-stricter-the-rule-brussels-new-draft-rules-on-artificial-intellige |access-date=2024-01-06 |website=Euronews |language=en |archive-date=6 January 2024 |archive-url=https://web.archive.org/web/20240106182629/https://www.euronews.com/my-europe/2021/04/21/the-higher-the-risk-the-stricter-the-rule-brussels-new-draft-rules-on-artificial-intellige |url-status=live }}</ref> These systems are not regulated, and Member States cannot impose additional regulations due to [[maximum harmonisation]] rules. Existing national laws regarding the design or use of such systems are overridden. However, a voluntary code of conduct is suggested.<ref name=\"Veale 20212\">{{Cite journal |last=Veale |first=Michael |date=2021 |title=Demystifying the Draft EU Artificial Intelligence Act |journal=Computer Law Review International |volume=22 |issue=4 |arxiv=2107.03721 |doi=10.31235/osf.io/38p5f |s2cid=241559535}}</ref>\n\n===Exemptions===\nArticles 2.3 and 2.6 exempt AI systems used for [[Artificial intelligence#Military|military]] or [[Artificial intelligence in government|national security]] purposes or pure scientific research and development from the AI Act.<ref name=\"LQDN_technosolutionist_goldrush\" />\n\nArticle 5.2 bans algorithmic video surveillance only if it is conducted in real time. Exceptions allowing real-time algorithmic video surveillance include policing aims including \"a real and present or real and foreseeable threat of terrorist attack\".<ref name=\"LQDN_technosolutionist_goldrush\">{{cite Q|Q126064181|url-status=live}}</ref>\n\nRecital 31 of the act prohibits \"AI systems providing social scoring of natural persons by public or private actors\", but allows for \"lawful evaluation practices of natural persons that are carried out for a specific purpose in accordance with Union and national law.\"<ref>{{Cite web |url=https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_EN.html |title=European Parliament legislative resolution of 13 March 2024 on the proposal for a regulation of the European Parliament and of the Council on laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts (COM(2021)0206 \u2013 C9-0146/2021 \u2013 2021/0106(COD)) |access-date=24 May 2024 |archive-date=21 May 2024 |archive-url=https://web.archive.org/web/20240521164731/https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_EN.html |url-status=live }}</ref> [[La Quadrature du Net]] interprets this exemption as permitting sector-specific social scoring systems,<ref name=\"LQDN_technosolutionist_goldrush\" /> such as the suspicion score used by the French family payments agency {{ill|Caisse d'allocations familiales|fr|Caisse d'allocations familiales (France)}}.<ref name=\"LQDN_notation_CAF\">{{cite Q|Q126066451|url-status=live}}</ref><ref name=\"LQDN_technosolutionist_goldrush\" />\n\n=== Institutional governance ===\nThe AI Act, per the European Parliament Legislative Resolution of 13 March 2024, includes the establishment of various new institutions in Article 64 and the following articles. These institutions are tasked with implementing and enforcing the AI Act. The approach is characterised by a multidimensional combination of centralised and decentralised, as well as public and private enforcement aspects, due to the interaction of various institutions and actors at both EU and national levels.\n\nThe following new institutions will be established:<ref>{{Cite news |last=Bertuzzi |first=Luca |date=November 21, 2023 |title=EU lawmakers to discuss AI rulebook's revised governance structure |url=https://www.euractiv.com/section/artificial-intelligence/news/eu-lawmakers-to-discuss-ai-rulebooks-revised-governance-structure/ |work=Euractiv |access-date=18 April 2024 |archive-date=22 May 2024 |archive-url=https://web.archive.org/web/20240522124047/https://www.euractiv.com/section/artificial-intelligence/news/eu-lawmakers-to-discuss-ai-rulebooks-revised-governance-structure/ |url-status=live }}</ref><ref name=\":7\">{{Cite journal |last1=Friedl |first1=Paul |last2=Gasiola |first2=Gustavo Gil |date=2024-02-07 |title=Examining the EU's Artificial Intelligence Act |url=https://verfassungsblog.de/examining-the-eus-artificial-intelligence-act/ |journal=Verfassungsblog |language=en-GB |access-date=16 April 2024 |archive-date=22 May 2024 |archive-url=https://web.archive.org/web/20240522124123/https://verfassungsblog.de/examining-the-eus-artificial-intelligence-act/ |url-status=live }}</ref>\n\n# AI Office: attached to the European Commission, this authority will coordinate the implementation of the AI Act in all Member States and oversee the compliance of general-purpose AI providers.\n# European Artificial Intelligence Board: composed of one representative from each Member State, the Board will advise and assist the Commission and Member States to facilitate the consistent and effective application of the AI Act. Its tasks include gathering and sharing technical and regulatory expertise, providing recommendations, written opinions, and other advice.\n# Advisory Forum: established to advise and provide technical expertise to the Board and the Commission, this forum will represent a balanced selection of stakeholders, including industry, start-ups, small and medium-sized enterprises, civil society, and academia, ensuring that a broad spectrum of opinions is represented during the implementation and application process.\n# Scientific Panel of Independent Experts: this panel will provide technical advice and input to the AI Office and national authorities, enforce rules for general-purpose AI models (notably by launching qualified alerts of possible risks to the AI Office), and ensure that the rules and implementations of the AI Act correspond to the latest scientific findings.\n\nWhile the establishment of new institutions is planned at the EU level, Member States will have to designate \"national competent authorities\".<ref>{{Cite web |date=13 March 2024 |title=Artificial Intelligence Act |url=https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206 |website=European Parliament |access-date=18 April 2024 |archive-date=18 April 2024 |archive-url=https://web.archive.org/web/20240418000949/https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206 |url-status=live }} Article 3 \u2013 definitions. Excerpt: \"'national competent authority' means the national supervisory authority, the notifying authority and the market surveillance authority;\"</ref> These authorities will be responsible for ensuring the application and implementation of the AI Act, and for conducting \"market surveillance\".<ref>{{Cite web |date=12 December 2023 |title=Artificial Intelligence \u2013 Questions and Answers |url=https://ec.europa.eu/commission/presscorner/detail/en/qanda_21_1683 |access-date=2024-04-17 |website=European Commission |archive-date=6 April 2024 |archive-url=https://web.archive.org/web/20240406232525/https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683 |url-status=live }}</ref> They will verify that AI systems comply with the regulations, notably by checking the proper performance of conformity assessments and by appointing third-parties to carry out external conformity assessments.\n\n=== Enforcement ===\nThe Act regulates the entry to the [[EU internal market]] using the New Legislative Framework. It contains essential requirements that all AI systems must meet to access the EU market. These essential requirements are passed on to European Standardisation Organisations, which develop technical standards that further detail these requirements.<ref>{{Cite journal |last=Tartaro |first=Alessio |date=2023 |title=Regulating by standards: current progress and main challenges in the standardisation of Artificial Intelligence in support of the AI Act. |url=https://universitypress.unisob.na.it/ojs/index.php/ejplt/article/view/1792 |journal=European Journal of Privacy Law and Technologies |volume=1 |issue=1 |via= |access-date=10 December 2023 |archive-date=3 December 2023 |archive-url=https://web.archive.org/web/20231203233559/https://universitypress.unisob.na.it/ojs/index.php/ejplt/article/view/1792 |url-status=live }}</ref>\n\nThe Act mandates that member states establish their own notifying bodies. Conformity assessments are conducted to verify whether AI systems comply with the standards set out in the AI Act.<ref>{{Cite web |title=EUR-Lex \u2013 52021SC0084 \u2013 EN \u2013 EUR-Lex |url=https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021SC0084 |access-date=2023-04-17 |website=eur-lex.europa.eu |language=en |archive-date=17 April 2023 |archive-url=https://web.archive.org/web/20230417093353/https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:52021SC0084 |url-status=live }}</ref> This assessment can be done in two ways: either through self-assessment, where the AI system provider checks conformity, or through third-party conformity assessment, where the notifying body conducts the assessment.<ref>{{Cite journal |last1=Veale |first1=Michael |last2=Borgesius |first2=Frederik Zuiderveen |date=2021-08-01 |title=Demystifying the Draft EU Artificial Intelligence Act \u2014 Analysing the good, the bad, and the unclear elements of the proposed approach |journal=Computer Law Review International |language=en |volume=22 |issue=4 |pages=97\u2013112 |doi=10.9785/cri-2021-220402 |arxiv=2107.03721 |s2cid=235765823 |issn=2194-4164}}</ref> Notifying bodies also have the authority to carry out audits to ensure proper conformity assessments.<ref>{{Cite journal |last=Casarosa |first=Federica |date=2022-06-01 |title=Cybersecurity certification of Artificial Intelligence: a missed opportunity to coordinate between the Artificial Intelligence Act and the Cybersecurity Act |journal=International Cybersecurity Law Review |language=en |volume=3 |issue=1 |pages=115\u2013130 |doi=10.1365/s43439-021-00043-6 |s2cid=258697805 |issn=2662-9739}}</ref>\n\nCriticism has arisen regarding the fact that many high-risk AI systems do not require third-party conformity assessments.<ref>{{cite web |last1=Smuha |first1=Nathalie A. |last2=Ahmed-Rengers |first2=Emma |last3=Harkens |first3=Adam |last4=Li |first4=Wenlong |last5=MacLaren |first5=James |last6=Piselli |first6=Riccardo |last7=Yeung |first7=Karen |date=2021-08-05 |title=How the EU Can Achieve Legally Trustworthy AI: A Response to the European Commission's Proposal for an Artificial Intelligence Act |url=https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3899991 |doi=10.2139/ssrn.3899991 |s2cid=239717302 |ssrn=3899991 |access-date=14 March 2024 |archive-date=26 February 2024 |archive-url=https://web.archive.org/web/20240226150629/https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3899991 |url-status=live }}</ref><ref>{{Cite journal |last1=Ebers |first1=Martin |last2=Hoch |first2=Veronica R. S. |last3=Rosenkranz |first3=Frank |last4=Ruschemeier |first4=Hannah |last5=Steinr\u00f6tter |first5=Bj\u00f6rn |date=December 2021 |title=The European Commission's Proposal for an Artificial Intelligence Act\u2014A Critical Assessment by Members of the Robotics and AI Law Society (RAILS) |journal=J |language=en |volume=4 |issue=4 |pages=589\u2013603 |doi=10.3390/j4040043 |issn=2571-8800 |doi-access=free }}</ref><ref>{{Cite journal |last1=Almada |first1=Marco |last2=Petit |first2=Nicolas |title=The EU AI Act: Between Product Safety and Fundamental Rights |url=https://papers.ssrn.com/abstract=4308072 | journal=Robert Schuman Centre for Advanced Studies Research Paper No. 2023/59| doi=10.2139/ssrn.4308072 |ssrn=4308072 |s2cid=255388310 | date=27 October 2023| access-date=14 March 2024 |archive-date=17 April 2023 |archive-url=https://web.archive.org/web/20230417093353/https://papers.ssrn.com/abstract=4308072 |url-status=live }}</ref> Some commentators argue that independent third-party assessments are necessary for high-risk AI systems to ensure safety before deployment. Legal scholars have suggested that AI systems capable of generating deepfakes for political misinformation or creating non-consensual intimate imagery should be classified as high-risk and subjected to stricter regulation.<ref>{{cite journal |last=Romero-Moreno |first=Felipe |date=29 March 2024 |title=Generative AI and deepfakes: a human rights approach to tackling harmful content |journal=International Review of Law, Computers & Technology |volume=39 |issue=2 |pages=1\u201330|doi-access=free |doi=10.1080/13600869.2024.2324540 |issn=1360-0869 |hdl-access=free |hdl=2299/20431}}</ref>\n\n== Legislative procedure ==\n{{further|European Union legislative procedure}}\nIn February 2020, the [[European Commission]] published \"White Paper on Artificial Intelligence \u2013 A European approach to excellence and trust\".<ref>{{Cite web |date=2020-02-19 |title=White Paper on Artificial Intelligence \u2013 a European approach to excellence and trust |url=https://digital-strategy.ec.europa.eu/en/consultations/white-paper-artificial-intelligence-european-approach-excellence-and-trust |access-date=2024-01-06 |website= |publisher=[[European Commission]] |language=en |archive-date=5 January 2024 |archive-url=https://web.archive.org/web/20240105090033/https://digital-strategy.ec.europa.eu/en/consultations/white-paper-artificial-intelligence-european-approach-excellence-and-trust |url-status=live }}</ref> In October 2020, debates between EU leaders took place in the [[European Council]]. On 21 April 2021, the AI Act was officially proposed by the Commission. On 6 December 2022, the European Council adopted the general orientation, allowing negotiations to begin with the [[European Parliament]]. On 9 December 2023, after three days of \"marathon\" talks, the [[Council of the European Union|EU Council]] and Parliament concluded an agreement.<ref>{{Cite web |date=9 December 2023|title=Timeline \u2013 Artificial intelligence |url=https://www.consilium.europa.eu/en/policies/artificial-intelligence/timeline-artificial-intelligence/ |access-date=6 January 2024 |publisher=[[European Council]] |archive-date=6 January 2024 |archive-url=https://web.archive.org/web/20240106182627/https://www.consilium.europa.eu/en/policies/artificial-intelligence/timeline-artificial-intelligence/ |url-status=live }}</ref>\n\nThe law was passed in the European Parliament on 13 March 2024, by a vote of 523 for, 46 against, and 49 abstaining.<ref name=EUParliamentPassage>{{Cite web |date=2024-03-13 |title=Artificial Intelligence Act: MEPs adopt landmark law |url=https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law |access-date=2024-03-14 |website=European Parliament |language=en |archive-date=15 March 2024 |archive-url=https://web.archive.org/web/20240315034359/https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law |url-status=live }}</ref> It was approved by the EU Council on 21 May 2024.<ref name=\"auto\"/> It will come into force 20 days after being published in the ''[[Official Journal of the European Union|Official Journal]]'' at the end of the legislative term in May.<ref name=\"CNBC\"/><ref name=\":0\">{{Cite web |last=David |first=Emilia |date=2023-12-14 |title=The EU AI Act passed \u2014 now comes the waiting |url=https://www.theverge.com/2023/12/14/24001919/eu-ai-act-foundation-models-regulation-data |url-status=live |archive-url=https://web.archive.org/web/20240110235258/https://www.theverge.com/2023/12/14/24001919/eu-ai-act-foundation-models-regulation-data |archive-date=10 January 2024 |access-date=2024-01-06 |website=The Verge |language=en}}</ref> After coming into force, there will be a delay before it becomes applicable, which depends on the type of application. This delay is 6 months for bans on \"unacceptable risk\" AI systems, 9 months for codes of practice, 12 months for general-purpose AI systems, 36 months for some obligations related to \"high-risk\" AI systems, and 24 months for everything else.<ref name=\":0\" /><ref name=EUParliamentPassage/>\n\n==Reactions==\nExperts have argued that though the jurisdiction of the law is European, it could have far-ranging implications for international companies that plan to expand to Europe.<ref name=\":5\">{{Cite web |date=2023-12-11 |title=Europe agreed on world-leading AI rules. How do they work and will they affect people everywhere? |url=https://apnews.com/article/eu-ai-act-artificial-intelligence-regulation-0283a10a891a24703068edcae3d60deb |access-date=2024-05-31 |website=AP News |language=en}}</ref> [[Anu Bradford]] at [[Columbia University|Columbia]] has argued that the law provides significant momentum to the world-wide movement to regulate AI technologies.<ref name=\":5\" /> \n\n[[Amnesty International]] criticized the AI Act for not completely banning real-time [[Facial recognition system|facial recognition]], which they said could damage \"human rights, civil space and rule of law\" in the European Union. It also criticized the absence of ban on ''exporting'' AI technologies that can harm human rights.<ref name=\":5\" /> \n\nSome tech watchdogs have argued that there were major loopholes in the law that would allow large tech monopolies to entrench their advantage in AI, or to lobby to weaken rules.<ref>{{Cite web |title=EU parliament greenlights landmark artificial intelligence regulations |url=https://www.aljazeera.com/news/2024/3/13/eu-parliament-greenlights-landmark-artificial-intelligence-regulations |access-date=2024-05-31 |website=Al Jazeera |language=en}}</ref><ref name=\":6\" /> Some startups welcomed the clarification the act provides, while others argued the additional regulation would make European startups uncompetitive compared to American and Chinese startups.<ref name=\":6\">{{Cite web |date=2024-03-16 |title=The EU passed the first AI law. Tech experts say it\u2019s \u2018bittersweet\u2019 |url=https://www.euronews.com/next/2024/03/16/eu-ai-act-reaction-tech-experts-say-the-worlds-first-ai-law-is-historic-but-bittersweet |access-date=2024-05-31 |website=euronews |language=en}}</ref> [[La Quadrature du Net]] (LQDN) described the AI Act as \"tailor-made for the tech industry, European police forces as well as other large bureaucracies eager to automate social control\". LQDN described the role of self-regulation and exemptions in the act to render it \"largely incapable of standing in the way of the social, political and environmental damage linked to the proliferation of AI\".<ref name=\"LQDN_technosolutionist_goldrush\" />\n\n== See also ==\n* [[Algorithmic bias]]\n* [[Ethics of artificial intelligence]]\n* [[Regulation of algorithms]]\n* [[Regulation of artificial intelligence in the European Union]]\n* [[Existential risk from artificial general intelligence]]\n\n==Notes==\n{{notelist}}\n\n== References ==\n{{reflist}}\n\n== External links ==\n* [https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138-FNL-COR01_EN.pdf Artificial Intelligence Act] (19 April 2024 corrected version, {{webarchive|url=https://web.archive.org/web/20240521131008/https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138-FNL-COR01_EN.pdf|date=21 May 2024}})\n\n{{Existential risk from artificial intelligence}}\n{{authority control}}\n\n[[Category:Policies of the European Union]]\n[[Category:European Digital Strategy]]\n[[Category:2021 in law]]\n[[Category:2021 in the European Union]]\n[[Category:2024 in law]]\n[[Category:2024 in politics]]\n[[Category:Artificial intelligence]]\n[[Category:Data laws]]\n[[Category:Draft European Union laws]]\n[[Category:Regulation of robots]]\n[[Category:Regulation of artificial intelligence]]"}