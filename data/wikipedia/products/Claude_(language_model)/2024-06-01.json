{"title": "Claude (language model)", "page_id": 75879512, "revision_id": 1226017875, "revision_timestamp": "2024-05-28T03:03:56Z", "content": "{{Short description|Large language model by Anthropic}}\n\n{{Infobox software\n| title = Claude\n| logo = \n| developer = [[Anthropic]]\n| released = {{start date and age|2023|3}}\n| replaces = \n| replaced_by = \n| genre = {{ indented plainlist |\n*[[Large language model]]\n*[[Generative pre-trained transformer|GPT]]\n*[[Foundation model]]\n}}\n| license = [[Proprietary software|Proprietary]]\n| website = {{URL|https://claude.ai}}\n}}\n'''Claude''' is a family of [[large language model|large language models]] developed by [[Anthropic]].<ref name=\":0\" /> The first model was released in March 2023. Claude 3, released in March 2024, can also analyze images.<ref name=\":2\" />\n\n== Training ==\nClaude models are [[Generative pre-trained transformer|generative pre-trained transformers]]. They have been pre-trained to predict the next word in large amounts of text. Claude models have then been fine-tuned with Constitutional AI with the aim of making them helpful, honest, and harmless.<ref name=\"auto\" /><ref name=\":4\">{{Cite web |date=May 9, 2023 |title=Claude's Constitution |url=https://www.anthropic.com/news/claudes-constitution |access-date=2024-03-26 |website=Anthropic |language=en}}</ref>\n\n=== Constitutional AI ===\nConstitutional AI is an approach developed by Anthropic for training AI systems, particularly language models like Claude, to be harmless and helpful without relying on extensive human feedback. The method, detailed in the paper \"Constitutional AI: Harmlessness from AI Feedback\" involves two phases: [[supervised learning]] and [[reinforcement learning]].<ref name=\":4\" />\n\nIn the supervised learning phase, the model generates responses to prompts, self-critiques these responses based on a set of guiding principles (a \"constitution\"), and revises the responses. Then the model is fine-tuned on these revised responses.<ref name=\":4\" />\n\nFor the reinforcement learning from AI feedback (RLAIF) phase, responses are generated and compared according to their compliance with the constitution. This dataset of AI feedback is used to train a preference model that evaluates responses based on how much they satisfy the constitution. Claude is then fine-tuned to [[AI alignment|align]] with this preference model. This technique is similar to [[reinforcement learning from human feedback]] (RLHF), except that the comparisons used to train the preference model are AI-generated, and that they are based on the constitution.<ref>{{Cite web |last=Eliot |first=Lance |date=May 25, 2023 |title=Latest Generative AI Boldly Labeled As Constitutional AI Such As Claude By Anthropic Has Heart In The Right Place, Says AI Ethics And AI Law |url=https://www.forbes.com/sites/lanceeliot/2023/05/25/latest-generative-ai-boldly-labeled-as-constitutional-ai-such-as-claude-by-anthropic-has-heart-in-the-right-place-says-ai-ethics-and-ai-law/ |access-date=2024-03-27 |website=Forbes |language=en}}</ref><ref name=\":4\" />\n\nThis approach enables the training of AI assistants that are both helpful and harmless, and that can explain their objections to harmful requests, enhancing transparency and reducing reliance on human supervision.<ref name=\"auto1\">{{Citation |last1=Bai |first1=Yuntao |title=Constitutional AI: Harmlessness from AI Feedback |date=2022-12-15 |arxiv=2212.08073 |last2=Kadavath |first2=Saurav |last3=Kundu |first3=Sandipan |last4=Askell |first4=Amanda |last5=Kernion |first5=Jackson |last6=Jones |first6=Andy |last7=Chen |first7=Anna |last8=Goldie |first8=Anna |last9=Mirhoseini |first9=Azalia}}</ref><ref>{{Cite web |last=Mok |first=Aaron |title=A ChatGPT rival just published a new constitution to level up its AI guardrails, and prevent toxic and racist responses |url=https://www.businessinsider.com/anthropic-new-crowd-sourced-ai-constitution-accuracy-safety-toxic-racist-2023-10 |access-date=2024-01-23 |website=Business Insider |language=en-US}}</ref>\n\nThe \"constitution\" for Claude included 75 points, including sections from the [[Universal Declaration of Human Rights|UN Universal Declaration of Human Rights]].<ref name=\"auto1\"/><ref name=\"auto\">{{Cite magazine |date=2023-07-18 |title=What to Know About Claude 2, Anthropic's Rival to ChatGPT |url=https://time.com/6295523/claude-2-anthropic-chatgpt/ |access-date=2024-01-23 |magazine=TIME |language=en}}</ref>\n\n== Models ==\n\n=== Claude ===\nClaude was the initial version of Anthropic's language model released in March 2023,<ref name=\":02\">{{Cite web |last=Drapkin |first=Aaron |date=2023-10-27 |title=What Is Claude AI and Anthropic? ChatGPT's Rival Explained |url=https://tech.co/news/what-is-claude-ai-anthropic |access-date=2024-01-23 |website=Tech.co |language=en-US}}</ref> Claude demonstrated proficiency in various tasks but had certain limitations in coding, math, and reasoning capabilities.<ref name=\":3\">{{Cite web |date=March 14, 2023 |title=Introducing Claude |url=https://www.anthropic.com/news/introducing-claude |website=Anthropic}}</ref> Anthropic partnered with companies like [[Notion (productivity software)|Notion]] (productivity software) and [[Quora]] (to help develop the [[Poe (chatbot)|Poe]] chatbot).<ref name=\":3\" />\n\n=== Claude Instant ===\nClaude was released as two versions, Claude and Claude Instant, with Claude Instant being a faster, less expensive and lighter version. Claude Instant has an input context length of 100,000 [[Lexical analysis|tokens]] (which corresponds to around 75,000 words).<ref>{{Cite news |last=Yao |first=Deborah |date=August 11, 2023 |title=Anthropic's Claude Instant: A Smaller, Faster and Cheaper Language Model |url=https://aibusiness.com/nlp/anthropic-s-claude-instant-a-smaller-faster-and-cheaper-language-model |work=AI Business}}</ref>\n\n=== Claude 2 ===\nClaude 2 was the next major iteration of Claude, which was released in July 11 2023 and available to the general public, whereas the Claude 1 was only available to selected users approved by Anthropic.<ref>{{Cite web |last=Matthews |first=Dylan |date=2023-07-17 |title=The $1 billion gamble to ensure AI doesn't destroy humanity |url=https://www.vox.com/future-perfect/23794855/anthropic-ai-openai-claude-2 |access-date=2024-01-23 |website=Vox |language=en}}</ref>\n\nClaude 2 expanded its context window from 9,000 tokens to 100,000 tokens.<ref name=\":02\" /> Features included ability to upload [[PDF]]s and other documents that enables Claude to read, summarise and assist with tasks.\n\n==== Claude 2.1 ====\nClaude 2.1 doubled the number of tokens that the chatbot could handle, increasing it to a window of 200,000 tokens, which equals around 500 pages of written material.<ref name=\":0\">{{Cite web |last=Davis |first=Wes |date=2023-11-21 |title=OpenAI rival Anthropic makes its Claude chatbot even more useful |url=https://www.theverge.com/2023/11/21/23971070/anthropic-claude-2-1-openai-ai-chatbot-update-beta-tools |access-date=2024-01-23 |website=The Verge |language=en}}</ref>\n\nAnthropic states that the new model is less likely to produce false statements compared to its predecessors.<ref name=\":1\">{{Cite web |title=Anthropic Announces Claude 2.1 LLM with Wider Context Window and Support for AI Tools |url=https://www.infoq.com/news/2023/11/anthropic-announces-claude-2-1/ |access-date=2024-01-23 |website=InfoQ |language=en}}</ref>\n\n=== {{Anchor|Claude 3}}Claude 3 ===\nClaude 3 was released on March 14, 2024 with claims in the press release to have set new industry benchmarks across a wide range of cognitive tasks. The Claude 3 family includes three state-of-the-art models in ascending order of capability: Haiku, Sonnet, and Opus. The default version of Claude 3, Opus, has a context window of 200,000 tokens, but this is being expanded to 1 million for specific use cases.<ref>{{Cite web |title=Introducing the next generation of Claude |url=https://www.anthropic.com/news/claude-3-family |access-date=2024-03-04 |website=Anthropic |language=en}}</ref><ref name=\":2\">{{Cite web |last=Whitney |first=Lance |date=March 4, 2024 |title=Anthropic's Claude 3 chatbot claims to outperform ChatGPT, Gemini |url=https://www.zdnet.com/article/anthropics-claude-3-chatbot-claims-to-outperform-chatgpt-gemini/ |access-date=2024-03-05 |website=ZDNET |language=en}}</ref>\n\nClaude 3 has seemed to perform [[Metacognition|meta-cognitive reasoning]], including the ability to realize it is being artificially tested during [[needle in a haystack test]]s.<ref>{{Cite web |last=Edwards |first=Benj |date=2024-03-05 |title=Anthropic's Claude 3 causes stir by seeming to realize when it was being tested |url=https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/ |access-date=2024-03-09 |website=Ars Technica |language=en-us}}</ref>\n\n== Access ==\nLimited-use access is free of charge, but requires both an e-mail address and a cellphone number.\n\nOn May 1, 2024, Anthropic announced the Claude Team plan, its first enterprise offering for Claude, and a Claude [[iOS app]].<ref>{{Cite news |last=Field |first=Hayden |date=May 1, 2024 |title=Amazon-backed Anthropic launches iPhone app and business tier to compete with OpenAI's ChatGPT |url=https://www.cnbc.com/2024/05/01/anthropic-iphone-ai-app-business-plan-to-compete-with-openai-announced.html |url-status=live |access-date=May 3, 2024 |work=[[CNBC]]}}</ref>\n\n== Criticism ==\n\nClaude 2 has faced criticism for its stringent ethical alignment that may reduce usability and performance. Users have been refused assistance with benign requests, for example with the programming question \"How can I [[Kill (command)|kill]] all [[Python (programming language)|python]] processes in my [[ubuntu]] server?\" This has led to a debate over the \"alignment tax\" (the cost of ensuring an AI system is [[AI alignment|aligned]]) in AI development, with discussions centered on balancing ethical considerations and practical functionality. Critics argue for user autonomy and effectiveness, while proponents stress the importance of ethical AI.<ref name=\":22\">{{Cite web |last=Glifton |first=Gerald |date=January 3, 2024 |title=Criticisms Arise Over Claude AI's Strict Ethical Protocols Limiting User Assistance |url=https://lightsquare.org/news/criticisms-arise-over-claude-ais-strict-ethical-protocols-limiting-user-assistance |access-date=2024-01-23 |website=Light Square |language=en}}</ref><ref name=\":1\" />\n\n== References ==\n<references />\n[[Category:Artificial intelligence]]\n[[Category:Machine learning]]\n[[Category:Large language models]]\n[[Category:Chatbots]]\n[[Category:Virtual assistants]]\n[[Category:2023 software]]"}