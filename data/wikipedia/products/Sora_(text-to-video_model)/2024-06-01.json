{"title": "Sora (text-to-video model)", "page_id": 76106601, "revision_id": 1225920595, "revision_timestamp": "2024-05-27T14:42:37Z", "content": "{{Short description|Text-to-video model by OpenAI}}\n{{Use mdy dates|date=February 2024}}\n{{Infobox software\n| screenshot = File:Photoreal-train.webm\n| screenshot size = 300px\n| caption = A video generated by Sora. It depicts the [[Glenfinnan Viaduct]], but with two rail lines rather than one, and the train resembles [[The Jacobite (steam train)|The Jacobite]], with two [[Chimney (locomotive)|chimney]]s rather than one.\n| developer = [[OpenAI]]\n| genre = [[Text-to-video model]]\n| released = \n| platform = OpenAI\n}}\n{{Artificial intelligence}}\n\n'''Sora''' is an upcoming [[generative artificial intelligence]] model developed by  [[OpenAI]], that specializes in [[text-to-video model|text-to-video]] generation. The model accepts textual descriptions, known as [[prompt engineering|prompts]], from users and generates short video clips corresponding to those descriptions. Prompts can specify artistic styles, fantastical imagery, or real-world scenarios. When creating real-world scenarios, user input may be required to ensure factual accuracy, otherwise features can be added [[Hallucination_(artificial_intelligence)|erroneously]]. Sora is praised for its ability to produce videos with high levels of visual detail, including intricate camera movements and characters that exhibit a range of emotions. Furthermore, the model possesses the functionality to extend existing short videos by generating new content that seamlessly precedes or follows the original clip.<ref name=\"NYT_CM_2024_02_15\">{{cite news |author=Metz |first=Cade |date=February 15, 2024 |title=OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos |url=https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html |work=[[The New York Times]] |publisher= |access-date=February 15, 2024 |archive-date=February 15, 2024 |archive-url=https://web.archive.org/web/20240215220626/https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html |url-status=live }}</ref><ref name=\"OAI_research\"/><ref>{{cite news|last=Roth|first=Emma|date=February 15, 2024|title=OpenAI introduces Sora, its text-to-video AI model|url=https://www.theverge.com/2024/2/15/24074151/openai-sora-text-to-video-ai|work=[[The Verge]]|access-date=February 21, 2024|archive-date=February 21, 2024|archive-url=https://web.archive.org/web/20240221042044/https://www.theverge.com/2024/2/15/24074151/openai-sora-text-to-video-ai|url-status=live}}</ref> {{As of|2024|05|post=,}} it is unreleased and not yet available to the public.<ref name=\"NBC\" />\n\n==History==\nSeveral other text-to-video generating models had been created prior to Sora, including [[Meta Platforms|Meta]]'s Make-A-Video, [[Runway (company)|Runway]]'s Gen-2, and [[Google]]'s Lumiere, the last of which, {{As of|February 2024|lc=y|post=,}} is also still in its research phase.<ref name=\"Wired\" /> [[OpenAI]], the company behind Sora, had released [[DALL-E|DALL\u00b7E 3]], the third of its DALL-E [[text-to-image model]]s, in September 2023.<ref name=\"CNET\">{{cite web |last1=Lacy |first1=Lisa |title=Meet Sora, OpenAI's Text-to-Video Generator |url=https://www.cnet.com/tech/meet-sora-openais-text-to-video-generator/ |website=[[CNET]] |access-date=February 16, 2024 |date=February 15, 2024 |archive-date=February 16, 2024 |archive-url=https://web.archive.org/web/20240216004932/https://www.cnet.com/tech/meet-sora-openais-text-to-video-generator/ |url-status=live }}</ref>\n\nThe team that developed Sora named it after [[:Wiktionary:\u7a7a#Japanese|the Japanese word for sky]] to signify its \"limitless creative potential\".<ref name=\"NYT_CM_2024_02_15\"/> On February 15, 2024, OpenAI first previewed Sora by releasing multiple clips of [[high-definition video]]s that it created, including an [[SUV]] driving down a mountain road, an animation of a \"short fluffy monster\" next to a candle, two people walking through [[Tokyo]] in the snow, and fake historical footage of the [[California gold rush]], and stated that it was able to generate videos up to one minute long.<ref name=\"Wired\" /> The company then shared a technical report, which highlighted the methods used to train the model.<ref name=\"OAI_research\">{{cite web |last1=Brooks |first1=Tim |last2=Peebles |first2=Bill |last3=Holmes |first3=Connor |last4=DePue |first4=Will |last5=Guo |first5=Yufei |last6=Jing |first6=Li |last7=Schnurr |first7=David |last8=Taylor |first8=Joe |last9=Luhman |first9=Troy |date=February 15, 2024 |title=Video generation models as world simulators |url=https://openai.com/research/video-generation-models-as-world-simulators |url-status=live |website=[[OpenAI]] |publisher= |first10=Eric |last10=Luhman |first11=Clarence Wing Yin |last11=Ng |first12=Ricky |last12=Wang |first13=Aditya |last13=Ramesh |access-date=February 16, 2024 |archive-date=February 16, 2024 |archive-url=https://web.archive.org/web/20240216072133/https://openai.com/research/video-generation-models-as-world-simulators }}</ref><ref name=\"ars\"/> OpenAI CEO [[Sam Altman]] also posted a series of tweets, responding to [[Twitter]] users' prompts with Sora-generated videos of the prompts.\n\nOpenAI has stated that it plans to make Sora available to the public but that it would not be soon; it has not specified when.<ref name=\"Wired\">{{cite magazine |last1=Levy |first1=Steven |author-link=Steven Levy |date=February 15, 2024 |title=OpenAI's Sora Turns AI Prompts Into Photorealistic Videos |url=https://www.wired.com/story/openai-sora-generative-ai-video/ |access-date=February 16, 2024 |magazine=[[Wired (magazine)|Wired]] |archive-date=February 15, 2024 |archive-url=https://web.archive.org/web/20240215234655/https://www.wired.com/story/openai-sora-generative-ai-video/ |url-status=live }}</ref><ref name=\"NBC\">{{cite web |last1=Yang |first1=Angela |date=February 15, 2024 |title=OpenAI teases 'Sora,' its new text-to-video AI model |url=https://www.nbcnews.com/tech/tech-news/openai-sora-video-artificial-intelligence-unveiled-rcna139065 |access-date=February 16, 2024 |website=[[NBC News]] |publisher= |archive-date=February 15, 2024 |archive-url=https://web.archive.org/web/20240215235542/https://www.nbcnews.com/tech/tech-news/openai-sora-video-artificial-intelligence-unveiled-rcna139065 |url-status=live }}</ref> The company provided limited access to a small \"[[red team]]\", including experts in misinformation and bias, to perform [[Adversarial machine learning|adversarial testing]] on the model.<ref name=\"CNET\" /> The company also shared Sora with a small group of creative professionals, including video makers and artists, to seek feedback on its usefulness in creative fields.<ref name=\"WDH_MIT_2024_02_15\">{{cite web |author=Heaven |first=Will Douglas |date=February 15, 2024 |title=OpenAI teases an amazing new generative video model called Sora |url=https://www.technologyreview.com/2024/02/15/1088401/openai-amazing-new-generative-ai-video-model-sora/ |website=[[MIT Technology Review]] |publisher= |access-date=February 15, 2024 |archive-date=February 15, 2024 |archive-url=https://web.archive.org/web/20240215220619/https://www.technologyreview.com/2024/02/15/1088401/openai-amazing-new-generative-ai-video-model-sora/ |url-status=live }}</ref>\n\n==Capabilities and limitations==\n[[file:Cat-on-bed.webm|thumb|right|200px|A video generated by Sora of someone lying in a bed with a cat on it, containing several mistakes]]\nThe technology behind Sora is an adaptation of the technology behind [[DALL-E 3]]. According to OpenAI, Sora is a diffusion transformer<ref>{{Cite book |last1=Peebles |first1=William |last2=Xie |first2=Saining |chapter=Scalable Diffusion Models with Transformers |date=2023 |title=2023 IEEE/CVF International Conference on Computer Vision (ICCV) |chapter-url=https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html |volume= |pages=4172\u20134182 |doi=10.1109/ICCV51070.2023.00387 |arxiv=2212.09748 |isbn=979-8-3503-0718-4 |s2cid=254854389 |issn=2380-7504 |access-date=February 17, 2024 |archive-date=February 17, 2024 |archive-url=https://web.archive.org/web/20240217080434/https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html |url-status=live }}</ref> \u2013 a [[Diffusion model|denoising latent diffusion model]] with one [[Transformer (deep learning architecture)|Transformer]] as the denoiser. A video is generated in latent space by denoising 3D \"patches\", then transformed to standard space by a video decompressor. Re-captioning is used to [[Data augmentation|augment training data]], by using a video-to-text model to create detailed captions on videos.<ref name=\"ars\">{{Cite web |last=Edwards |first=Benj |date=February 16, 2024 |title=OpenAI collapses media reality with Sora, a photorealistic AI video generator |url=https://arstechnica.com/information-technology/2024/02/openai-collapses-media-reality-with-sora-a-photorealistic-ai-video-generator/ |access-date=February 17, 2024 |website=[[Ars Technica]] |language=en-us |archive-date=February 17, 2024 |archive-url=https://web.archive.org/web/20240217000922/https://arstechnica.com/information-technology/2024/02/openai-collapses-media-reality-with-sora-a-photorealistic-ai-video-generator/ |url-status=live }}</ref> \n\nOpenAI trained the model using publicly available videos as well as copyrighted videos licensed for the purpose, but did not reveal the number or the exact source of the videos.<ref name=\"NYT_CM_2024_02_15\"/> Upon its release, OpenAI acknowledged some of Sora's shortcomings, including its struggling to simulate complex physics, to understand [[causality]], and to differentiate left from right.<ref>{{cite news |author=Peque\u00f1o IV |first=Antonio |date=February 15, 2024 |title=OpenAI Reveals 'Sora': AI Video Model Capable Of Realistic Text-To-Video Prompts |url=https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/ |work=[[Forbes]] |publisher= |access-date=February 15, 2024 |archive-date=February 15, 2024 |archive-url=https://web.archive.org/web/20240215220634/https://www.forbes.com/sites/antoniopequenoiv/2024/02/15/openai-reveals-sora-ai-video-model-capable-of-realistic-text-to-video-prompts/ |url-status=live }}</ref> One example shows a group of wolf pups seemingly multiplying and converging, creating a hard-to-follow scenario.<ref>{{cite web |title=Sora-generated video of wolves playing with some video issues |url=https://www.abc.net.au/news/2024-02-16/sora-generated-video-of-wolves-playing-with-some-video-issues-/103476602 |website=ABC News Australia |access-date=16 May 2024}}</ref> OpenAI also stated that, in adherence to the company's existing safety practices, Sora will restrict text prompts for sexual, violent, hateful, or celebrity imagery, as well as content featuring pre-existing [[intellectual property]].<ref name=\"CNET\" />\n\nTim Brooks, a researcher on Sora, stated that the model figured out how to create [[3D computer graphics|3D graphics]] from its dataset alone, while Bill Peebles, also a Sora researcher, said that the model automatically created different video angles without being prompted.<ref name=\"Wired\" /> According to OpenAI, Sora-generated videos are tagged with [[Content Authenticity Initiative|C2PA metadata]] to indicate that they were AI-generated.<ref name=\"NYT_CM_2024_02_15\" />\n\n==Reception==\nWill Douglas Heaven of the ''[[MIT Technology Review]]'' called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and may not be representative of Sora's typical output.<ref name=\"WDH_MIT_2024_02_15\"/> American academic [[Oren Etzioni]] expressed concerns over the technology's ability to create online [[disinformation]] for political campaigns.<ref name=\"NYT_CM_2024_02_15\"/> For ''[[Wired (magazine)|Wired]]'', [[Steven Levy]] similarly wrote that it had the potential to become \"a misinformation train wreck\" and opined that its preview clips were \"impressive\" but \"not perfect\" and that it \"show[ed] an emergent grasp of cinematic grammar\" due to its unprompted shot changes. Levy added, \"[i]t will be a very long time, if ever, before text-to-video threatens actual filmmaking.\"<ref name=\"Wired\" /> Lisa Lacy of [[CNET]] called its example videos \"remarkably realistic \u2013 except perhaps when a human face appears close up or when sea creatures are swimming\".<ref name=\"CNET\" />\n\nFilmmaker [[Tyler Perry]] announced he would be putting a planned $800 million expansion of his [[Atlanta]] studio on hold, expressing concern about Sora's potential impact on the film industry.<ref>{{Cite web |last=Kilkenny |first=Katie |date=2024-02-23 |title=Tyler Perry Puts $800M Studio Expansion on Hold After Seeing OpenAI's Sora: \"Jobs Are Going to Be Lost\" |url=https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/ |access-date=2024-02-26 |website=The Hollywood Reporter |language=en-US |archive-date=February 26, 2024 |archive-url=https://web.archive.org/web/20240226021123/https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/ |url-status=live }}</ref><ref>{{Cite web |last=Edwards |first=Benj |date=2024-02-23 |title=Tyler Perry puts $800 million studio expansion on hold because of OpenAI's Sora |url=https://arstechnica.com/information-technology/2024/02/i-just-dont-see-how-we-survive-tyler-perry-issues-hollywood-warning-over-ai-video-tech/ |access-date=2024-02-26 |website=Ars Technica |language=en-us |archive-date=February 26, 2024 |archive-url=https://web.archive.org/web/20240226021124/https://arstechnica.com/information-technology/2024/02/i-just-dont-see-how-we-survive-tyler-perry-issues-hollywood-warning-over-ai-video-tech/ |url-status=live }}</ref>\n\n== See also ==\n* {{annotated link|VideoPoet}}\n<!--* Runway [[Stable Diffusion]] (by [[Runway (company)#Stable Diffusion|Runway]])\n* HeyGen, D-ID, Kaiber, AI Studios, Synthesia-->\n\n==References==\n{{reflist}}\n\n== External links ==\n{{Commons category|Sora (text-to-video model)|Sora}}\n* {{Official website|https://openai.com/sora}}\n\n{{OpenAI navbox}}\n\n[[Category:OpenAI]]\n[[Category:Applications of artificial intelligence]]\n[[Category:2024 software]]\n[[Category:Video processing]]\n[[Category:Film and video technology]]"}