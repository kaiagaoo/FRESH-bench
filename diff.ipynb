{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3edb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import diff_match_patch as dmp_module\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()  # Automatically uses OPENAI_API_KEY from environment\n",
    "dmp = dmp_module.diff_match_patch()  # Myers diff implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6de5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_myers_diff(text_t1: str, text_t2: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get Myers diff between two Wikipedia snapshots.\n",
    "    Uses Google's diff-match-patch library which implements Myers algorithm.\n",
    "    Returns structured change objects with context.\n",
    "    \"\"\"\n",
    "    # Compute Myers diff\n",
    "    diffs = dmp.diff_main(text_t1, text_t2)\n",
    "    dmp.diff_cleanupSemantic(diffs)  # Clean up for human readability\n",
    "    \n",
    "    changes = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(diffs):\n",
    "        op, text = diffs[i]\n",
    "        \n",
    "        # op: -1 = DELETE, 0 = EQUAL, 1 = INSERT\n",
    "        if op == -1:  # Deletion\n",
    "            # Check if next is an insertion (modification)\n",
    "            if i + 1 < len(diffs) and diffs[i + 1][0] == 1:\n",
    "                changes.append({\n",
    "                    \"type\": \"modification\",\n",
    "                    \"old\": text.strip(),\n",
    "                    \"new\": diffs[i + 1][1].strip()\n",
    "                })\n",
    "                i += 1  # Skip the insertion since we paired it\n",
    "            else:\n",
    "                changes.append({\n",
    "                    \"type\": \"deletion\",\n",
    "                    \"old\": text.strip(),\n",
    "                    \"new\": None\n",
    "                })\n",
    "        elif op == 1:  # Insertion (not paired with deletion)\n",
    "            changes.append({\n",
    "                \"type\": \"addition\",\n",
    "                \"old\": None,\n",
    "                \"new\": text.strip()\n",
    "            })\n",
    "        # op == 0 means equal, skip\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Filter out empty changes\n",
    "    changes = [c for c in changes if (c.get(\"old\") or c.get(\"new\"))]\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANGE_CLASSIFICATION_PROMPT = \"\"\"You are analyzing a change between two Wikipedia article snapshots.\n",
    "\n",
    "Classify this change into ONE of the following categories:\n",
    "- FACTUAL_UPDATE: A core fact changed (e.g., CEO changed, status changed, role changed)\n",
    "- NUMERIC_UPDATE: A number changed (e.g., population, revenue, date, statistics)\n",
    "- ADDITION: New substantive information was added\n",
    "- DELETION: Substantive information was removed\n",
    "- WORDING: Same fact expressed differently (paraphrase, grammar fix, formatting)\n",
    "\n",
    "Change type: {change_type}\n",
    "Old text: {old_text}\n",
    "New text: {new_text}\n",
    "\n",
    "Respond with ONLY one of: FACTUAL_UPDATE, NUMERIC_UPDATE, ADDITION, DELETION, WORDING\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "\n",
    "def classify_change(change: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Use LLM to classify a single change.\n",
    "    \"\"\"\n",
    "    prompt = CHANGE_CLASSIFICATION_PROMPT.format(\n",
    "        change_type=change[\"type\"],\n",
    "        old_text=change.get(\"old\", \"N/A\"),\n",
    "        new_text=change.get(\"new\", \"N/A\")\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=20,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    classification = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Validate response\n",
    "    valid_classes = [\"FACTUAL_UPDATE\", \"NUMERIC_UPDATE\", \"ADDITION\", \"DELETION\", \"WORDING\"]\n",
    "    if classification not in valid_classes:\n",
    "        # Try to extract valid class from response\n",
    "        for vc in valid_classes:\n",
    "            if vc in classification.upper():\n",
    "                return vc\n",
    "        return \"WORDING\"  # Default fallback\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_factual_changes(changes: List[Dict], batch_size: int = 10) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Filter changes to keep only factual/semantic changes (not just wording).\n",
    "    Uses LLM to classify each change.\n",
    "    \"\"\"\n",
    "    factual_changes = []\n",
    "    \n",
    "    for i, change in enumerate(changes):\n",
    "        # Skip very short changes (likely formatting)\n",
    "        old_len = len(change.get(\"old\", \"\") or \"\")\n",
    "        new_len = len(change.get(\"new\", \"\") or \"\")\n",
    "        \n",
    "        if old_len < 5 and new_len < 5:\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Classifying change {i+1}/{len(changes)}...\", end=\"\\r\")\n",
    "        \n",
    "        classification = classify_change(change)\n",
    "        change[\"classification\"] = classification\n",
    "        \n",
    "        # Keep all non-WORDING changes\n",
    "        if classification != \"WORDING\":\n",
    "            factual_changes.append(change)\n",
    "    \n",
    "    print(f\"\\n  Found {len(factual_changes)} factual changes out of {len(changes)} total changes\")\n",
    "    return factual_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1873d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_factual_changes(wiki_snapshot_t1: str, wiki_snapshot_t2: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Main function: Detect factual changes between two Wikipedia snapshots.\n",
    "    \n",
    "    Step 1: Use Myers diff to find all changes\n",
    "    Step 2: Use LLM to filter for semantic/factual changes only\n",
    "    \n",
    "    Returns list of classified factual changes.\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Computing Myers diff...\")\n",
    "    all_changes = get_myers_diff(wiki_snapshot_t1, wiki_snapshot_t2)\n",
    "    print(f\"  Found {len(all_changes)} raw changes\")\n",
    "    \n",
    "    if not all_changes:\n",
    "        print(\"  No changes detected\")\n",
    "        return []\n",
    "    \n",
    "    print(\"\\nStep 2: Filtering for factual changes...\")\n",
    "    factual_changes = filter_factual_changes(all_changes)\n",
    "    \n",
    "    return factual_changes\n",
    "\n",
    "\n",
    "def summarize_changes(factual_changes: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Summarize the factual changes by category.\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        \"FACTUAL_UPDATE\": [],\n",
    "        \"NUMERIC_UPDATE\": [],\n",
    "        \"ADDITION\": [],\n",
    "        \"DELETION\": []\n",
    "    }\n",
    "    \n",
    "    for change in factual_changes:\n",
    "        classification = change.get(\"classification\", \"WORDING\")\n",
    "        if classification in summary:\n",
    "            summary[classification].append(change)\n",
    "    \n",
    "    print(\"\\n=== Change Summary ===\")\n",
    "    for category, items in summary.items():\n",
    "        print(f\"{category}: {len(items)} changes\")\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057d33a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Entity: Elon_Musk\n",
      "  Raw changes detected: 35\n",
      "  Modifications: 16, Additions: 12, Deletions: 7\n",
      "  Sample changes:\n",
      "    [modification] 'B...' -> 'South African-born b...'\n",
      "    [modification] 'o...' -> 'O...'\n",
      "    [modification] 'pp-vandalism|small=yes}}\n",
      "{{pp-move}}\n",
      "{{Good articl...' -> 'Good article}}\n",
      "{{pp-move}}\n",
      "{{pp-vandalism|small=ye...'\n",
      "\n",
      "============================================================\n",
      "Entity: Sam_Altman\n",
      "  Raw changes detected: 10\n",
      "  Modifications: 4, Additions: 4, Deletions: 2\n",
      "  Sample changes:\n",
      "    [addition] '...' -> '{{Short description|American entrepreneur and inve...'\n",
      "    [deletion] '{{Short description|American entrepreneur and inve...' -> '...'\n",
      "    [deletion] 'File:...' -> '...'\n",
      "\n",
      "============================================================\n",
      "Entity: Taylor_Swift\n",
      "  Raw changes detected: 48\n",
      "  Modifications: 22, Additions: 18, Deletions: 8\n",
      "  Sample changes:\n",
      "    [modification] 'For|the album|Taylor Swift (album){{!}}''Taylor Sw...' -> 'Other uses...'\n",
      "    [modification] 'October...' -> 'March...'\n",
      "    [modification] '0...' -> '4...'\n",
      "\n",
      "============================================================\n",
      "Entity: LeBron_James\n",
      "  Raw changes detected: 83\n",
      "  Modifications: 47, Additions: 28, Deletions: 8\n",
      "  Sample changes:\n",
      "    [modification] 'Nov...' -> 'Dec...'\n",
      "    [modification] '3...' -> '4...'\n",
      "    [modification] 'In-Season Tournament champions|NBA In-Season Tourn...' -> 'Cup champions|NBA Cup...'\n",
      "\n",
      "============================================================\n",
      "Entity: Joe_Biden\n",
      "  Raw changes detected: 47\n",
      "  Modifications: 20, Additions: 16, Deletions: 11\n",
      "  Sample changes:\n",
      "    [addition] '...' -> 'first-born...'\n",
      "    [addition] '...' -> 'other uses...'\n",
      "    [modification] 'Februar...' -> 'Jul...'\n",
      "\n",
      "============================================================\n",
      "Entity: Mark_Zuckerberg\n",
      "  Raw changes detected: 29\n",
      "  Modifications: 17, Additions: 6, Deletions: 6\n",
      "  Sample changes:\n",
      "    [deletion] 'and philanthropist...' -> '...'\n",
      "    [addition] '...' -> '{{good article}}...'\n",
      "    [deletion] 'executive...' -> '...'\n",
      "\n",
      "============================================================\n",
      "Entity: Sundar_Pichai\n",
      "  Raw changes detected: 11\n",
      "  Modifications: 6, Additions: 4, Deletions: 1\n",
      "  Sample changes:\n",
      "    [modification] 's...' -> 'S...'\n",
      "    [addition] '...' -> 'born...'\n",
      "    [modification] 'engineer and executive...' -> 'business executive (born 1972)...'\n",
      "\n",
      "============================================================\n",
      "Entity: Lionel_Messi\n",
      "  Raw changes detected: 59\n",
      "  Modifications: 34, Additions: 21, Deletions: 4\n",
      "  Sample changes:\n",
      "    [addition] '...' -> '-vandalism...'\n",
      "    [modification] 'December...' -> 'January...'\n",
      "    [modification] '3...' -> '4...'\n",
      "\n",
      "============================================================\n",
      "Entity: Donald_Trump\n",
      "  Raw changes detected: 53\n",
      "  Modifications: 23, Additions: 15, Deletions: 15\n",
      "  Sample changes:\n",
      "    [addition] '...' -> '-elect and 45th president...'\n",
      "    [deletion] 'from 2017 to 2021...' -> '...'\n",
      "    [addition] '...' -> '|Donald Trump (disambiguation)...'\n",
      "\n",
      "============================================================\n",
      "Entity: Jensen_Huang\n",
      "  Raw changes detected: 35\n",
      "  Modifications: 17, Additions: 16, Deletions: 2\n",
      "  Sample changes:\n",
      "    [modification] 'American entrepreneur and businessman...' -> 'Taiwanese and American businessman (born 1963)}}\n",
      "{...'\n",
      "    [modification] 'November...' -> 'June...'\n",
      "    [modification] '1...' -> '4...'\n"
     ]
    }
   ],
   "source": [
    "# Test Myers diff on 10 entities from Wikipedia data\n",
    "import glob\n",
    "\n",
    "data_dir = \"data/wikipedia\"\n",
    "\n",
    "# Get 10 entities from people domain\n",
    "entities = [\n",
    "    \"Elon_Musk\", \"Sam_Altman\", \"Taylor_Swift\", \"LeBron_James\", \"Joe_Biden\",\n",
    "    \"Mark_Zuckerberg\", \"Sundar_Pichai\", \"Lionel_Messi\", \"Donald_Trump\", \"Jensen_Huang\"\n",
    "]\n",
    "\n",
    "# Compare 2024-01-01 vs 2025-01-01 snapshots\n",
    "for entity in entities:\n",
    "    path_t1 = f\"{data_dir}/people/{entity}/2024-01-01.json\"\n",
    "    path_t2 = f\"{data_dir}/people/{entity}/2025-01-01.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(path_t1) as f:\n",
    "            snapshot_t1 = json.load(f).get(\"content\", \"\")\n",
    "        with open(path_t2) as f:\n",
    "            snapshot_t2 = json.load(f).get(\"content\", \"\")\n",
    "        \n",
    "        # Run Myers diff\n",
    "        changes = get_myers_diff(snapshot_t1, snapshot_t2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Entity: {entity}\")\n",
    "        print(f\"  Raw changes detected: {len(changes)}\")\n",
    "        \n",
    "        # Show breakdown by type\n",
    "        mods = sum(1 for c in changes if c[\"type\"] == \"modification\")\n",
    "        adds = sum(1 for c in changes if c[\"type\"] == \"addition\")\n",
    "        dels = sum(1 for c in changes if c[\"type\"] == \"deletion\")\n",
    "        print(f\"  Modifications: {mods}, Additions: {adds}, Deletions: {dels}\")\n",
    "        \n",
    "        # Show first 3 changes as examples\n",
    "        if changes:\n",
    "            print(f\"  Sample changes:\")\n",
    "            for c in changes[:3]:\n",
    "                old = (c.get(\"old\") or \"\")[:50]\n",
    "                new = (c.get(\"new\") or \"\")[:50]\n",
    "                print(f\"    [{c['type']}] '{old}...' -> '{new}...'\")\n",
    "                \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n{entity}: Files not found - {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
